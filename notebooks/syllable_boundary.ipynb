{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.analysis.state_space import prepare_state_trajectory, StateSpaceAnalysisSpec, flatten_trajectory\n",
    "from src.utils.timit import get_word_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model_dir = \"outputs/models/librispeech-train-clean-100/w2v2_8/discrim-rnn_32-mAP1/word_broad_10frames_fixedlen25\"\n",
    "output_dir = \".\"\n",
    "dataset_path = \"outputs/preprocessed_data/librispeech-train-clean-100\"\n",
    "equivalence_path = \"outputs/equivalence_datasets/librispeech-train-clean-100/w2v2_8/word_broad_10frames_fixedlen25/equivalence.pkl\"\n",
    "hidden_states_path = \"outputs/hidden_states/librispeech-train-clean-100/w2v2_8/hidden_states.h5\"\n",
    "state_space_specs_path = \"outputs/state_space_specs/librispeech-train-clean-100/w2v2_8/state_space_specs.h5\"\n",
    "embeddings_path = \"outputs/model_embeddings/librispeech-train-clean-100/w2v2_8/discrim-rnn_32-mAP1/word_broad_10frames_fixedlen25/librispeech-train-clean-100.npy\"\n",
    "\n",
    "metric = \"cosine\"\n",
    "\n",
    "# Retain words with N or more instances\n",
    "retain_n = 10\n",
    "\n",
    "subsample_instances = 50\n",
    "\n",
    "model_sfreq = 50\n",
    "\n",
    "expand_window = (15, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(embeddings_path, \"rb\") as f:\n",
    "    model_representations: np.ndarray = np.load(f)\n",
    "state_space_spec_syll = StateSpaceAnalysisSpec.from_hdf5(state_space_specs_path, \"syllable\")\n",
    "state_space_spec_word = StateSpaceAnalysisSpec.from_hdf5(state_space_specs_path, \"word\")\n",
    "assert state_space_spec_syll.is_compatible_with(model_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syll_from_word = state_space_spec_word.cuts.xs(\"syllable\", level=\"level\")\n",
    "syll_from_word[\"instance_diff\"] = syll_from_word.index.get_level_values(\"instance_idx\").diff()\n",
    "# NB this breaks on single-syllable words because of adjacent rows with the same instance_idx,\n",
    "# which is fine; we want to exclude those\n",
    "syll_from_word[\"word_initial\"] = syll_from_word[\"instance_diff\"].isna() | (syll_from_word[\"instance_diff\"] != 0)\n",
    "syll_from_word.loc[\"reaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_initial = syll_from_word.reset_index().set_index(\"onset_frame_idx\").word_initial.to_dict()\n",
    "word_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space_spec = state_space_spec_syll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = state_space_spec.label_counts\n",
    "drop_labels = label_counts[label_counts < retain_n].index\n",
    "state_space_spec = state_space_spec.drop_labels(drop_names=drop_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space_spec = state_space_spec.subsample_instances(subsample_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-hoc hack: retain only non-word-initial syllables\n",
    "to_drop = set((label_idx, j)\n",
    "           for label_idx, spans_i in enumerate(state_space_spec.target_frame_spans)\n",
    "           for j, (start_frame, end_frame) in enumerate(spans_i)\n",
    "           if word_initial[start_frame])\n",
    "print(f\"Dropping {len(to_drop)} word-initial syllables\")\n",
    "new_target_frame_spans = [[span_j for j, span_j in enumerate(spans_i) if (i, j) not in to_drop]\n",
    "                           for i, spans_i in enumerate(state_space_spec.target_frame_spans)]\n",
    "from dataclasses import replace\n",
    "ss_new = replace(state_space_spec, cuts=None, target_frame_spans=new_target_frame_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_label_idxs = [idx for idx, spans_i in enumerate(ss_new.target_frame_spans) if len(spans_i) == 0]\n",
    "ss_new = ss_new.drop_labels(drop_idxs=drop_label_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = prepare_state_trajectory(model_representations, ss_new, pad=np.nan,\n",
    "                                      expand_window=expand_window)\n",
    "lengths = [np.isnan(traj_i[:, :, 0]).any(axis=1) * np.isnan(traj_i[:, :, 0]).argmax(axis=1) + \\\n",
    "           ~np.isnan(traj_i[:, :, 0]).any(axis=1) * traj_i.shape[1]\n",
    "           for traj_i in trajectory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_full, traj_full_flat_src = flatten_trajectory(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trajectory), np.concatenate(lengths).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_full = PCA(n_components=4)\n",
    "traj_full_flat_pca = pca_full.fit_transform(traj_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare truncated trajectory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_trunc = [traj_i[:, :(expand_window[0] + 15)] for traj_i in trajectory]\n",
    "traj_trunc_flat, traj_trunc_flat_src = flatten_trajectory(traj_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc_times = np.concatenate([-np.arange(expand_window[0], -1, -1), np.arange(1, 15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=4)\n",
    "traj_trunc_flat_pca = pca.fit_transform(traj_trunc_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_full_flat_src_dict = {src: i for i, src in enumerate(map(tuple, traj_full_flat_src))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_full_flat_frame_dict = defaultdict(list)\n",
    "for i, src in enumerate(traj_full_flat_src):\n",
    "    traj_full_flat_frame_dict[tuple(src[:2])].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(traj_full_flat_frame_dict[6, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_state_space_binned(n_bins, groupby=None, return_data=False, hide_largest_bin=True):\n",
    "    all_lengths = np.concatenate(lengths)\n",
    "    max_traj_length = all_lengths.max()\n",
    "\n",
    "    # bin word tokens by length\n",
    "    length_bins = pd.qcut(all_lengths, q=n_bins, labels=np.arange(n_bins), retbins=True)[1]\n",
    "    bin_time_edges = np.maximum(0, length_bins) / model_sfreq\n",
    "    bin_assignments = [np.digitize(traj_lengths, length_bins, right=True) - 1\n",
    "                       for traj_lengths in lengths]    \n",
    "    all_bin_assignments = np.concatenate(bin_assignments)\n",
    "    all_bin_assignments = all_bin_assignments[all_bin_assignments >= 0]\n",
    "\n",
    "    # key := bin + grouping variables\n",
    "    # build reverse map from key and frame index to list of (label_idx, instance_idx) tuples\n",
    "    bin_assignments_rev = defaultdict(list)\n",
    "    if groupby is not None:\n",
    "        group_lookup = metadata[groupby].to_dict()\n",
    "    for label_idx, assignments_i in enumerate(bin_assignments):\n",
    "        for j, bin_idx in enumerate(assignments_i):\n",
    "            if bin_idx < 0:\n",
    "                continue\n",
    "\n",
    "            if groupby is not None:\n",
    "                group_value = group_lookup[state_space_spec.labels[label_idx], j]\n",
    "                if group_value is None or (isinstance(group_value, float) and np.isnan(group_value)):\n",
    "                    continue\n",
    "                key = (bin_idx, group_value)\n",
    "            else:\n",
    "                key = (bin_idx,)\n",
    "            bin_assignments_rev[key].append((label_idx, j))\n",
    "\n",
    "    # Prepare per-key vector collections\n",
    "    if return_data:\n",
    "        bin_frame_data, bin_frame_src = {}, {}\n",
    "        for key, traj_indices in bin_assignments_rev.items():\n",
    "            data_i, src_i = [], []\n",
    "            for label_idx, instance_idx in traj_indices:\n",
    "                flat_idxs = traj_full_flat_frame_dict[label_idx, instance_idx]\n",
    "                data_i.append(traj_full_flat_pca[flat_idxs])\n",
    "                src_i.append(traj_full_flat_src[flat_idxs])\n",
    "\n",
    "            bin_frame_data[key] = data_i\n",
    "            bin_frame_src[key] = src_i\n",
    "\n",
    "    # Prepare per-frame and per-key means\n",
    "    bin_frame_means = defaultdict(list)\n",
    "    for key, traj_indices in tqdm(bin_assignments_rev.items(), desc=\"retrieving per-bin data\"):\n",
    "        for frame_idx in range(max_traj_length):\n",
    "            flat_idxs = [traj_full_flat_src_dict[(label_idx, instance_idx, frame_idx)]\n",
    "                        for label_idx, instance_idx in traj_indices\n",
    "                        if (label_idx, instance_idx, frame_idx) in traj_full_flat_src_dict]\n",
    "            \n",
    "            if len(flat_idxs) == 0:\n",
    "                bin_frame_means[key].append(np.full(traj_full_flat_pca.shape[1], np.nan))\n",
    "            else:\n",
    "                bin_frame_means[key].append(traj_full_flat_pca[flat_idxs].mean(axis=0))\n",
    "\n",
    "    bin_frame_means = {key: np.array(frame_means_i) for key, frame_means_i in bin_frame_means.items()}\n",
    "\n",
    "    ## Plot\n",
    "    pcs = [[0, 1], [2, 3]]\n",
    "    f, axs = plt.subplots(1, len(pcs), figsize=(10 * len(pcs), 10), squeeze=False)\n",
    "\n",
    "    # bin_colors = sns.color_palette(\"tab10\", n_bins)\n",
    "    # get normalized continuous hue for bin edges\n",
    "    bin_colors = sns.color_palette(\"spring\", n_bins)\n",
    "    grouping_values = sorted(set(key[1:] for key in bin_frame_means.keys()))\n",
    "    grouping_styles = [\"-\", \"--\", \"-.\", \":\", (0, (3, 5, 1, 5)), (0, (3, 5, 1, 5, 1, 5))]\n",
    "    assert len(grouping_values) <= len(grouping_styles)\n",
    "\n",
    "    for i, (pcs_i, ax) in enumerate(zip(pcs, axs.flat)):\n",
    "        ax.axvline(0, color=\"black\", linestyle=\"--\")\n",
    "        ax.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "        i, j = pcs_i\n",
    "        ax.set_xlabel(f\"PC {i+1}\")\n",
    "        ax.set_ylabel(f\"PC {j+1}\")\n",
    "\n",
    "        k = 0\n",
    "        for key in sorted(bin_frame_means.keys()):\n",
    "            bin_idx = key[0]\n",
    "            if hide_largest_bin and bin_idx == n_bins - 1:\n",
    "                continue\n",
    "\n",
    "            grouping_values_ij = key[1:]\n",
    "            means = bin_frame_means[key]\n",
    "            bin_edge = bin_time_edges[bin_idx]\n",
    "            ax.plot(means[:, i], means[:, j], label=f\"{key[1:]} {bin_edge:.2f} s\",\n",
    "                    color=bin_colors[bin_idx],\n",
    "                    linestyle=grouping_styles[grouping_values.index(grouping_values_ij)],\n",
    "                    alpha=0.7)\n",
    "\n",
    "            ax.quiver(means[:-1, i], means[:-1, j], means[1:, i] - means[:-1, i], means[1:, j] - means[:-1, j],\n",
    "                        angles='xy', scale_units='xy', scale=1, color=\"gray\", alpha=0.5)\n",
    "            \n",
    "            # O at start of word\n",
    "            word_start_frame = 0 + expand_window[0]\n",
    "            ax.scatter(means[word_start_frame, i], means[word_start_frame, j], color=\"blue\", marker=\"o\")\n",
    "\n",
    "            # X at middle of word\n",
    "            if np.isnan(means).any():\n",
    "                max_length = np.isnan(means).argmax(0).min() - 1\n",
    "            else:\n",
    "                max_length = means.shape[0]\n",
    "            word_midpoint_frame = (max_length - word_start_frame) // 2 + word_start_frame\n",
    "            ax.scatter(means[word_midpoint_frame, i], means[word_midpoint_frame, j], color=\"red\", marker=\"x\")\n",
    "\n",
    "        # legend on last axis\n",
    "        handles, labels = [], []\n",
    "        from matplotlib import patches as mpatches\n",
    "        from matplotlib.lines import Line2D\n",
    "        handles.append(mpatches.Patch(color=\"white\", label=\"\"))\n",
    "        labels.append(\"length bin\")\n",
    "        for bin in range(n_bins):\n",
    "            handles.append(mpatches.Patch(color=bin_colors[bin], label=f\"bin {bin}\"))\n",
    "            labels.append(f\"{bin_time_edges[bin]:.2f} s\")\n",
    "\n",
    "        if groupby is not None:\n",
    "            handles.append(mpatches.Patch(color=\"white\", label=\"\"))\n",
    "            labels.append(groupby)\n",
    "            for group, style in zip(grouping_values, grouping_styles):\n",
    "                handles.append(Line2D([0], [0], color=\"black\", linestyle=style))\n",
    "                labels.append(group)\n",
    "\n",
    "        ax.legend(handles, labels, loc=\"upper right\", bbox_to_anchor=(1.5, 1))\n",
    "\n",
    "    if return_data:\n",
    "        return f, bin_frame_data, bin_frame_src, bin_frame_means, bin_time_edges\n",
    "    else:\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ss_data_all, ss_src_all, ss_means_all, ss_edges_all = plot_state_space_binned(5, return_data=True)\n",
    "f.savefig(Path(output_dir) / \"state_space.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_track_key = (0,)\n",
    "maxlen = max(data_i.shape[0] for data_i in ss_data_all[norm_track_key])\n",
    "norm_track_data = np.full((len(ss_data_all[norm_track_key]), maxlen), np.nan)\n",
    "diff_norm_track_data = np.full((len(ss_data_all[norm_track_key]), maxlen), np.nan)\n",
    "for i, data_i in enumerate(ss_data_all[norm_track_key]):\n",
    "    norm_track_data[i, :data_i.shape[0]] = np.linalg.norm(data_i, axis=1)\n",
    "    diff_norm_track_data[i, :data_i.shape[0]] = np.linalg.norm(np.roll(data_i, -1, axis=0) - data_i, axis=1)\n",
    "\n",
    "# order by peak time\n",
    "norm_track_data = norm_track_data[norm_track_data.argmax(axis=1).argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.nanmean(norm_track_data, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.nanmean(diff_norm_track_data, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_idxs_by_frame = []\n",
    "for frame_idx in range(traj_trunc_flat_src[:, 2].max() + 1):\n",
    "    traj_idxs_by_frame.append(np.where(traj_trunc_flat_src[:, 2] == frame_idx)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_means, frame_sds, frame_counts = [], [], []\n",
    "for frame_idx, traj_idxs_i in enumerate(traj_idxs_by_frame):\n",
    "    frame_means.append(traj_trunc_flat_pca[traj_idxs_i].mean(axis=0))\n",
    "    frame_sds.append(traj_trunc_flat_pca[traj_idxs_i].std(axis=0))\n",
    "    frame_counts.append(len(traj_idxs_i))\n",
    "\n",
    "frame_means = np.array(frame_means)\n",
    "frame_sds = np.array(frame_sds)\n",
    "frame_counts = np.array(frame_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "\n",
    "times = np.arange(-expand_window[0], frame_means.shape[0] - expand_window[0]) / model_sfreq\n",
    "ax.axvline(0, color=\"gray\", linestyle=\"--\")\n",
    "ax.axhline(0, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "for component in range(frame_means.shape[1]):\n",
    "    ax.plot(times, frame_means[:, component], label=f\"PC {component+1}\")\n",
    "    ax.fill_between(times,\n",
    "                    frame_means[:, component] - frame_sds[:, component] / np.sqrt(frame_counts),\n",
    "                    frame_means[:, component] + frame_sds[:, component] / np.sqrt(frame_counts),\n",
    "                    alpha=0.3)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Distance from syllable boundary\")\n",
    "\n",
    "f.savefig(Path(output_dir) / \"syllable_boundary.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

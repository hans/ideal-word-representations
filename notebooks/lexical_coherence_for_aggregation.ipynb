{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study how lexical coherence relations are preserved by aggregation functions over time.\n",
    "This is relevant because the brain encoding pipeline aggregates these over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.analysis import coherence\n",
    "from src.analysis.state_space import StateSpaceAnalysisSpec, \\\n",
    "    prepare_state_trajectory, aggregate_state_trajectory\n",
    "from src.datasets.speech_equivalence import SpeechEquivalenceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model_dir = \"outputs/models/timit/w2v2_6/rnn_8-aniso2/word_broad_10frames\"\n",
    "output_dir = \".\"\n",
    "dataset_path = \"outputs/preprocessed_data/timit\"\n",
    "equivalence_path = \"outputs/equivalence_datasets/timit/w2v2_6/word_broad_10frames/equivalence.pkl\"\n",
    "hidden_states_path = \"outputs/hidden_states/timit/w2v2_6/hidden_states.h5\"\n",
    "state_space_specs_path = \"outputs/state_space_specs/timit/w2v2_6/state_space_specs.pkl\"\n",
    "embeddings_path = \"outputs/model_embeddings/timit/w2v2_6/rnn_8-weightdecay0.01/word_broad_10frames/embeddings.npy\"\n",
    "\n",
    "metric = \"cosine\"\n",
    "\n",
    "# Retain words with N or more instances\n",
    "retain_n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(embeddings_path, \"rb\") as f:\n",
    "    model_representations: np.ndarray = np.load(f)\n",
    "with open(state_space_specs_path, \"rb\") as f:\n",
    "    state_space_spec: StateSpaceAnalysisSpec = torch.load(f)[\"word\"]\n",
    "assert state_space_spec.is_compatible_with(model_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_idxs = [idx for idx, target_frames in enumerate(state_space_spec.target_frame_spans)\n",
    "               if len(target_frames) < retain_n]\n",
    "state_space_spec = state_space_spec.drop_labels(drop_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_fns = [\n",
    "    \"mean\", \"max\", \"last_frame\",\n",
    "    (\"mean_last_k\", 2), (\"mean_last_k\", 5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = prepare_state_trajectory(model_representations, state_space_spec, pad=np.nan)\n",
    "lengths = [np.isnan(traj_i[:, :, 0]).argmax(axis=1) for traj_i in trajectory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_aggs = {agg_fn: aggregate_state_trajectory(trajectory, state_space_spec, agg_fn, keepdims=True)\n",
    "                   for agg_fn in agg_fns}\n",
    "dummy_lengths = [np.ones(len(traj_i), dtype=int) for traj_i in trajectory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trajectory), np.concatenate(lengths).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate within-word distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_distance_dfs = {}\n",
    "\n",
    "for agg_fn, traj_agg in tqdm(trajectory_aggs.items(), unit=\"aggfn\"):\n",
    "    within_distance, within_distance_offset = \\\n",
    "        coherence.estimate_within_distance(traj_agg, dummy_lengths, state_space_spec, metric=metric)\n",
    "\n",
    "    within_distance_dfs[agg_fn] = pd.DataFrame(\n",
    "        within_distance, columns=[\"distance\"], index=pd.Index(state_space_spec.labels, name=\"word\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate between-word distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "between_distance_dfs = {}\n",
    "\n",
    "for agg_fn, traj_agg in tqdm(trajectory_aggs.items(), unit=\"aggfn\"):\n",
    "    between_distance, between_distance_offset = \\\n",
    "        coherence.estimate_between_distance(traj_agg, dummy_lengths, state_space_spec, metric=metric)\n",
    "\n",
    "    between_distance_dfs[agg_fn] = pd.DataFrame(\n",
    "        between_distance.squeeze(1).mean(axis=-1),\n",
    "        columns=[\"distance\"], index=pd.Index(state_space_spec.labels, name=\"word\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat({\n",
    "    \"within\": pd.concat(within_distance_dfs, names=[\"agg_fn\"]),\n",
    "    \"between\": pd.concat(between_distance_dfs, names=[\"agg_fn\"]),\n",
    "}, names=[\"type\"])\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.catplot(data=merged_df.reset_index(),\n",
    "                 x=\"agg_fn\", y=\"distance\", hue=\"type\", kind=\"bar\")\n",
    "# ax.set_title(\"Representational distance within- and between-word\")\n",
    "# ax.set_xlabel(\"Frames since word onset\")\n",
    "# ax.set_ylabel(f\"{metric.capitalize()} distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate distance by grouping features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onsets = [word[0] for word in state_space_spec.labels]\n",
    "\n",
    "onset_distance_dfs = {}\n",
    "for agg_fn, traj_agg in tqdm(trajectory_aggs.items(), unit=\"aggfn\"):\n",
    "    onset_distance_dfs[agg_fn], _ = coherence.estimate_category_within_between_distance(\n",
    "        traj_agg, dummy_lengths, onsets, metric=metric, labels=state_space_spec.labels\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onset_distance_df = pd.concat(onset_distance_dfs, names=[\"agg_fn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onset_distance_df.to_csv(Path(output_dir) / \"distances-grouped_onset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.catplot(data=onset_distance_df, x=\"agg_fn\", y=\"distance\", hue=\"type\", kind=\"bar\")\n",
    "# ax.set_title(\"Representational distance by onset match/mismatch\")\n",
    "# ax.set_xlabel(\"Frames since word onset\")\n",
    "# ax.set_ylabel(f\"{metric.capitalize()} distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = [word[-1] for word in state_space_spec.labels]\n",
    "\n",
    "offset_distance_dfs = {}\n",
    "for agg_fn, traj_agg in tqdm(trajectory_aggs.items(), unit=\"aggfn\"):\n",
    "    offset_distance_dfs[agg_fn], _ = coherence.estimate_category_within_between_distance(\n",
    "        traj_agg, dummy_lengths, offsets, metric=metric, labels=state_space_spec.labels\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_distance_df = pd.concat(offset_distance_dfs, names=[\"agg_fn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_distance_df.to_csv(Path(output_dir) / \"distances-grouped_offset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=offset_distance_df.reset_index(), x=\"agg_fn\", y=\"distance\", hue=\"type\", kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_distance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-free exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_references = np.concatenate(trajectory_aggs[\"mean\"]).squeeze(1)\n",
    "knn_reference_ids = np.concatenate([np.stack([np.ones(len(traj)) * i, np.arange(len(traj))]).T\n",
    "                                   for i, traj in enumerate(trajectory_aggs[\"mean\"])], axis=0).astype(int)\n",
    "\n",
    "assert len(knn_references) == len(knn_reference_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_instances = np.random.choice(len(knn_references), 10, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist, pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for knn_instance in knn_instances:\n",
    "    ref_embedding = knn_references[knn_instance]\n",
    "    knn_instance_results = cdist(knn_references, ref_embedding[None, :], metric=metric).ravel()\n",
    "\n",
    "    print(state_space_spec.labels[knn_reference_ids[knn_instance][0]], knn_reference_ids[knn_instance][1])\n",
    "    print(\"Nearest neighbors:\")\n",
    "    for class_idx, instance_idx in knn_reference_ids[knn_instance_results.argsort()[1:10]]:\n",
    "        print(\"\\t\", state_space_spec.labels[class_idx], instance_idx)\n",
    "    print(\"Furthest neighbors:\")\n",
    "    for class_idx, instance_idx in knn_reference_ids[-knn_instance_results.argsort()[1:10]]:\n",
    "        print(\"\\t\", state_space_spec.labels[class_idx], instance_idx)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSA, collapsed over instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsa_distances = {}\n",
    "\n",
    "for agg_fn, traj_agg in tqdm(trajectory_aggs.items(), unit=\"aggfn\"):\n",
    "    rsa_references = np.stack([np.mean(traj_agg_i.squeeze(1), axis=0) for traj_agg_i in traj_agg])\n",
    "    rsa_distances[agg_fn] = pd.DataFrame(\n",
    "        squareform(pdist(rsa_references, metric=metric)),\n",
    "        index=state_space_spec.labels,\n",
    "        columns=state_space_spec.labels\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsa_viz_sample = np.random.choice(state_space_spec.labels, size=20, replace=False)\n",
    "\n",
    "f, axs = plt.subplots(len(agg_fns), 1, figsize=(10, 10 * len(agg_fns)))\n",
    "for ax, (agg_fn, rsa_distances_i) in zip(axs.ravel(), rsa_distances.items()):\n",
    "    rsa_viz = rsa_distances_i.loc[rsa_viz_sample, rsa_viz_sample]\n",
    "    sns.heatmap(rsa_viz, ax=ax)\n",
    "    ax.set_title(agg_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsa_sims = {}\n",
    "for agg1, agg2 in itertools.product(agg_fns, repeat=2):\n",
    "    rsa_triu1 = rsa_distances[agg1].values[np.triu_indices(len(rsa_distances[agg1]), k=1)]\n",
    "    rsa_triu2 = rsa_distances[agg2].values[np.triu_indices(len(rsa_distances[agg2]), k=1)]\n",
    "    rsa_sims[agg1, agg2] = scipy.stats.spearmanr(rsa_triu1, rsa_triu2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsa_sims = pd.Series(rsa_sims)\n",
    "rsa_sims.index.set_names([\"agg1\", \"agg2\"], inplace=True)\n",
    "rsa_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(rsa_sims.unstack())\n",
    "ax.set_title(\"Similarity in word-level RSA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(rsa_viz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

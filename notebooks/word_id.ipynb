{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from src.analysis import coherence\n",
    "from src.analysis.state_space import StateSpaceAnalysisSpec, \\\n",
    "    prepare_state_trajectory, aggregate_state_trajectory, flatten_trajectory\n",
    "from src.datasets.speech_equivalence import SpeechEquivalenceDataset\n",
    "from src.utils import ndarray_to_long_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model_dir = \"outputs/models/librispeech-train-clean-100/w2v2_8/rnn_32-aniso3/word_broad_10frames\"\n",
    "output_dir = \".\"\n",
    "dataset_path = \"outputs/preprocessed_data/librispeech-train-clean-100\"\n",
    "equivalence_path = \"outputs/equivalence_datasets/librispeech-train-clean-100/w2v2_8/word_broad_10frames/equivalence.pkl\"\n",
    "hidden_states_path = \"outputs/hidden_states/librispeech-train-clean-100/w2v2_8/librispeech-train-clean-100.h5\"\n",
    "state_space_specs_path = \"outputs/state_space_specs/librispeech-train-clean-100/w2v2_8/state_space_specs.pkl\"\n",
    "embeddings_path = \"outputs/model_embeddings/librispeech-train-clean-100/w2v2_8/rnn_32-aniso3/word_broad_10frames/librispeech-train-clean-100.npy\"\n",
    "\n",
    "agg_methods = {\n",
    "    \"mean_within_phoneme\": (\"mean_within_cut\", \"phoneme\"),\n",
    "    \"mean_within_syllable\": (\"mean_within_cut\", \"syllable\"),\n",
    "    \"mean\": \"mean\",\n",
    "    \"last_frame\": \"last_frame\",\n",
    "    \"max\": \"max\",\n",
    "    \"none\": None,\n",
    "}\n",
    "\n",
    "# Keep just the K most frequent words\n",
    "k = 500\n",
    "\n",
    "# Keep at most N instances of each word\n",
    "n = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(embeddings_path, \"rb\") as f:\n",
    "    model_representations: np.ndarray = np.load(f)\n",
    "with open(state_space_specs_path, \"rb\") as f:\n",
    "    state_space_spec: StateSpaceAnalysisSpec = torch.load(f)[\"word\"]\n",
    "assert state_space_spec.is_compatible_with(model_representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PWCCA definition\n",
    "\n",
    "https://github.com/1Konny/Projection_Weighted_CCA/blob/master/cca.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy&paste from: https://github.com/google/svcca/blob/master/cca_core.py\n",
    "def positivedef_matrix_sqrt(array):\n",
    "    \"\"\"Stable method for computing matrix square roots, supports complex matrices.\n",
    "\n",
    "    Args:\n",
    "        array: A numpy 2d array, can be complex valued that is a positive\n",
    "            definite symmetric (or hermitian) matrix\n",
    "\n",
    "    Returns:\n",
    "        sqrtarray: The matrix square root of array\n",
    "    \"\"\"\n",
    "    w, v = np.linalg.eigh(array)\n",
    "    wsqrt = np.sqrt(w)\n",
    "    sqrtarray = np.dot(v, np.dot(np.diag(wsqrt), np.conj(v).T))\n",
    "    return sqrtarray\n",
    "\n",
    "\n",
    "# copy&paste from: https://github.com/google/svcca/blob/master/cca_core.py\n",
    "def remove_small(sigma_xx, sigma_xy, sigma_yx, sigma_yy, threshold=1e-6):\n",
    "    \"\"\"Takes covariance between X, Y, and removes values of small magnitude.\n",
    "\n",
    "    Args:\n",
    "        sigma_xx: 2d numpy array, variance matrix for x\n",
    "        sigma_xy: 2d numpy array, crossvariance matrix for x,y\n",
    "        sigma_yx: 2d numpy array, crossvariance matrixy for x,y,\n",
    "            (conjugate) transpose of sigma_xy\n",
    "        sigma_yy: 2d numpy array, variance matrix for y\n",
    "        threshold: cutoff value for norm below which directions are thrown\n",
    "            away\n",
    "\n",
    "    Returns:\n",
    "            sigma_xx_crop: 2d array with low x norm directions removed\n",
    "            sigma_xy_crop: 2d array with low x and y norm directions removed\n",
    "            sigma_yx_crop: 2d array with low x and y norm directiosn removed\n",
    "            sigma_yy_crop: 2d array with low y norm directions removed\n",
    "            x_idxs: indexes of sigma_xx that were removed\n",
    "            y_idxs: indexes of sigma_yy that were removed\n",
    "    \"\"\"\n",
    "\n",
    "    x_diag = np.abs(np.diagonal(sigma_xx))\n",
    "    y_diag = np.abs(np.diagonal(sigma_yy))\n",
    "    x_idxs = (x_diag >= threshold)\n",
    "    y_idxs = (y_diag >= threshold)\n",
    "\n",
    "    sigma_xx_crop = sigma_xx[x_idxs][:, x_idxs]\n",
    "    sigma_xy_crop = sigma_xy[x_idxs][:, y_idxs]\n",
    "    sigma_yx_crop = sigma_yx[y_idxs][:, x_idxs]\n",
    "    sigma_yy_crop = sigma_yy[y_idxs][:, y_idxs]\n",
    "\n",
    "    return (sigma_xx_crop, sigma_xy_crop, sigma_yx_crop, sigma_yy_crop, x_idxs, y_idxs)\n",
    "\n",
    "\n",
    "def gs_orthonormalize(array):\n",
    "    \"\"\"Gram-Schmidt orthonormalization.\"\"\"\n",
    "    q, _ = np.linalg.qr(array)\n",
    "    if q.shape[1] < array.shape[1]:\n",
    "        zero_pad = np.zeros(shape=(q.shape[0], array.shape[1]-q.shape[1]))\n",
    "        q = np.concatenate([q, zero_pad], 1)\n",
    "    return q\n",
    "\n",
    "\n",
    "# modified from and built on the codes in https://github.com/google/svcca/blob/master/cca_core.py\n",
    "def solve_cca(x, y):\n",
    "    \"\"\"Calculate CCA correlations, position vectors, images, and Mean|Projection Weighted similarity.\n",
    "    \n",
    "    The terms, 'correlation', 'position vector', 'image' are detailed in [1].\n",
    "    [1] A Tutorial on Canonical Correlation Methods, Uurtio et al\n",
    "    \n",
    "    Args:\n",
    "        x: A representation of shape (num_neurons, num_datapoints)\n",
    "        y: A representation of shape (num_neurons, num_datapoints)\n",
    "    \"\"\"\n",
    "    assert x.ndim == y.ndim == 2, 'both x and y should be 2D array, [num_neurons, num_datapoints]'\n",
    "    assert x.shape[1] == y.shape[1], 'the number of datapoints between x and y do not match'\n",
    "    assert x.shape[0] <= x.shape[1], 'num_datapoints should be greater than or equal to num_neurons. please check x.shape'\n",
    "    assert y.shape[0] <= y.shape[1], 'num_datapoints should be greater than or equal to num_neurons. please check y.shape'\n",
    "    epsilon = 1e-6\n",
    "    \n",
    "    numx = x.shape[0]\n",
    "    numy = y.shape[0]\n",
    "\n",
    "    sigma = np.cov(x, y)\n",
    "    sigmaxx = sigma[:numx, :numx]\n",
    "    sigmaxy = sigma[:numx, numx:]\n",
    "    sigmayx = sigma[numx:, :numx]\n",
    "    sigmayy = sigma[numx:, numx:]\n",
    "\n",
    "    # normalize covariance matrices for stability\n",
    "    xmax = np.max(np.abs(sigmaxx))\n",
    "    ymax = np.max(np.abs(sigmayy))\n",
    "    sigmaxx /= xmax\n",
    "    sigmayy /= ymax\n",
    "    sigmaxy /= np.sqrt(xmax*ymax)\n",
    "    sigmayx /= np.sqrt(ymax*xmax)\n",
    "    \n",
    "    # remove negligibly small covariances\n",
    "    sigmaxx, sigmaxy, sigmayx, sigmayy, x_idxs, y_idxs = remove_small(sigmaxx, sigmaxy, sigmayx, sigmayy)\n",
    "    x = x[x_idxs]\n",
    "    y = y[y_idxs]\n",
    "\n",
    "    numx = sigmaxx.shape[0]\n",
    "    numy = sigmayy.shape[0]\n",
    "    if numx == 0 or numy == 0:\n",
    "        raise NotImplementedError('check here.')\n",
    "\n",
    "    sigmaxx += epsilon*np.eye(numx)\n",
    "    sigmayy += epsilon*np.eye(numy)\n",
    "    inv_sigmaxx = np.linalg.pinv(sigmaxx)\n",
    "    inv_sigmayy = np.linalg.pinv(sigmayy)\n",
    "    invsqrt_sigmaxx = positivedef_matrix_sqrt(inv_sigmaxx)\n",
    "    invsqrt_sigmayy = positivedef_matrix_sqrt(inv_sigmayy)\n",
    "\n",
    "    arrx = invsqrt_sigmaxx.dot(sigmaxy).dot(inv_sigmayy.dot(sigmayx.dot(invsqrt_sigmaxx)))\n",
    "    arry = invsqrt_sigmayy.dot(sigmayx).dot(inv_sigmaxx.dot(sigmaxy.dot(invsqrt_sigmayy)))\n",
    "    arrx += epsilon*np.eye(arrx.shape[0])\n",
    "    arry += epsilon*np.eye(arry.shape[0])\n",
    "\n",
    "    ux, sx, vhx = np.linalg.svd(arrx)\n",
    "    uy, sy, vhy = np.linalg.svd(arry)\n",
    "\n",
    "    cca_corr_x = np.sqrt(np.abs(sx)) # each value represents k-th order canonical correlation coefficient of x\n",
    "    cca_corr_x = np.where(cca_corr_x>1, 1, cca_corr_x)\n",
    "    cca_corr_x = np.where(cca_corr_x<epsilon, 0, cca_corr_x)\n",
    "    \n",
    "    cca_corr_y = np.sqrt(np.abs(sy)) \n",
    "    cca_corr_y = np.where(cca_corr_y>1, 1, cca_corr_y)\n",
    "    cca_corr_y = np.where(cca_corr_y<epsilon, 0, cca_corr_y)\n",
    "    \n",
    "    # check\n",
    "    cca_pos_x = vhx.dot(invsqrt_sigmaxx) # each row represents k-th order canonical correlation position vector of x\n",
    "    cca_pos_y = vhy.dot(invsqrt_sigmayy)\n",
    "    \n",
    "    # check\n",
    "    cca_image_x = cca_pos_x.dot(x) # each row represents k-th order canonical correlation image of x\n",
    "    cca_image_y = cca_pos_y.dot(y)\n",
    "\n",
    "    min_numxy = min(numx, numy)\n",
    "    truncated_corr_x = cca_corr_x[:min_numxy]\n",
    "    truncated_corr_y = cca_corr_y[:min_numxy]\n",
    "    equally_weighted_cca_sim_x = truncated_corr_x.mean()\n",
    "    equally_weighted_cca_sim_y = truncated_corr_y.mean()\n",
    "    \n",
    "    truncated_cca_image_x = cca_image_x[:min_numxy]\n",
    "    truncated_cca_image_y = cca_image_y[:min_numxy]\n",
    "\n",
    "    # check\n",
    "    orthonorm_cca_image_x = gs_orthonormalize(truncated_cca_image_x)\n",
    "    orthonorm_cca_image_y = gs_orthonormalize(truncated_cca_image_y)\n",
    "\n",
    "    projection_weights_x = np.abs(orthonorm_cca_image_x.dot(x.T)).sum(1)\n",
    "    projection_weights_x /= projection_weights_x.sum()\n",
    "    projection_weighted_cca_sim_x = (projection_weights_x*truncated_corr_x).sum() # dist = 1 - sim\n",
    "\n",
    "    projection_weights_y = np.abs(orthonorm_cca_image_y.dot(y.T)).sum(1)\n",
    "    projection_weights_y /= projection_weights_y.sum()\n",
    "    projection_weighted_cca_sim_y = (projection_weights_y*truncated_corr_y).sum() # dist = 1 - sim\n",
    "    \n",
    "    output_dicts = {}\n",
    "    output_dicts['cca_corr_x'] = cca_corr_x\n",
    "    output_dicts['cca_corr_y'] = cca_corr_y\n",
    "    output_dicts['cca_pos_x'] = cca_pos_x\n",
    "    output_dicts['cca_pos_y'] = cca_pos_y\n",
    "    output_dicts['cca_image_x'] = cca_image_x\n",
    "    output_dicts['cca_image_y'] = cca_image_y\n",
    "    output_dicts['ewcca_sim_x'] = equally_weighted_cca_sim_x\n",
    "    output_dicts['ewcca_sim_y'] = equally_weighted_cca_sim_y\n",
    "    output_dicts['pwcca_sim_x'] = projection_weighted_cca_sim_x\n",
    "    output_dicts['pwcca_sim_y'] = projection_weighted_cca_sim_y\n",
    "\n",
    "    return output_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the K most frequent words\n",
    "state_space_spec_small = state_space_spec.keep_top_k(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep at most N instances per word\n",
    "state_space_spec_small = state_space_spec_small.subsample_instances(n, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = prepare_state_trajectory(model_representations, state_space_spec_small, pad=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cca(trajectory, state_space_spec, agg_method, cv=5):\n",
    "    \"\"\"\n",
    "    Evaluate CCA alignment between model representations and one-hot word embeddings.\n",
    "    \"\"\"\n",
    "    if agg_method is not None:\n",
    "        trajectory_agg = aggregate_state_trajectory(trajectory, state_space_spec, agg_method, keepdims=True)\n",
    "    else:\n",
    "        trajectory_agg = trajectory\n",
    "    flat_traj, flat_traj_src = flatten_trajectory(trajectory_agg)\n",
    "\n",
    "    # Z-score\n",
    "    flat_traj = (flat_traj - flat_traj.mean(0)) / flat_traj.std(0)\n",
    "\n",
    "    # Target values\n",
    "    Y = np.zeros((len(flat_traj), k), dtype=int)\n",
    "    Y[np.arange(len(flat_traj)), flat_traj_src[:, 0]] = 1\n",
    "\n",
    "    cv = KFold(cv, shuffle=True) if isinstance(cv, int) else cv\n",
    "    # NB here \"frame\" depends on the aggregation method; this may correspond to a model frame,\n",
    "    # phoneme, syllable, etc.\n",
    "    max_num_frames = flat_traj_src[:, 2].max() + 1\n",
    "\n",
    "    # store the images of all instances in the aligned space\n",
    "    # keys are (frame_idx, fold_idx)\n",
    "    cca_images = {}\n",
    "    cca_scores = np.zeros((max_num_frames, cv.get_n_splits(), 4)) * np.nan\n",
    "    for frame_idx in trange(max_num_frames, desc=\"Estimating CCA\", unit=\"frame\"):\n",
    "        sample_idxs = np.where(flat_traj_src[:, 2] == frame_idx)[0]\n",
    "        if len(sample_idxs) / cv.get_n_splits() < flat_traj.shape[1]:\n",
    "            # Not enough samples\n",
    "            continue\n",
    "\n",
    "        for fold_idx, (train_idxs, test_idxs) in enumerate(cv.split(sample_idxs)):\n",
    "            x_src = flat_traj_src[sample_idxs[train_idxs]]\n",
    "            x, y = flat_traj[sample_idxs[train_idxs]].T, Y[sample_idxs[train_idxs]].T\n",
    "            cca = solve_cca(x, y)\n",
    "            cca_scores[frame_idx, fold_idx, 0] = cca[\"pwcca_sim_x\"]\n",
    "            cca_scores[frame_idx, fold_idx, 1] = cca[\"pwcca_sim_y\"]\n",
    "            cca_scores[frame_idx, fold_idx, 2] = cca[\"ewcca_sim_x\"]\n",
    "            cca_scores[frame_idx, fold_idx, 3] = cca[\"ewcca_sim_y\"]\n",
    "\n",
    "            cca_images[frame_idx, fold_idx] = cca[\"cca_pos_x\"] @ flat_traj.T\n",
    "\n",
    "    cca_scores_df = ndarray_to_long_dataframe(cca_scores, [\"frame_idx\", \"fold_idx\", \"measure\"]).reset_index()\n",
    "    cca_scores_df[\"measure\"] = cca_scores_df[\"measure\"].map({0: \"pw_x\", 1: \"pw_y\", 2: \"ew_x\", 3: \"ew_y\"})\n",
    "\n",
    "    return flat_traj, flat_traj_src, cca_scores_df, cca_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, agg_spec in tqdm(agg_methods.items(), unit=\"method\"):\n",
    "    flat_traj, flat_traj_src, cca_scores_df, cca_images = evaluate_cca(trajectory, state_space_spec_small, agg_spec, cv=5)\n",
    "    cca_scores_df.to_csv(f\"{output_dir}/cca_scores-{name}.csv\", index=False)\n",
    "    with open(f\"{output_dir}/cca_images-{name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(cca_images, f)\n",
    "\n",
    "    max_num_frames = cca_scores_df.dropna()[\"frame_idx\"].max() + 1\n",
    "    min_value = min(0.5, cca_scores_df[\"value\"].min())\n",
    "    max_value = cca_scores_df[\"value\"].max()\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(12, 6))\n",
    "    if max_num_frames > 1:\n",
    "        sns.lineplot(data=cca_scores_df, x=\"frame_idx\", y=\"value\", hue=\"measure\", ax=ax)\n",
    "        ax.set_title(f\"CCA alignment scores (aggregation: {name})\")\n",
    "        ax.set_xlabel(\"Frame index\")\n",
    "        ax.set_ylim((min_value, max_value))\n",
    "    else:\n",
    "        sns.barplot(data=cca_scores_df, x=\"measure\", y=\"value\", ax=ax)\n",
    "        ax.set_title(f\"CCA alignment scores ({name})\")\n",
    "        ax.set_ylim((min_value, max_value))\n",
    "    f.savefig(Path(output_dir) / f\"cca_scores-{name}.png\")\n",
    "\n",
    "    # plot PCA of resulting image space for a spectrum of frames\n",
    "    num_plots = 5\n",
    "    # pick a random fold\n",
    "    fold_idx = np.random.randint(cca_scores_df.dropna().fold_idx.max())\n",
    "    # pick random words to sample\n",
    "    plot_sample_idxs = np.random.choice(len(flat_traj), min(100, len(flat_traj)), replace=False)\n",
    "    frame_points = np.unique(np.linspace(0, max_num_frames - 1, num_plots, dtype=int))\n",
    "\n",
    "    for frame_idx in frame_points:\n",
    "        cca_image_i = cca_images[frame_idx, fold_idx]\n",
    "        pca = PCA(2).fit(cca_image_i.T)\n",
    "\n",
    "        plot_points = pca.transform(cca_image_i[:, plot_sample_idxs].T)\n",
    "        plot_label_idxs = flat_traj_src[plot_sample_idxs, 0]\n",
    "        \n",
    "        f, ax = plt.subplots(figsize=(12, 12))\n",
    "        ax.scatter(*plot_points.T)\n",
    "        ax.set_title(f\"PCA of CCA image space (aggregation: {name}, frame {frame_idx})\")\n",
    "        for i, label_idx in enumerate(plot_label_idxs):\n",
    "            ax.text(*plot_points[i], state_space_spec.labels[label_idx], fontsize=8)\n",
    "\n",
    "        f.savefig(Path(output_dir) / f\"pca_image-{name}-frame{frame_idx}.png\")\n",
    "\n",
    "plt.close(\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import replace\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.analysis import coherence\n",
    "from src.analysis.state_space import prepare_state_trajectory, StateSpaceAnalysisSpec\n",
    "from src.datasets.speech_equivalence import SpeechEquivalenceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model_dir = \"outputs/models/timit/w2v2_6/rnn_8/phoneme\"\n",
    "output_dir = \"outputs/notebooks/timit/w2v2_6/rnn_8/phoneme/plot\"\n",
    "dataset_path = \"outputs/preprocessed_data/timit\"\n",
    "equivalence_path = \"outputs/equivalence_datasets/timit/w2v2_6/phoneme/equivalence.pkl\"\n",
    "hidden_states_path = \"outputs/hidden_states/timit/w2v2_6/hidden_states.h5\"\n",
    "state_space_specs_path = \"outputs/state_space_specs/timit/w2v2_6/state_space_specs.pkl\"\n",
    "embeddings_path = \"outputs/model_embeddings/timit/w2v2_6/rnn_8/phoneme/embeddings.npy\"\n",
    "\n",
    "output_dir = \".\"\n",
    "\n",
    "metric = \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(embeddings_path, \"rb\") as f:\n",
    "    model_representations: np.ndarray = np.load(f)\n",
    "with open(equivalence_path, \"rb\") as f:\n",
    "    equiv_dataset: SpeechEquivalenceDataset = torch.load(f)\n",
    "with open(state_space_specs_path, \"rb\") as f:\n",
    "    state_space_spec: StateSpaceAnalysisSpec = torch.load(f)[\"syllable_by_identity_and_ordinal\"]\n",
    "assert state_space_spec.is_compatible_with(model_representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for well-attested syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build representation of all syllable identities/positions\n",
    "all_syllables = sorted(set(syllable for syllable, position in state_space_spec.labels))\n",
    "all_positions = sorted(set(position for syllable, position in state_space_spec.labels))\n",
    "syllable_mat = np.zeros((len(all_syllables), len(all_positions)), dtype=int)\n",
    "for i, (syllable, position) in enumerate(state_space_spec.labels):\n",
    "    syllable_mat[all_syllables.index(syllable), all_positions.index(position)] = \\\n",
    "        len(state_space_spec.target_frame_spans[i])\n",
    "syllable_df = pd.DataFrame(syllable_mat, index=all_syllables, columns=all_positions)\n",
    "syllable_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find syllables which appear in every ordinal position at least twice up to `min_number_positions`\n",
    "min_number_positions = 3\n",
    "syllable_max_position = (syllable_df >= 2).idxmin(axis=1)\n",
    "match_syllables = syllable_max_position.loc[syllable_max_position >= min_number_positions].index.tolist()\n",
    "len(match_syllables), match_syllables[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=syllable_df.loc[match_syllables, :min_number_positions] \\\n",
    "                    .melt(var_name=\"ordinal_position\", value_name=\"frequency\"),\n",
    "            x=\"ordinal_position\", y=\"frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retain_labels = [(syllable, ordinal) for syllable in match_syllables\n",
    "                 for ordinal in range(min_number_positions)]\n",
    "drop_idxs = [idx for idx, label in enumerate(state_space_spec.labels)\n",
    "             if label not in retain_labels]\n",
    "state_space_spec = state_space_spec.drop_labels(drop_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_label_strs = [f\"{' '.join(phones)} {ordinal}\" for phones, ordinal in state_space_spec.labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = prepare_state_trajectory(model_representations, state_space_spec, pad=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [np.isnan(traj_i[:, :, 0]).argmax(axis=1) for traj_i in trajectory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate within-syllable, within-position distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_distance, within_distance_offset = \\\n",
    "    coherence.estimate_within_distance(trajectory, lengths, state_space_spec, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(within_distance, center=1, cmap=\"RdBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_distance_df = pd.DataFrame(within_distance, index=pd.Index(spec_label_strs, name=\"syllable\")) \\\n",
    "    .reset_index() \\\n",
    "    .melt(id_vars=[\"syllable\"], var_name=\"frame\", value_name=\"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_distance_offset_df = pd.DataFrame(within_distance_offset, index=pd.Index(spec_label_strs, name=\"syllable\")) \\\n",
    "    .reset_index() \\\n",
    "    .melt(id_vars=[\"syllable\"], var_name=\"frame\", value_name=\"distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate within-syllable, between-position distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "between1_samples = [[state_space_spec.labels.index((syllable_i, ordinal_j))\n",
    "                     for ordinal_j in range(min_number_positions)\n",
    "                     if ordinal_j != ordinal_i]\n",
    "                    for syllable_i, ordinal_i in state_space_spec.labels]\n",
    "\n",
    "between1_distance, between1_distance_offset = \\\n",
    "    coherence.estimate_between_distance(trajectory, lengths, state_space_spec,\n",
    "                                        between_samples=between1_samples,\n",
    "                                        metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "between1_distance_df = pd.DataFrame(np.nanmean(between1_distance, axis=-1),\n",
    "                                    index=pd.Index(spec_label_strs, name=\"syllable\")) \\\n",
    "    .reset_index() \\\n",
    "    .melt(id_vars=[\"syllable\"], var_name=\"frame\", value_name=\"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "between1_distance_offset_df = pd.DataFrame(np.nanmean(between1_distance_offset, axis=-1),\n",
    "                                     index=pd.Index(spec_label_strs, name=\"syllable\")) \\\n",
    "    .reset_index() \\\n",
    "    .melt(id_vars=[\"syllable\"], var_name=\"frame\", value_name=\"distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate between-syllable distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the number of between-samples with the earlier analysis\n",
    "num_samples = min_number_positions\n",
    "\n",
    "between_distance, between_distance_offset = \\\n",
    "    coherence.estimate_between_distance(trajectory, lengths, state_space_spec,\n",
    "                                        num_samples=num_samples, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "between_distance_df = pd.DataFrame(np.nanmean(between_distance, axis=-1),\n",
    "                                    index=pd.Index(spec_label_strs, name=\"syllable\")) \\\n",
    "    .reset_index() \\\n",
    "    .melt(id_vars=[\"syllable\"], var_name=\"frame\", value_name=\"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "between_distance_offset_df = pd.DataFrame(np.nanmean(between_distance_offset, axis=-1),\n",
    "                                          index=pd.Index(spec_label_strs, name=\"syllable\")) \\\n",
    "    .reset_index() \\\n",
    "    .melt(id_vars=[\"syllable\"], var_name=\"frame\", value_name=\"distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([within_distance_df.assign(type=\"within\"),\n",
    "                       between1_distance_df.assign(type=\"different_position\"),\n",
    "                       between_distance_df.assign(type=\"between\")])\n",
    "merged_df.to_csv(Path(output_dir) / \"distances.csv\", index=False)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=merged_df.dropna().replace({\"type\": {\"within\": \"Same identity, same position\",\n",
    "                                                            \"different_position\": \"Same identity, different position\",\n",
    "                                                            \"between\": \"Different identity, different position\"}}),\n",
    "                  x=\"frame\", y=\"distance\", hue=\"type\")\n",
    "ax.set_title(\"Representational distance within- and between-syllable\")\n",
    "ax.set_xlabel(\"Frames since syllable onset\")\n",
    "ax.set_ylabel(f\"{metric.capitalize()} distance\")\n",
    "ax.set_xlim((0, np.percentile(np.concatenate(lengths), 95)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_offset_df = pd.concat([within_distance_offset_df.assign(type=\"within\"),\n",
    "                              between_distance_offset_df.assign(type=\"between\"),\n",
    "                              between1_distance_offset_df.assign(type=\"different_position\")])\n",
    "merged_offset_df.to_csv(Path(output_dir) / \"distances_aligned_offset.csv\", index=False)\n",
    "merged_offset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=merged_offset_df.dropna().replace({\"type\": {\"within\": \"Same identity, same position\",\n",
    "                                                            \"different_position\": \"Same identity, different position\",\n",
    "                                                            \"between\": \"Different identity, different position\"}}),\n",
    "                  x=\"frame\", y=\"distance\", hue=\"type\")\n",
    "ax.set_title(\"Representational distance within- and between-syllable\")\n",
    "ax.set_xlabel(\"Frames before syllable offset\")\n",
    "ax.set_ylabel(f\"{metric.capitalize()} distance\")\n",
    "ax.set_xlim((0, np.percentile(np.concatenate(lengths), 95)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

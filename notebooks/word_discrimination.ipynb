{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.analysis.state_space import StateSpaceAnalysisSpec, \\\n",
    "    prepare_state_trajectory, aggregate_state_trajectory, flatten_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = \"librispeech-train-clean-100\"\n",
    "state_space_name = \"word\"\n",
    "\n",
    "# base_model = \"w2v2_6\"\n",
    "# model_class = \"rnn_8-weightdecay0.01\"\n",
    "# model_name = \"biphone_recon\"\n",
    "\n",
    "base_model = \"w2v2_8\"\n",
    "model_class = \"rnn_32-hinge-mAP4\"\n",
    "model_name = \"word_broad\"\n",
    "\n",
    "model_dir = f\"outputs/models/{dataset}/{base_model}/{model_class}/{model_name}_10frames\"\n",
    "output_dir = f\"outputs/notebooks/{dataset}/{base_model}/{model_class}/{model_name}_10frames/state_space\"\n",
    "dataset_path = f\"outputs/preprocessed_data/{dataset}\"\n",
    "equivalence_path = f\"outputs/equivalence_datasets/{dataset}/{base_model}/{model_name}_10frames/equivalence.pkl\"\n",
    "hidden_states_path = f\"outputs/hidden_states/{dataset}/{base_model}/hidden_states.h5\"\n",
    "state_space_specs_path = f\"outputs/state_space_specs/{dataset}/{base_model}/state_space_specs.pkl\"\n",
    "embeddings_path = f\"outputs/model_embeddings/{dataset}/{base_model}/{model_class}/{model_name}_10frames/{dataset}.npy\"\n",
    "\n",
    "metric = \"cosine\"\n",
    "\n",
    "# name -> (agg_spec, length_grouping_level)\n",
    "# CCA will be estimated and evaluated on words within length groups; the unit of this length count\n",
    "# is determined by `length_grouping_level`. This is because it makes more sense to talk about syllable-by-syllable\n",
    "# representation within words matched in syllable count.\n",
    "# The `length_grouping_level` should correspond to a `level` in the state space spec cuts.\n",
    "agg_methods = {\n",
    "    \"mean_within_phoneme\": ((\"mean_within_cut\", \"phoneme\"), \"phoneme\"),\n",
    "    # \"mean_within_syllable\": ((\"mean_within_cut\", \"syllable\"), \"syllable\"),\n",
    "    # \"mean\": (\"mean\", \"phoneme\"),\n",
    "    # \"last_frame\": (\"last_frame\", \"phoneme\"),\n",
    "    # \"max\": (\"max\", \"phoneme\"),\n",
    "    # \"none\": (None, \"phoneme\"),\n",
    "}\n",
    "\n",
    "# keep K most frequent words\n",
    "freq_top_k = 2000\n",
    "\n",
    "# keep at most `max_instances_per_label`\n",
    "max_instances_per_label = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO get a measure of random chance\n",
    "# TODO record prediction performance on *all* words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(embeddings_path, \"rb\") as f:\n",
    "    model_representations: np.ndarray = np.load(f)\n",
    "with open(state_space_specs_path, \"rb\") as f:\n",
    "    state_space_spec: StateSpaceAnalysisSpec = torch.load(f)[state_space_name]\n",
    "assert state_space_spec.is_compatible_with(model_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space_spec = state_space_spec.keep_top_k(freq_top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space_spec = state_space_spec.subsample_instances(max_instances_per_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = prepare_state_trajectory(\n",
    "    model_representations,\n",
    "    state_space_spec,\n",
    "    pad=np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_method = agg_methods[\"mean_within_phoneme\"][0]\n",
    "agg_traj = aggregate_state_trajectory(trajectory, state_space_spec, agg_method, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_traj, flat_traj_src = flatten_trajectory(agg_traj)\n",
    "max_num_frames = flat_traj_src[:, 2].max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_average_precision(embeddings: np.ndarray, classes: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    estimate classification performance by learning a classifier and calculating mean\n",
    "    average precision\n",
    "\n",
    "    Returns:\n",
    "    - n_folds array: mAP scores for each fold\n",
    "    - n_examples * n_classes array: predicted classes for each example (corresponding to integer\n",
    "      values of `classes`; not indices)\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "    scores = []\n",
    "\n",
    "    X = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    Y = LabelBinarizer().fit_transform(classes)\n",
    "\n",
    "    Y_pred = np.zeros_like(classes)\n",
    "    Y_pred_proba = np.zeros_like(Y, dtype=float)\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X, classes):\n",
    "        clf = LogisticRegression(max_iter=1000)\n",
    "        try:\n",
    "            clf.fit(X[train_idx], classes[train_idx])\n",
    "        except ValueError as e:\n",
    "            # fitting error -- this may be due to e.g. degenerate training set\n",
    "            L.error(f\"Error fitting classifier: {e}\")\n",
    "            scores.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # compute multi-class mAP\n",
    "        Y_pred_f = clf.predict_proba(X[test_idx])\n",
    "        if Y_pred_f.shape[1] == 2:\n",
    "            Y_pred_f = Y_pred_f[:, 1] # binary casex\n",
    "\n",
    "        scores.append(average_precision_score(Y[test_idx], Y_pred_f, average=\"macro\"))\n",
    "        Y_pred_proba[test_idx] = Y_pred_f\n",
    "        Y_pred[test_idx] = clf.predict(X[test_idx])\n",
    "\n",
    "    return np.array(scores), Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_scores: for each frame position, store the mAP scores across folds\n",
    "# traj_idxs: for each frame position, store the trajectory indices used for estimating mAP\n",
    "# Y_pred: for each frame position, store the predicted probabilities\n",
    "map_scores, traj_srcs, Y_pred = [], [], []\n",
    "for num_frames in range(max_num_frames):\n",
    "    print(f\"Computing mAP for {num_frames + 1} frames\")\n",
    "    traj_idxs_i = (flat_traj_src[:, 2] == num_frames).nonzero()[0]\n",
    "    traj_srcs.append(flat_traj_src[traj_idxs_i])\n",
    "    X_i = flat_traj[traj_idxs_i]\n",
    "    Y_i = flat_traj_src[traj_idxs_i, 0]\n",
    "\n",
    "    print(X_i.shape, Y_i.shape)\n",
    "    map_scores_i, Y_pred_i = compute_mean_average_precision(X_i, Y_i)\n",
    "    print(f\"Mean average precision at {num_frames}: {np.nanmean(map_scores_i)}\")\n",
    "    map_scores.append(map_scores_i)\n",
    "    Y_pred.append(Y_pred_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_scores_df = pd.DataFrame(map_scores, index=pd.RangeIndex(1, len(map_scores) + 1, name=\"num_frames\")) \\\n",
    "    .reset_index().melt(id_vars=[\"num_frames\"], var_name=\"fold\", value_name=\"mAP\")\n",
    "map_scores_df.to_csv(Path(output_dir) / \"map_scores.csv\", index=False)\n",
    "map_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=map_scores_df, x=\"num_frames\", y=\"mAP\")\n",
    "ax.set_ylim((0.0, 1.0))\n",
    "ax.axhline(1 / len(state_space_spec.labels), color=\"gray\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = []\n",
    "for traj_src_i, Y_pred_i in zip(traj_srcs, Y_pred):\n",
    "    predictions_df.append(pd.DataFrame({\n",
    "        \"label_idx\": traj_src_i[:, 0],\n",
    "        \"instance_idx\": traj_src_i[:, 1],\n",
    "        \"predicted_label_idx\": Y_pred_i,\n",
    "    }))\n",
    "predictions_df = pd.concat(dict(enumerate(predictions_df)), names=[\"frame_idx\"]).droplevel(-1)\n",
    "predictions_df[\"label\"] = predictions_df.label_idx.map(dict(enumerate(state_space_spec.labels)))\n",
    "predictions_df[\"predicted_label\"] = predictions_df.predicted_label_idx.map(dict(enumerate(state_space_spec.labels)))\n",
    "predictions_df[\"correct\"] = predictions_df.label == predictions_df.predicted_label\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.groupby([\"label\", \"frame_idx\"]).correct.mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv(Path(output_dir) / \"predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

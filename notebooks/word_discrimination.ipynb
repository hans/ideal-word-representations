{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.analysis.state_space import StateSpaceAnalysisSpec, \\\n",
    "    prepare_state_trajectory, aggregate_state_trajectory, flatten_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"librispeech-train-clean-100\"\n",
    "state_space_name = \"word\"\n",
    "\n",
    "# base_model = \"w2v2_6\"\n",
    "# model_class = \"rnn_8-weightdecay0.01\"\n",
    "# model_name = \"biphone_recon\"\n",
    "\n",
    "base_model = \"w2v2_8\"\n",
    "model_class = \"rnn_32-hinge-mAP4\"\n",
    "model_name = \"word_broad\"\n",
    "\n",
    "model_dir = f\"outputs/models/{dataset}/{base_model}/{model_class}/{model_name}_10frames\"\n",
    "output_dir = f\"outputs/notebooks/{dataset}/{base_model}/{model_class}/{model_name}_10frames/state_space\"\n",
    "dataset_path = f\"outputs/preprocessed_data/{dataset}\"\n",
    "equivalence_path = f\"outputs/equivalence_datasets/{dataset}/{base_model}/{model_name}_10frames/equivalence.pkl\"\n",
    "hidden_states_path = f\"outputs/hidden_states/{dataset}/{base_model}/hidden_states.h5\"\n",
    "state_space_specs_path = f\"outputs/state_space_specs/{dataset}/{base_model}/state_space_specs.pkl\"\n",
    "embeddings_path = f\"outputs/model_embeddings/{dataset}/{base_model}/{model_class}/{model_name}_10frames/{dataset}.npy\"\n",
    "\n",
    "metric = \"cosine\"\n",
    "\n",
    "# name -> (agg_spec, length_grouping_level)\n",
    "# CCA will be estimated and evaluated on words within length groups; the unit of this length count\n",
    "# is determined by `length_grouping_level`. This is because it makes more sense to talk about syllable-by-syllable\n",
    "# representation within words matched in syllable count.\n",
    "# The `length_grouping_level` should correspond to a `level` in the state space spec cuts.\n",
    "agg_methods = {\n",
    "    \"mean_within_phoneme\": ((\"mean_within_cut\", \"phoneme\"), \"phoneme\"),\n",
    "    # \"mean_within_syllable\": ((\"mean_within_cut\", \"syllable\"), \"syllable\"),\n",
    "    # \"mean\": (\"mean\", \"phoneme\"),\n",
    "    # \"last_frame\": (\"last_frame\", \"phoneme\"),\n",
    "    # \"max\": (\"max\", \"phoneme\"),\n",
    "    # \"none\": (None, \"phoneme\"),\n",
    "}\n",
    "\n",
    "# keep K most frequent words\n",
    "freq_top_k = 1000\n",
    "\n",
    "# keep at most `max_instances_per_label`\n",
    "max_instances_per_label = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(embeddings_path, \"rb\") as f:\n",
    "    model_representations: np.ndarray = np.load(f)\n",
    "with open(state_space_specs_path, \"rb\") as f:\n",
    "    state_space_spec: StateSpaceAnalysisSpec = torch.load(f)[state_space_name]\n",
    "assert state_space_spec.is_compatible_with(model_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space_spec = state_space_spec.keep_top_k(freq_top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space_spec = state_space_spec.subsample_instances(max_instances_per_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = prepare_state_trajectory(\n",
    "    model_representations,\n",
    "    state_space_spec,\n",
    "    pad=np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_method = agg_methods[\"mean_within_phoneme\"][0]\n",
    "agg_traj = aggregate_state_trajectory(trajectory, state_space_spec, agg_method, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_traj, flat_traj_src = flatten_trajectory(agg_traj)\n",
    "max_num_frames = flat_traj_src[:, 2].max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_average_precision(embeddings: np.ndarray, classes: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    estimate classification performance by learning a classifier and calculating mean\n",
    "    average precision\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "    scores = []\n",
    "\n",
    "    X = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    Y = LabelBinarizer().fit_transform(classes)\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X, classes):\n",
    "        clf = LogisticRegression(max_iter=1000)\n",
    "        clf.fit(X[train_idx], classes[train_idx])\n",
    "        # compute multi-class mAP\n",
    "        Y_pred = clf.predict_proba(X[test_idx])\n",
    "        if Y_pred.shape[1] == 2:\n",
    "            Y_pred = Y_pred[:, 1] # binary casex\n",
    "        scores.append(average_precision_score(Y[test_idx], Y_pred, average=\"macro\"))\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_scores = []\n",
    "for num_frames in range(max_num_frames):\n",
    "    print(f\"Computing mAP for {num_frames + 1} frames\")\n",
    "    traj_idxs = (flat_traj_src[:, 2] == num_frames).nonzero()[0]\n",
    "    X = flat_traj[traj_idxs]\n",
    "    Y = flat_traj_src[traj_idxs, 0]\n",
    "\n",
    "    print(X.shape, Y.shape)\n",
    "    map_scores_i = compute_mean_average_precision(X, Y)\n",
    "    print(f\"Mean average precision at {num_frames}: {map_scores_i.mean()}\")\n",
    "    map_scores.append(map_scores_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_scores_df = pd.DataFrame(map_scores, index=pd.RangeIndex(1, len(map_scores) + 1, name=\"num_frames\")) \\\n",
    "    .reset_index().melt(id_vars=[\"num_frames\"], var_name=\"fold\", value_name=\"mAP\")\n",
    "map_scores_df.to_csv(Path(output_dir) / \"map_scores.csv\", index=False)\n",
    "map_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=map_scores_df, x=\"num_frames\", y=\"mAP\")\n",
    "ax.set_ylim((0.0, 1.0))\n",
    "ax.axhline(1 / len(state_space_spec.labels), color=\"gray\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

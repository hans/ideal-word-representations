{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from typing import Any\n",
    "\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.decoding import ReceptiveField\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from src.analysis.trf import estimate_trf_cv\n",
    "from src.models import get_best_checkpoint\n",
    "from src.models.integrator import ContrastiveEmbeddingModel, load_or_compute_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(context='talk', style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model_dir = \"outputs/models/w2v2_6_8/phoneme\"\n",
    "# model_checkpoint = \"out/ce_model_phoneme_6_8/checkpoint-800\"\n",
    "# use a word-level equivalence dataset regardless of model, so that we can look up cohort facts\n",
    "equiv_dataset_path = \"data/timit_equivalence_facebook-wav2vec2-base_6-phoneme-1.pkl\"\n",
    "timit_corpus_path = \"data/timit_syllables\"\n",
    "\n",
    "output_dir = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ContrastiveEmbeddingModel.from_pretrained(get_best_checkpoint(model_dir))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(equiv_dataset_path, \"rb\") as f:\n",
    "    equiv_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_by_item = equiv_dataset.hidden_state_dataset.frames_by_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_representations = load_or_compute_embeddings(model, equiv_dataset, model_dir, equiv_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit_corpus = datasets.load_from_disk(timit_corpus_path)[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_item(item_idx, ax, plot_dims=None):\n",
    "    item = timit_corpus[item_idx]\n",
    "    start_frame, end_frame = frames_by_item[item_idx]\n",
    "    compression_ratio = (end_frame - start_frame) / len(item[\"input_values\"])\n",
    "\n",
    "    times = np.linspace(0, len(item[\"input_values\"]) / 16000, int(len(item[\"input_values\"]) / 16000 * 1000))\n",
    "    ax.plot(times, np.interp(times, np.arange(len(item[\"input_values\"])) / 16000,\n",
    "                            item[\"input_values\"]),\n",
    "            alpha=0.2)\n",
    "\n",
    "    # plot word and phoneme boundaries\n",
    "    for i, word in enumerate(item[\"word_phonemic_detail\"]):\n",
    "        word_str = item[\"word_detail\"][\"utterance\"][i]\n",
    "\n",
    "        word_start, word_stop = word[0][\"start\"] / 16000, word[-1][\"stop\"] / 16000\n",
    "        ax.axvline(word_start, color=\"black\", linestyle=\"--\")\n",
    "        ax.text(word_start, -5, word_str, rotation=90, verticalalignment=\"top\", alpha=0.7)\n",
    "\n",
    "        for j, phoneme in enumerate(word):\n",
    "            phoneme_str = phoneme[\"phone\"]\n",
    "            phoneme_start, phoneme_stop = phoneme[\"start\"] / 16000, phoneme[\"stop\"] / 16000\n",
    "\n",
    "            if j > 0:\n",
    "                color = \"black\" if phoneme[\"idx_in_syllable\"] == 0 else \"gray\"\n",
    "                ax.axvline(phoneme_start, color=color, linestyle=\":\", alpha=0.5)\n",
    "            # ax.text(phoneme_start + 0.01, -5, phoneme_str, rotation=90, verticalalignment=\"bottom\", fontdict={\"size\": 8})\n",
    "\n",
    "    model_ax = ax.twinx()\n",
    "    if plot_dims is None:\n",
    "        plot_dims = list(range(model_representations.shape[1]))\n",
    "    for dim in plot_dims:\n",
    "        model_ax.plot(times, np.interp(times, np.arange(0, end_frame - start_frame) / compression_ratio / 16000,\n",
    "                                model_representations[start_frame:end_frame, dim]),\n",
    "                label=f\"Model dimension {dim + 1}\")\n",
    "\n",
    "    # align at origin\n",
    "    ax.set_ylim((-8, 8))\n",
    "    model_ax.set_ylim((-2, 2))\n",
    "    model_ax.legend()\n",
    "\n",
    "    ax.set_title(f\"{item['speaker_id']}_{item['id']}: {item['text']}\")\n",
    "    ax.set_yticks([])\n",
    "    model_ax.set_yticks([])\n",
    "    ax.grid(False)\n",
    "    model_ax.grid(False)\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_items = [18]\n",
    "f, axs = plt.subplots(len(plot_items), 1, figsize=(18, 8 * len(plot_items)))\n",
    "for item_idx, ax in zip(plot_items, axs if isinstance(axs, list) else [axs]):\n",
    "    plot_item(item_idx, ax, plot_dims=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot single word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lookup = \"act\"\n",
    "matches = []\n",
    "\n",
    "def find_word(item, idx):\n",
    "    if word_lookup in item[\"word_detail\"][\"utterance\"]:\n",
    "        matches.append((idx, item[\"word_detail\"][\"utterance\"].index(word_lookup)))\n",
    "\n",
    "timit_corpus.map(find_word, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_word_in_item(item_idx, word_idx, ax, annot=True, text=True):\n",
    "    item = timit_corpus[item_idx]\n",
    "    start_frame, end_frame = frames_by_item[item_idx]\n",
    "    compression_ratio = (end_frame - start_frame) / len(item[\"input_values\"])\n",
    "\n",
    "    word_start_sample, word_end_sample = item[\"word_detail\"][\"start\"][word_idx], item[\"word_detail\"][\"stop\"][word_idx]\n",
    "    word_start, word_end = item[\"word_detail\"][\"start\"][word_idx] / 16000, item[\"word_detail\"][\"stop\"][word_idx] / 16000\n",
    "\n",
    "    times = np.linspace(word_start, word_end, int((word_end - word_start) * 16000))\n",
    "    audio_samples = np.arange(word_start_sample, word_end_sample)\n",
    "\n",
    "    # Normalize audio samples to [-1, 1]\n",
    "    values = np.array(item[\"input_values\"][word_start_sample:word_end_sample])\n",
    "    values = (values - values.min()) / (values.max() - values.min()) * 2 - 1\n",
    "\n",
    "    ax.plot(times, np.interp(times, audio_samples / 16000, values),\n",
    "            alpha=0.3)\n",
    "\n",
    "    ax.set_xlim((word_start, word_end))\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    if annot:\n",
    "        for j, phoneme in enumerate(item[\"word_phonemic_detail\"][word_idx]):\n",
    "            phoneme_str = phoneme[\"phone\"]\n",
    "            phoneme_start, phoneme_stop = phoneme[\"start\"] / 16000, phoneme[\"stop\"] / 16000\n",
    "\n",
    "            color = \"black\" if phoneme[\"idx_in_syllable\"] == 0 else \"gray\"\n",
    "            ax.axvline(phoneme_start, color=color, linestyle=\":\")\n",
    "\n",
    "            if text:\n",
    "                ax.text(phoneme_start + 0.01, 0, phoneme_str, verticalalignment=\"bottom\", fontdict={\"size\": 15, \"weight\": \"bold\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(18, 4))\n",
    "plot_word_in_item(*matches[0], ax, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_plots = [\n",
    "    (143, 0), # positive\n",
    "    (206, 5), # popularity\n",
    "    (253, 9), # impossible\n",
    "    (4442, 8), # employee\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(len(manual_plots), 1, figsize=(18, 4 * len(manual_plots)))\n",
    "if len(manual_plots) == 1:\n",
    "    axs = [axs]\n",
    "for (item_idx, word_idx), ax in zip(manual_plots, axs):\n",
    "    plot_word_in_item(item_idx, word_idx, ax, annot=True, text=True)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_ylim((-1.1, 1.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(matches) > 18:\n",
    "    matches = [matches[idx] for idx in np.random.choice(len(matches), 18, replace=False)]\n",
    "\n",
    "f, axs = plt.subplots(len(matches), 1, figsize=(18, 4 * len(matches)))\n",
    "if len(matches) == 1:\n",
    "    axs = [axs]\n",
    "for (item_idx, word_idx), ax in zip(matches, axs):\n",
    "    plot_word_in_item(item_idx, word_idx, ax, annot=False)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_ylim((-1.1, 1.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot single syllable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable_lookup = (\"IH\", \"M\")\n",
    "matched_syllables = []\n",
    "matched_words = []\n",
    "\n",
    "def find_syllable(item, idx):\n",
    "    for word_idx, sylls in enumerate(item[\"word_syllable_detail\"]):\n",
    "        for syll_idx, syll in enumerate(sylls):\n",
    "            if tuple(syll[\"phones\"]) == syllable_lookup:\n",
    "                if item[\"word_detail\"][\"utterance\"][word_idx] in matched_words:\n",
    "                    continue\n",
    "                matched_syllables.append((idx, word_idx, syll_idx))\n",
    "                matched_words.append(item[\"word_detail\"][\"utterance\"][word_idx])\n",
    "\n",
    "timit_corpus.map(find_syllable, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_syllable_in_item(item_idx, word_idx, syll_idx, ax, annot=True):\n",
    "    item = timit_corpus[item_idx]\n",
    "    start_frame, end_frame = frames_by_item[item_idx]\n",
    "    compression_ratio = (end_frame - start_frame) / len(item[\"input_values\"])\n",
    "\n",
    "    syllable = item[\"word_syllable_detail\"][word_idx][syll_idx]\n",
    "\n",
    "    syll_start_sample, syll_end_sample = syllable[\"start\"], syllable[\"stop\"]\n",
    "    syll_start, syll_end = syllable[\"start\"] / 16000, syllable[\"stop\"] / 16000\n",
    "\n",
    "    times = np.linspace(syll_start, syll_end, int((syll_end - syll_start) * 16000))\n",
    "    audio_samples = np.arange(syll_start_sample, syll_end_sample)\n",
    "\n",
    "    # Normalize audio samples to [-1, 1]\n",
    "    values = np.array(item[\"input_values\"][syll_start_sample:syll_end_sample])\n",
    "    values = (values - values.min()) / (values.max() - values.min()) * 2 - 1\n",
    "\n",
    "    ax.plot(times, np.interp(times, audio_samples / 16000, values),\n",
    "            alpha=0.3)\n",
    "\n",
    "    ax.set_xlim((syll_start, syll_end))\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    if annot:\n",
    "        for j, phoneme in enumerate(item[\"word_phonemic_detail\"][word_idx]):\n",
    "            if j >= syllable[\"phoneme_start_idx\"] and j <= syllable[\"phoneme_stop_idx\"]:\n",
    "                phoneme_str = phoneme[\"phone\"]\n",
    "                phoneme_start, phoneme_stop = phoneme[\"start\"] / 16000, phoneme[\"stop\"] / 16000\n",
    "\n",
    "                color = \"black\" if phoneme[\"idx_in_syllable\"] == 0 else \"gray\"\n",
    "                ax.axvline(phoneme_start, color=color, linestyle=\":\")\n",
    "                ax.text(phoneme_start + 0.01, 0, phoneme_str, verticalalignment=\"bottom\", fontdict={\"size\": 15, \"weight\": \"bold\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(matched_syllables) > 18:\n",
    "    matched_syllables = [matched_syllables[idx] for idx in np.random.choice(len(matched_syllables), 18, replace=False)]\n",
    "\n",
    "f, axs = plt.subplots(len(matched_syllables), 1, figsize=(8, 4 * len(matched_syllables)))\n",
    "if len(matched_syllables) == 1:\n",
    "    axs = [axs]\n",
    "for (item_idx, word_idx, syll_idx), ax in zip(matched_syllables, axs):\n",
    "    plot_syllable_in_item(item_idx, word_idx, syll_idx, ax, annot=False)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_ylim((-1.1, 1.1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

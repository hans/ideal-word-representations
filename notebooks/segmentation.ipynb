{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "test_dataset_path = \"../out/rnn/w2v2base_rnn2_hidden128_drop6/test_result\"\n",
    "model_sfreq = 50\n",
    "tokenizer_name = \"charsiu/tokenizer_en_cmu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.load_from_disk(test_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.Wav2Vec2Tokenizer.from_pretrained(tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_state_sources = []\n",
    "hidden_states = []\n",
    "for i, item in enumerate(tqdm(test_dataset)):\n",
    "    hidden_state_sources += [(i, j) for j in range(item[\"real_frames\"])]\n",
    "    hidden_states.append(np.array(item[\"rnn_hidden_states\"][:item[\"real_frames\"]]))\n",
    "\n",
    "hidden_states = np.concatenate(hidden_states, axis=0)\n",
    "assert len(hidden_state_sources) == hidden_states.shape[0]\n",
    "\n",
    "hidden_state_source_to_flat_idx = {source: i for i, source in enumerate(hidden_state_sources)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_event_names = [\"file\", \"phoneme\", \"word\"]\n",
    "boundary_event_to_idx = {event_name: i for i, event_name in enumerate(boundary_event_names)}\n",
    "boundary_matrix = np.zeros((hidden_states.shape[0], len(boundary_event_names)))\n",
    "\n",
    "def add_boundaries(item, idx, boundary_matrix, boundary_event_to_idx, hidden_state_source_to_flat_idx):\n",
    "    compression_ratio = item[\"compression_ratio\"]\n",
    "\n",
    "    file_start_idx = hidden_state_source_to_flat_idx[(idx, 0)]\n",
    "    boundary_matrix[file_start_idx, boundary_event_to_idx[\"file\"]] = 1\n",
    "\n",
    "    for word in item[\"word_phonemic_detail\"]:\n",
    "        if len(word) == 0:\n",
    "            continue\n",
    "\n",
    "        word_start = int(word[0][\"start\"] * compression_ratio)\n",
    "        word_start_idx = hidden_state_source_to_flat_idx[(idx, word_start)]\n",
    "        boundary_matrix[word_start_idx, boundary_event_to_idx[\"word\"]] = 1\n",
    "\n",
    "        for phoneme in word:\n",
    "            phoneme_start = int(phoneme[\"start\"] * compression_ratio)\n",
    "            phoneme_start_idx = hidden_state_source_to_flat_idx[(idx, phoneme_start)]\n",
    "            boundary_matrix[phoneme_start_idx, boundary_event_to_idx[\"phoneme\"]] = 1\n",
    "\n",
    "    return None\n",
    "\n",
    "test_dataset.map(add_boundaries, batched=False, with_indices=True,\n",
    "                 fn_kwargs={\"boundary_matrix\": boundary_matrix, \"boundary_event_to_idx\": boundary_event_to_idx,\n",
    "                            \"hidden_state_source_to_flat_idx\": hidden_state_source_to_flat_idx})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA decomposition and time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_pca = 4\n",
    "pca = PCA(d_pca)\n",
    "hidden_states_pca = pca.fit_transform((hidden_states - hidden_states.mean(axis=0)) / hidden_states.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.decoding import ReceptiveField\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(boundary_matrix, hidden_states_pca, shuffle=True, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf = ReceptiveField(tmin=-5, tmax=20, sfreq=1, feature_names=boundary_event_names)\n",
    "trf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(trf.coef_.shape[1], 1, figsize=(5 * trf.coef_.shape[1], 5))\n",
    "for input_dim, (name, ax) in enumerate(zip(boundary_event_names, axs.ravel())):\n",
    "    ax.set_title(name)\n",
    "    for output_dim in range(trf.coef_.shape[0]):\n",
    "        ax.plot(trf.delays_, trf.coef_[output_dim, input_dim, :], label=output_dim)\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoched analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_and_plot(epoch_event, hidden_states, boundary_matrix, epoch_window=(-5, 20), baseline_window=(-5, 0)):\n",
    "    epoch_data = []\n",
    "    target_width = epoch_window[1] - epoch_window[0]\n",
    "    for event_idx in tqdm(boundary_matrix[:, boundary_event_to_idx[epoch_event]].nonzero()[0]):\n",
    "        epoch_states = hidden_states[event_idx + epoch_window[0]:event_idx + epoch_window[1]]\n",
    "\n",
    "        if baseline_window is not None:\n",
    "            baseline_states = hidden_states[event_idx + baseline_window[0]:event_idx + baseline_window[1]]\n",
    "            epoch_states -= baseline_states.mean(axis=0)\n",
    "\n",
    "        if epoch_states.shape[0] < target_width:\n",
    "            # Pad\n",
    "            epoch_states = np.pad(epoch_states, ((0, target_width - epoch_states.shape[0]), (0, 0)))\n",
    "        epoch_data.append(epoch_states)\n",
    "\n",
    "    epoch_data = np.array(epoch_data)\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.axvline(0, color=\"gray\")\n",
    "    ax.axhline(0, color=\"gray\")\n",
    "\n",
    "    for dim in range(epoch_data.shape[2]):\n",
    "        data = epoch_data[:, :, dim]\n",
    "        data_mean = data.mean(axis=0)\n",
    "        data_sem = data.std(axis=0) / np.sqrt(data.shape[0])\n",
    "\n",
    "        xs = np.arange(epoch_window[0], epoch_window[1]) / model_sfreq\n",
    "        ax.plot(xs, data_mean, label=dim)\n",
    "        ax.fill_between(xs, data_mean - data_sem, data_mean + data_sem, alpha=0.3)\n",
    "\n",
    "    return ax, epoch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, _ = epoch_and_plot(\"word\", hidden_states_pca, boundary_matrix)\n",
    "ax.set_title(\"Word onset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, _ = epoch_and_plot(\"phoneme\", hidden_states_pca, boundary_matrix)\n",
    "ax.set_title(\"Phoneme onset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Norm time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 1000\n",
    "lim = 400\n",
    "f, ax = plt.subplots(figsize=(20, 8))\n",
    "ax.plot(np.linalg.norm(hidden_states, axis=1)[offset:offset + lim])\n",
    "for word_onset in boundary_matrix[:, boundary_event_to_idx[\"word\"]].nonzero()[0]:\n",
    "    if word_onset > lim:\n",
    "        break\n",
    "    ax.axvline(word_onset, color=\"red\", alpha=0.5)\n",
    "for phon_onset in boundary_matrix[:, boundary_event_to_idx[\"phoneme\"]].nonzero()[0]:\n",
    "    if phon_onset > lim:\n",
    "        break\n",
    "    if boundary_matrix[phon_onset, boundary_event_to_idx[\"word\"]] == 1:\n",
    "        continue\n",
    "    ax.axvline(phon_onset, color=\"green\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf_norm = ReceptiveField(tmin=-5, tmax=20, sfreq=1, feature_names=boundary_event_names)\n",
    "norm_X_train, norm_X_test, norm_y_train, norm_y_test = train_test_split(boundary_matrix, np.linalg.norm(hidden_states, axis=1), shuffle=True, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf_norm.fit(norm_X_train, norm_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf_norm.score(norm_X_test, norm_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf_norm.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(trf_norm.coef_.shape[0], 1, figsize=(5 * trf_norm.coef_.shape[0], 5))\n",
    "for input_dim, (name, ax) in enumerate(zip(boundary_event_names, axs.ravel())):\n",
    "    ax.set_title(name)\n",
    "\n",
    "    ax.plot(trf_norm.delays_, trf_norm.coef_[input_dim, :], label=output_dim)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, _ = epoch_and_plot(\"word\", np.linalg.norm(hidden_states, axis=1, keepdims=True), boundary_matrix)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, _ = epoch_and_plot(\"phoneme\", np.linalg.norm(hidden_states, axis=1, keepdims=True), boundary_matrix)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA decomposition of state transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_state_shifts = hidden_states[1:] - hidden_states[:-1]\n",
    "boundary_matrix_shift = boundary_matrix[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_pca = 4\n",
    "shift_pca = PCA(d_pca)\n",
    "hidden_state_shifts_pca = shift_pca.fit_transform((hidden_state_shifts - hidden_state_shifts.mean(axis=0)) / hidden_state_shifts.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf_shift = ReceptiveField(tmin=-5, tmax=20, sfreq=1, feature_names=boundary_event_names)\n",
    "shift_X_train, shift_X_test, shift_y_train, shift_y_test = train_test_split(boundary_matrix_shift, hidden_state_shifts_pca, shuffle=True, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf_shift.fit(shift_X_train, shift_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf_shift.score(shift_X_test, shift_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(trf.coef_.shape[1], 1, figsize=(5 * trf.coef_.shape[1], 5))\n",
    "for input_dim, (name, ax) in enumerate(zip(boundary_event_names, axs.ravel())):\n",
    "    ax.set_title(name)\n",
    "    for output_dim in range(trf.coef_.shape[0]):\n",
    "        ax.plot(trf.delays_, trf.coef_[output_dim, input_dim, :], label=output_dim)\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_and_plot_shift(epoch_event, epoch_window=(-5, 20), baseline_window=(-5, 0)):\n",
    "    epoch_data = []\n",
    "    target_width = epoch_window[1] - epoch_window[0]\n",
    "    for event_idx in tqdm(boundary_matrix_shift[:, boundary_event_to_idx[epoch_event]].nonzero()[0]):\n",
    "        epoch_states = hidden_state_shifts_pca[event_idx + epoch_window[0]:event_idx + epoch_window[1]]\n",
    "        baseline_states = hidden_state_shifts_pca[event_idx + baseline_window[0]:event_idx + baseline_window[1]]\n",
    "        \n",
    "        epoch_states -= baseline_states.mean(axis=0)\n",
    "        if epoch_states.shape[0] < target_width:\n",
    "            # Pad\n",
    "            epoch_states = np.pad(epoch_states, ((0, target_width - epoch_states.shape[0]), (0, 0)))\n",
    "        epoch_data.append(epoch_states)\n",
    "\n",
    "    epoch_data = np.array(epoch_data)\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.axvline(0, color=\"gray\")\n",
    "    ax.axhline(0, color=\"gray\")\n",
    "\n",
    "    for dim in range(epoch_data.shape[2]):\n",
    "        data = epoch_data[:, :, dim]\n",
    "        data_mean = data.mean(axis=0)\n",
    "        data_sem = data.std(axis=0) / np.sqrt(data.shape[0])\n",
    "\n",
    "        xs = np.arange(epoch_window[0], epoch_window[1]) / model_sfreq\n",
    "        ax.plot(xs, data_mean, label=dim)\n",
    "        ax.fill_between(xs, data_mean - data_sem, data_mean + data_sem, alpha=0.3)\n",
    "\n",
    "    return ax, epoch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, _ = epoch_and_plot_shift(\"word\")\n",
    "ax.set_title(\"Word onset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, _ = epoch_and_plot_shift(\"phoneme\")\n",
    "ax.set_title(\"Phoneme onset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

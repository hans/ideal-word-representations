{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect integrator output values, grouping by different equivalence classings on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.datasets.speech_equivalence import SpeechEquivalenceDataset, SpeechHiddenStateDataset\n",
    "from src.models import get_best_checkpoint\n",
    "from src.models.integrator import ContrastiveEmbeddingModel, iter_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model_dir = \"outputs/models/timit-no_repeats/w2v2_8/randomff_32/random\"\n",
    "output_dir = \"outputs/notebooks/timit-no_repeats/w2v2_8/randomff_32/random/predictions\"\n",
    "dataset_path = \"outputs/preprocessed_data/timit-no_repeats\"\n",
    "phoneme_equivalence_path = \"outputs/equivalence_datasets/timit-no_repeats/w2v2_8/phoneme_10frames/equivalence.pkl\"\n",
    "hidden_states_path = \"outputs/hidden_states/timit-no_repeats/w2v2_8/hidden_states.h5\"\n",
    "state_space_specs_path = \"outputs/state_space_specs/timit-no_repeats/w2v2_8/state_space_specs.pkl\"\n",
    "embeddings_path = \"outputs/model_embeddings/timit-no_repeats/w2v2_8/randomff_32/random/embeddings.npy\"\n",
    "\n",
    "metric = \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ContrastiveEmbeddingModel.from_pretrained(get_best_checkpoint(model_dir))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(phoneme_equivalence_path, \"rb\") as f:\n",
    "    equiv_dataset: SpeechEquivalenceDataset = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.Dataset.from_generator(\n",
    "    iter_dataset, gen_kwargs=dict(equiv_dataset_path=phoneme_equivalence_path,\n",
    "                                    hidden_states_path=hidden_states_path,\n",
    "                                    max_length=model.config.max_length,\n",
    "                                    num_examples=min(10000, equiv_dataset.num_instances),\n",
    "                                    infinite=False)) \\\n",
    "    .with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = torch.bincount(ds[\"example_class\"], minlength=len(equiv_dataset.class_labels)).numpy()\n",
    "sns.barplot(pd.Series(class_counts, index=equiv_dataset.class_labels).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, idxs = [], []\n",
    "\n",
    "def compute_loss_batch(batch, batch_idxs):\n",
    "    if all(neg == None for neg in batch[\"neg\"]):\n",
    "        batch[\"neg\"] = None\n",
    "        batch[\"neg_length\"] = None\n",
    "    with torch.no_grad():\n",
    "        model_output = model(batch[\"example\"], batch[\"example_length\"],\n",
    "                             batch[\"pos\"], batch[\"pos_length\"],\n",
    "                             batch[\"neg\"], batch[\"neg_length\"],\n",
    "                             example_idx=batch[\"example_class\"],\n",
    "                             in_batch_soft_negatives=True,\n",
    "                             loss_reduction=None)\n",
    "    losses.append(model_output.loss.numpy())\n",
    "    idxs.append(batch[\"example_idx\"].numpy())\n",
    "ds.map(compute_loss_batch, batched=True, with_indices=True, batch_size=32)\n",
    "\n",
    "losses = np.concatenate(losses)\n",
    "idxs = np.concatenate(idxs)\n",
    "\n",
    "loss_df = pd.DataFrame({\"loss\": losses, \"idx\": idxs, \"class\": equiv_dataset.Q[idxs]})\n",
    "loss_df[\"class_label\"] = loss_df[\"class\"].map(dict(enumerate(equiv_dataset.class_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=loss_df, x=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df.to_csv(Path(output_dir) / \"loss.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=loss_df, x=\"class_label\", y=\"loss\",\n",
    "            order=loss_df.groupby(\"class_label\")[\"loss\"].mean().sort_values().index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "from dataclasses import replace\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.analysis.state_space import prepare_state_trajectory, StateSpaceAnalysisSpec\n",
    "from src.datasets.speech_equivalence import SpeechEquivalenceDataset\n",
    "from src.models import get_best_checkpoint\n",
    "from src.models.integrator import ContrastiveEmbeddingModel, compute_embeddings, load_or_compute_embeddings\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model_dir = \"outputs/models/timit/w2v2_6/rnn_8/phoneme\"\n",
    "output_dir = \"outputs/notebooks/timit/w2v2_6/rnn_8/phoneme/plot\"\n",
    "dataset_path = \"outputs/preprocessed_data/timit\"\n",
    "equivalence_path = \"outputs/equivalence_datasets/timit/w2v2_6/phoneme/equivalence.pkl\"\n",
    "hidden_states_path = \"outputs/hidden_states/timit/w2v2_6/hidden_states.h5\"\n",
    "state_space_specs_path = \"outputs/state_space_specs/timit/w2v2_6/state_space_specs.h5\"\n",
    "embeddings_path = \"outputs/model_embeddings/timit/w2v2_6/rnn_8/phoneme/embeddings.npy\"\n",
    "\n",
    "# Add 4 frames prior to phoneme onset to each trajectory\n",
    "expand_frame_window = (4, 0)\n",
    "\n",
    "metric = \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(embeddings_path, \"rb\") as f:\n",
    "    model_representations: np.ndarray = np.load(f)\n",
    "with open(equivalence_path, \"rb\") as f:\n",
    "    equiv_dataset: SpeechEquivalenceDataset = torch.load(f)\n",
    "state_space_spec = StateSpaceAnalysisSpec.from_hdf5(state_space_specs_path, \"word\")\n",
    "assert state_space_spec.is_compatible_with(model_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space_spec.cuts[\"idx_in_level\"] = state_space_spec.cuts.groupby([\"label\", \"instance_idx\", \"level\"]).cumcount()\n",
    "state_space_spec.cuts[\"num_frames\"] = state_space_spec.cuts.offset_frame_idx - state_space_spec.cuts.onset_frame_idx\n",
    "sns.histplot(data=state_space_spec.cuts.reset_index(), x=\"idx_in_level\", hue=\"level\", discrete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = prepare_state_trajectory(model_representations, state_space_spec, expand_window=expand_frame_window, pad=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [np.isnan(traj_i[:, :, 0]).argmax(axis=1) for traj_i in trajectory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_temporal_generalization(trajectory, lengths, train_frame, test_frame):\n",
    "    X, Y = [], []\n",
    "    for traj_i, lengths_i in zip(trajectory, lengths):\n",
    "        analyze = ((lengths_i > test_frame) & (lengths_i > train_frame)).nonzero()[0]\n",
    "        for idx in analyze:\n",
    "            X.append(traj_i[idx, train_frame])\n",
    "            Y.append(traj_i[idx, test_frame])\n",
    "\n",
    "    if len(X) < 100:\n",
    "        return np.nan\n",
    "\n",
    "    X = np.stack(X)\n",
    "    Y = np.stack(Y)\n",
    "\n",
    "    # Fit linear model\n",
    "    model = RidgeCV(cv=KFold(3, shuffle=True))\n",
    "    return cross_val_score(model, X, Y, cv=KFold(3, shuffle=True), scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_generalization_scores = np.zeros((trajectory[0].shape[1], trajectory[0].shape[1])) * np.nan\n",
    "for train_frame, test_frame in tqdm(list(itertools.product(range(trajectory[0].shape[1]), repeat=2))):\n",
    "    scores = evaluate_temporal_generalization(trajectory, lengths, train_frame, test_frame)\n",
    "    temporal_generalization_scores[train_frame, test_frame] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_generalization_df = pd.DataFrame(temporal_generalization_scores, columns=pd.Index(range(trajectory[0].shape[1]), name=\"test_frame\"),\n",
    "                                          index=pd.Index(range(trajectory[0].shape[1]), name=\"train_frame\"))\n",
    "temporal_generalization_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_generalization_df.to_csv(Path(output_dir) / \"temporal_generalization.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = temporal_generalization_df.iloc[:30, :30]\n",
    "\n",
    "ax = sns.heatmap(plot_df, cmap=\"RdBu_r\", center=0, xticklabels=10, yticklabels=10)\n",
    "\n",
    "assert expand_frame_window[1] == 0\n",
    "# Draw word onset\n",
    "if expand_frame_window[0] != 0:\n",
    "    ax.axvline(expand_frame_window[0], color=\"gray\", linestyle=\"--\")\n",
    "    ax.axhline(expand_frame_window[0], color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "ax.set_xlabel(\"Test frame\")\n",
    "ax.set_ylabel(\"Train frame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal generalization by cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_temporal_generalization_by_cuts(\n",
    "        model_representations, mymap,\n",
    "        train_cut_position, train_frame_offset,\n",
    "        test_cut_position, test_frame_offset,\n",
    "        min_samples=100\n",
    "):\n",
    "    frames = mymap[train_cut_position, train_frame_offset, test_cut_position, test_frame_offset]\n",
    "    if len(frames) < min_samples:\n",
    "        return np.nan\n",
    "\n",
    "    X, Y = [], []\n",
    "    for train_frame, test_frame in frames:\n",
    "        X.append(model_representations[train_frame])\n",
    "        Y.append(model_representations[test_frame])\n",
    "\n",
    "    X = np.stack(X)\n",
    "    Y = np.stack(Y)\n",
    "\n",
    "    # Fit linear model\n",
    "    model = RidgeCV(cv=KFold(3, shuffle=True))\n",
    "    return cross_val_score(model, X, Y, cv=KFold(3, shuffle=True), scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_temporal_generalization_by_cut(cut_level, min_samples=100):\n",
    "    tg_cut_df = state_space_spec.cuts.xs(cut_level, level=\"level\").copy().sort_index()\n",
    "\n",
    "    # Find max number of frames for each unit position such that we have a minimum\n",
    "    # number of samples at each frame in that position\n",
    "    num_frames_for_position = {}\n",
    "    for frame in range(tg_cut_df.num_frames.max()):\n",
    "        num_samples = tg_cut_df.groupby(\"idx_in_level\").apply(lambda xs: (xs.num_frames > frame).sum())\n",
    "        for position, num_samples in num_samples.items():\n",
    "            if num_samples > min_samples:\n",
    "                num_frames_for_position[position] = frame\n",
    "    \n",
    "    # maps (train_position, train_frame_offset, test_position, test_frame_offset) -> [(train_frame, test_frame)]\n",
    "    mymap = defaultdict(list)\n",
    "\n",
    "    # skip positions which don't have enough samples\n",
    "    pair_tg_df = tg_cut_df[tg_cut_df.idx_in_level.isin(num_frames_for_position.keys())]\n",
    "    for (label, instance_idx), cuts_i in tqdm(pair_tg_df.groupby([\"label\", \"instance_idx\"])):\n",
    "        cuts_i = cuts_i.set_index(\"idx_in_level\")\n",
    "        for pos1, pos2 in itertools.product(cuts_i.index, repeat=2):\n",
    "            cuts_i1, cuts_i2 = cuts_i.loc[pos1], cuts_i.loc[pos2]\n",
    "            num_frames_1 = min(num_frames_for_position[pos1], cuts_i1.num_frames.max())\n",
    "            num_frames_2 = min(num_frames_for_position[pos2], cuts_i2.num_frames.max())\n",
    "            for frame_offset1, frame_offset2 in itertools.product(range(num_frames_1), range(num_frames_2)):\n",
    "                mymap[pos1, frame_offset1, pos2, frame_offset2].append((\n",
    "                    cuts_i1.onset_frame_idx + frame_offset1,\n",
    "                    cuts_i2.onset_frame_idx + frame_offset2\n",
    "                ))\n",
    "\n",
    "    all_eval_frames = [(position, frame) for position in num_frames_for_position\n",
    "                   for frame in range(num_frames_for_position[position])]\n",
    "\n",
    "    tg_scores_cut = np.zeros((len(all_eval_frames), len(all_eval_frames))) * np.nan\n",
    "    for ((i, (train_cut_position, train_frame)), (j, (test_cut_position, test_frame))) in tqdm(list(itertools.product(enumerate(all_eval_frames), repeat=2))):\n",
    "        scores = evaluate_temporal_generalization_by_cuts(\n",
    "            model_representations, mymap,\n",
    "            train_cut_position, train_frame,\n",
    "            test_cut_position, test_frame,\n",
    "            min_samples=min_samples\n",
    "        )\n",
    "        tg_scores_cut[i, j] = np.mean(scores)\n",
    "\n",
    "    tg_scores_cut_df = pd.DataFrame(tg_scores_cut, columns=pd.MultiIndex.from_tuples(all_eval_frames, names=[\"position\", \"frame\"]),\n",
    "                                    index=pd.MultiIndex.from_tuples(all_eval_frames, names=[\"position\", \"frame\"]))\n",
    "    \n",
    "    return tg_scores_cut_df, num_frames_for_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tg_scores(tg_scores_df, num_frames_for_position, title, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    # Flatten index to string values\n",
    "    tg_scores_df = tg_scores_df.copy()\n",
    "    tg_scores_df.index = tg_scores_df.index.map(lambda x: f\"{x[0]}:{x[1]}\")\n",
    "    tg_scores_df.columns = tg_scores_df.columns.map(lambda x: f\"{x[0]}:{x[1]}\")\n",
    "\n",
    "    ax = sns.heatmap(tg_scores_df, cmap=\"RdBu_r\", center=0)\n",
    "\n",
    "    # plot xticks just at cut unit borders\n",
    "    ax.set_xticks(np.cumsum([num_frames_for_position[position] for position in num_frames_for_position]))\n",
    "    ax.set_yticks(np.cumsum([num_frames_for_position[position] for position in num_frames_for_position]))\n",
    "    ax.set_xticklabels([f\"{position}\" for position in num_frames_for_position])\n",
    "    ax.set_yticklabels([f\"{position}\" for position in num_frames_for_position])\n",
    "\n",
    "    # Draw cut borders\n",
    "    acc = 0\n",
    "    for position, num_frames in num_frames_for_position.items():\n",
    "        acc += num_frames\n",
    "        ax.axvline(acc, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "        ax.axhline(acc, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Test frame\")\n",
    "    ax.set_ylabel(\"Train frame\")\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for level in tqdm(state_space_spec.cuts.index.get_level_values(\"level\").unique()):\n",
    "    print(level)\n",
    "\n",
    "    tg_scores_cut_df, num_frames_for_position = analyze_temporal_generalization_by_cut(level)\n",
    "    tg_scores_cut_df.to_csv(Path(output_dir) / f\"temporal_generalization-cut_{level}.csv\")\n",
    "\n",
    "    ax = plot_tg_scores(tg_scores_cut_df, num_frames_for_position, f\"Temporal generalization by cut: {level}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

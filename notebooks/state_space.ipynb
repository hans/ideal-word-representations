{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import replace\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "\n",
    "from src.analysis.state_space import StateSpaceAnalysisSpec, prepare_state_trajectory\n",
    "from src.datasets.speech_equivalence import SpeechEquivalenceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "base_model = \"w2v2_6\"\n",
    "model_class = \"rnn_8-aniso1\"\n",
    "model_name = \"word_broad\"\n",
    "model_dir = f\"outputs/models/timit/{base_model}/{model_class}/{model_name}_10frames\"\n",
    "output_dir = f\"outputs/notebooks/timit/{base_model}/{model_class}/{model_name}_10frames/state_space\"\n",
    "dataset_path = \"outputs/preprocessed_data/timit\"\n",
    "equivalence_path = f\"outputs/equivalence_datasets/timit/{base_model}/{model_name}_10frames/equivalence.pkl\"\n",
    "hidden_states_path = f\"outputs/hidden_states/timit/{base_model}/hidden_states.pkl\"\n",
    "state_space_specs_path = f\"outputs/state_space_specs/timit/{base_model}/state_space_specs.pkl\"\n",
    "embeddings_path = f\"outputs/model_embeddings/timit/{base_model}/{model_class}/{model_name}_10frames/embeddings.npy\"\n",
    "\n",
    "# Add 4 frames prior to onset to each trajectory\n",
    "expand_frame_window = (4, 0)\n",
    "\n",
    "metric = \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(embeddings_path, \"rb\") as f:\n",
    "    model_representations: np.ndarray = np.load(f)\n",
    "with open(state_space_specs_path, \"rb\") as f:\n",
    "    state_space_spec: StateSpaceAnalysisSpec = torch.load(f)[\"word\"]\n",
    "assert state_space_spec.is_compatible_with(model_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = sorted([(len(trajs), label) for trajs, label in zip(state_space_spec.target_frame_spans, state_space_spec.labels)], reverse=True)\n",
    "# import itertools\n",
    "# {k: sorted([(count, word) for count, word in vs if len(word) > 3], reverse=True)\n",
    "#  for k, vs in itertools.groupby(sorted(vocab, key=lambda x: x[1]), key=lambda x: x[1][0])}[\"p\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use top N words to compute broader PCA\n",
    "pca_num_words = 200\n",
    "pca_words = [label for _, label in sorted([(len(trajs), label) for trajs, label in zip(state_space_spec.target_frame_spans, state_space_spec.labels)], reverse=True)[:200]]\n",
    "# ..but just plot these words in the resulting space\n",
    "plot_words = [\"allow\", \"about\", \"around\",\n",
    "              \"before\", \"black\", \"barely\",\n",
    "              \"small\", \"said\", \"such\",\n",
    "              \"please\", \"people\", \"problem\"]\n",
    "if any(word not in state_space_spec.labels for word in plot_words):\n",
    "    raise ValueError(f\"Plot words not found in state space: {plot_words}\")\n",
    "drop_idxs = [idx for idx, word in enumerate(state_space_spec.labels)\n",
    "             if word not in pca_words + plot_words]\n",
    "state_space_spec = state_space_spec.drop_labels(drop_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = prepare_state_trajectory(\n",
    "    model_representations,\n",
    "    state_space_spec,\n",
    "    expand_window=expand_frame_window,\n",
    "    pad=np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trajectories_full = np.concatenate(trajectory)\n",
    "all_trajectories_src = np.array(list(np.ndindex(all_trajectories_full.shape[:2])))\n",
    "\n",
    "# flatten & retain non-padding\n",
    "all_trajectories = all_trajectories_full.reshape(-1, all_trajectories_full.shape[-1])\n",
    "retain_idxs = ~np.isnan(all_trajectories).any(axis=1)\n",
    "all_trajectories = all_trajectories[retain_idxs]\n",
    "all_trajectories_src = all_trajectories_src[retain_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(all_trajectories)\n",
    "\n",
    "all_trajectories_pca = pca.transform(all_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trajectories_pca_padded = np.full(all_trajectories_full.shape[:2] + (2,), np.nan)\n",
    "all_trajectories_pca_padded[all_trajectories_src[:, 0], all_trajectories_src[:, 1]] = all_trajectories_pca\n",
    "\n",
    "# get index of first nan in each item; back-fill with last value\n",
    "for idx, nan_onset in enumerate(np.isnan(all_trajectories_pca_padded)[:, :, 0].argmax(axis=1)):\n",
    "    if nan_onset == 0:\n",
    "        continue\n",
    "    all_trajectories_pca_padded[idx, nan_onset:] = all_trajectories_pca_padded[idx, nan_onset - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_dividers = np.cumsum([traj.shape[0] for traj in trajectory])\n",
    "trajectory_dividers = np.concatenate([[0], trajectory_dividers])\n",
    "# get just the dividers for plot_words\n",
    "plot_word_dividers = []\n",
    "for word in plot_words:\n",
    "    class_idx = state_space_spec.labels.index(word)\n",
    "    left_edge = trajectory_dividers[class_idx]\n",
    "    right_edge = trajectory_dividers[class_idx + 1] if class_idx + 1 < len(trajectory_dividers) else len(all_trajectories_pca_padded)\n",
    "    plot_word_dividers.append((left_edge, right_edge))\n",
    "plot_word_dividers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min, max = all_trajectories_pca.min(), all_trajectories_pca.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animate\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(np.floor(min), np.ceil(max))\n",
    "ax.set_ylim(np.floor(min), np.ceil(max))\n",
    "annot_frame = ax.text(-0.75, 0.75, \"-1\")\n",
    "\n",
    "color_classes = sorted(set(word[0] for word in plot_words))\n",
    "color_values = {class_: i for i, class_ in enumerate(color_classes)}\n",
    "\n",
    "cmap = plt.get_cmap(\"Set1\")\n",
    "scats = [ax.scatter(np.zeros(end - start + 1), np.zeros(end - start + 1),\n",
    "                    alpha=0.5,\n",
    "                    marker=\"o\",\n",
    "                    color=cmap(color_values[word[0]]),\n",
    "                   ) for i, (word, (start, end)) in enumerate(zip(plot_words, plot_word_dividers))]\n",
    "ax.legend(scats, plot_words, loc=1)\n",
    "\n",
    "def init():\n",
    "    for scat in scats:\n",
    "        scat.set_offsets(np.zeros((0, 2)))\n",
    "    return tuple(scats)\n",
    "\n",
    "def update(frame):\n",
    "    for scat, (idx_start, idx_end) in zip(scats, plot_word_dividers):\n",
    "        traj_i = all_trajectories_pca_padded[idx_start:idx_end, frame]\n",
    "        scat.set_offsets(traj_i)\n",
    "        # scat.set_array(np.arange(traj_i.shape[0]))\n",
    "    annot_frame.set_text(str(frame))\n",
    "    return tuple(scats) + (annot_frame,)\n",
    "\n",
    "# Animate by model frame\n",
    "num_frames = all_trajectories_pca_padded.shape[1]\n",
    "ani = animation.FuncAnimation(fig, update, frames=num_frames, interval=500,\n",
    "                              init_func=init)\n",
    "ani.save(Path(output_dir) / \"state_space.gif\", writer=\"ffmpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

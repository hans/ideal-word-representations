{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import replace\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.analysis.state_space import prepare_state_trajectory, StateSpaceAnalysisSpec\n",
    "from src.datasets.speech_equivalence import SpeechEquivalenceDataset\n",
    "from src.models import get_best_checkpoint\n",
    "from src.models.integrator import ContrastiveEmbeddingModel, compute_embeddings, load_or_compute_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"outputs/models/w2v2_8/syllable\"\n",
    "equiv_dataset_path = \"data/timit_equiv_phoneme_within_word_prefix_1.pkl\"\n",
    "# equiv_dataset_path = \"data/timit_equiv_phoneme_6_1.pkl\"\n",
    "output_dir = \".\"\n",
    "\n",
    "state_space_spec_path = \"out/state_space_specs/all_syllables.pkl\"\n",
    "\n",
    "metric = \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgauthier/u/transformers/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ContrastiveEmbeddingModel(\n",
       "  (rnn): RNNModel(\n",
       "    (rnn): LSTM(768, 32, batch_first=True)\n",
       "    (fc): Linear(in_features=32, out_features=8, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ContrastiveEmbeddingModel.from_pretrained(get_best_checkpoint(model_dir))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(equiv_dataset_path, \"rb\") as f:\n",
    "    equiv_dataset: SpeechEquivalenceDataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(state_space_spec_path, \"rb\") as f:\n",
    "    state_space_spec: StateSpaceAnalysisSpec = pickle.load(f)\n",
    "\n",
    "# DEV: retain just the samples available in this subset\n",
    "spans = [[(start, end) for start, end in spans_i if end < equiv_dataset.hidden_state_dataset.num_frames]\n",
    "         for spans_i in state_space_spec.target_frame_spans]\n",
    "retain_idxs = [idx for idx, spans_i in enumerate(spans) if len(spans_i) > 0]\n",
    "state_space_spec = replace(state_space_spec,\n",
    "                           target_frame_spans=[spans[i] for i in retain_idxs],\n",
    "                           labels=[state_space_spec.labels[i] for i in retain_idxs],\n",
    "                           total_num_frames=equiv_dataset.hidden_state_dataset.num_frames)\n",
    "    \n",
    "assert state_space_spec.is_compatible_with(equiv_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/embedding_cache/outputs-models-w2v2_8-syllable-data-timit_equiv_phoneme_within_word_prefix_1.pkl.npy\n"
     ]
    }
   ],
   "source": [
    "model_representations = load_or_compute_embeddings(model, equiv_dataset, model_dir, equiv_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only syllables with N or more instances\n",
    "retain_n = 5\n",
    "retain_idxs = [idx for idx, target_frames in enumerate(state_space_spec.target_frame_spans)\n",
    "               if len(target_frames) >= retain_n]\n",
    "state_space_spec = replace(state_space_spec,\n",
    "    labels=[state_space_spec.labels[i] for i in retain_idxs],\n",
    "    target_frame_spans=[state_space_spec.target_frame_spans[i] for i in retain_idxs],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = prepare_state_trajectory(model_representations, state_space_spec, pad=np.nan)\n",
    "lengths = [np.isnan(traj_i[:, :, 0]).argmax(axis=1) for traj_i in trajectory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_frames = [traj_i[np.arange(len(traj_i)), length_i - 1] for traj_i, length_i in zip(trajectory, lengths)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute syllable edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllables = state_space_spec.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate edit distance between two sequences of phonemes\n",
    "def edit_distance(s1, s2):\n",
    "    # Using Wagner-Fischer algorithm for computing edit distance\n",
    "    m, n = len(s1), len(s2)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0:\n",
    "                dp[i][j] = j   # Deletion\n",
    "            elif j == 0:\n",
    "                dp[i][j] = i   # Insertion\n",
    "            else:\n",
    "                cost = 0 if s1[i - 1] == s2[j - 1] else 1\n",
    "                dp[i][j] = min(dp[i - 1][j] + 1,      # Deletion\n",
    "                               dp[i][j - 1] + 1,      # Insertion\n",
    "                               dp[i - 1][j - 1] + cost) # Substitution\n",
    "    return dp[m][n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.zeros((len(syllables), len(syllables)))\n",
    "syllable2idx = {s: i for i, s in enumerate(syllables)}\n",
    "for i, s1 in enumerate(syllables):\n",
    "    for j, s2 in enumerate(syllables):\n",
    "        distances[i, j] = edit_distance(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 473)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d888fafdb2dd4a87a2580d3e86eae14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xs, y = [], []\n",
    "max_num_pairs, max_num_samples = 1000, 100\n",
    "\n",
    "syllable_pairs = list(itertools.combinations(list(range(len(syllables))), 2))\n",
    "np.random.shuffle(syllable_pairs)\n",
    "syllable_pairs = syllable_pairs[:max_num_pairs]\n",
    "\n",
    "for s1, s2 in tqdm(syllable_pairs):\n",
    "    frame_pairs = list(itertools.product(list(range(len(final_frames[s1]))), list(range(len(final_frames[s2])))))\n",
    "    np.random.shuffle(frame_pairs)\n",
    "    frame_pairs = frame_pairs[:max_num_samples]\n",
    "                       \n",
    "    for f1, f2 in frame_pairs:\n",
    "        Xs.append(np.concatenate([final_frames[s1][f1], final_frames[s2][f2]]))\n",
    "        y.append(distances[s1, s2])\n",
    "\n",
    "X = np.stack(Xs)\n",
    "y = np.array(y).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes=(10,), max_iter=1000)\n",
    "scores = cross_val_score(model, X, y, cv=KFold(5, shuffle=True), scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05810032, 0.06242847, 0.06203571, 0.07060511, 0.06393827])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced regression analysis: cosine distance as metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b02d16f1b9d42f9aeb1e9aadbf36326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xs, y = [], []\n",
    "max_num_pairs, max_num_samples = 1000, 100\n",
    "\n",
    "syllable_pairs = list(itertools.combinations(list(range(len(syllables))), 2))\n",
    "np.random.shuffle(syllable_pairs)\n",
    "syllable_pairs = syllable_pairs[:max_num_pairs]\n",
    "\n",
    "for s1, s2 in tqdm(syllable_pairs):\n",
    "    frame_pairs = list(itertools.product(list(range(len(final_frames[s1]))), list(range(len(final_frames[s2])))))\n",
    "    np.random.shuffle(frame_pairs)\n",
    "    frame_pairs = frame_pairs[:max_num_samples]\n",
    "                       \n",
    "    for f1, f2 in frame_pairs:\n",
    "        Xs.append(distance.cosine(final_frames[s1][f1], final_frames[s2][f2]))\n",
    "        y.append(distances[s1, s2])\n",
    "\n",
    "X = np.stack(Xs)\n",
    "y = np.array(y).astype(float)\n",
    "\n",
    "X -= X.mean()\n",
    "X /= X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RidgeCV(cv=KFold(5, shuffle=True))\n",
    "scores = cross_val_score(model, X[:, None], y, cv=KFold(5, shuffle=True), scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00044382, -0.00055969,  0.00010893,  0.00017792,  0.00025267])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

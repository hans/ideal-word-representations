{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d30d2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.analysis import analogy_pseudocausal\n",
    "from src.analysis.state_space import StateSpaceAnalysisSpec, \\\n",
    "    prepare_state_trajectory, aggregate_state_trajectory, flatten_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2de1395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"w2v2_pc_8\"\n",
    "\n",
    "model_class = \"ffff_32-pc-mAP1\"#discrim-rnn_32-pc-mAP1\"\n",
    "model_name = \"word_broad_10frames_fixedlen25\"\n",
    "\n",
    "train_dataset = \"librispeech-train-clean-100\"\n",
    "# hidden_states_path = f\"outputs/hidden_states/{base_model}/{train_dataset}.h5\"\n",
    "hidden_states_path = f\"/scratch/jgauthier/{base_model}_{train_dataset}.h5\"\n",
    "state_space_specs_path = f\"outputs/analogy/inputs/{train_dataset}/w2v2_pc/state_space_spec.h5\"\n",
    "embeddings_path = f\"outputs/model_embeddings/{train_dataset}/{base_model}/{model_class}/{model_name}/{train_dataset}.npy\"\n",
    "\n",
    "output_dir = f\"outputs/analogy_pseudocausal_broad/inputs/{train_dataset}/w2v2_pc/\"\n",
    "\n",
    "pos_counts_path = \"data/pos_counts.pkl\"\n",
    "\n",
    "seed = 42\n",
    "\n",
    "metric = \"cosine\"\n",
    "\n",
    "agg_fns = [\n",
    "    (\"mean_within_cut\", \"phoneme\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe338f",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3825872f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/jgauthier/transformers/lib/python3.10/site-packages/tables/attributeset.py:295: DataTypeWarning: Unsupported type for attribute 'labels_are_repr' in node '/'. Offending HDF5 class: 8\n",
      "  value = self._g_getattr(self._v_node, name)\n"
     ]
    }
   ],
   "source": [
    "with open(embeddings_path, \"rb\") as f:\n",
    "    model_representations: np.ndarray = np.load(f)\n",
    "state_space_spec = StateSpaceAnalysisSpec.from_hdf5(state_space_specs_path)\n",
    "assert state_space_spec.is_compatible_with(model_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7460e76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f068561c8f5142d281ed7c68baac9cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32046 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aadab2fc6bd24fb88b35f02bf3f58552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aggregating:   0%|          | 0/32046 [00:00<?, ?label/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trajectory = prepare_state_trajectory(model_representations, state_space_spec)\n",
    "trajectory = aggregate_state_trajectory(trajectory, state_space_spec, agg_fns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fcf0c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg, agg_src = flatten_trajectory(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0eae3105",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts_df = state_space_spec.cuts.xs(\"phoneme\", level=\"level\").drop(columns=[\"onset_frame_idx\", \"offset_frame_idx\"])\n",
    "cuts_df[\"label_idx\"] = cuts_df.index.get_level_values(\"label\").map({l: i for i, l in enumerate(state_space_spec.labels)})\n",
    "cuts_df[\"frame_idx\"] = cuts_df.groupby([\"label\", \"instance_idx\"]).cumcount()\n",
    "cuts_df = cuts_df.reset_index().set_index([\"label_idx\", \"instance_idx\", \"frame_idx\"]).sort_index()\n",
    "\n",
    "agg_flat_idxs = pd.Series(list(range(len(agg_src))),\n",
    "                          index=pd.MultiIndex.from_tuples([tuple(xs) for xs in agg_src],\n",
    "                                                          names=[\"label_idx\", \"instance_idx\", \"frame_idx\"]))\n",
    "cuts_df = pd.merge(cuts_df, agg_flat_idxs.rename(\"traj_flat_idx\"), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbbd6f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_phonemic_forms = cuts_df.groupby([\"label\", \"instance_idx\"]).description.agg(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d73a6362",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_df = pd.read_csv(\"data/WorldLex_Eng_US.Freq.2.txt\", sep=\"\\t\", index_col=\"Word\")\n",
    "word_freq_df = word_freq_df.loc[~word_freq_df.index.duplicated()]\n",
    "# compute weighted average frequency across domains\n",
    "word_freq_df[\"BlogFreq_rel\"] = word_freq_df.BlogFreq / word_freq_df.BlogFreq.sum()\n",
    "word_freq_df[\"TwitterFreq_rel\"] = word_freq_df.TwitterFreq / word_freq_df.TwitterFreq.sum()\n",
    "word_freq_df[\"NewsFreq_rel\"] = word_freq_df.NewsFreq / word_freq_df.NewsFreq.sum()\n",
    "word_freq_df[\"Freq\"] = word_freq_df[[\"BlogFreq_rel\", \"TwitterFreq_rel\", \"NewsFreq_rel\"]].mean(axis=1) \\\n",
    "    * word_freq_df[[\"BlogFreq\", \"TwitterFreq\", \"NewsFreq\"]].sum().mean()\n",
    "word_freq_df[\"LogFreq\"] = np.log10(word_freq_df.Freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed979df6",
   "metadata": {},
   "source": [
    "## Prepare cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05b3374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_phon_set = set(\"AH ER IH L S Z T D M N\".split())\n",
    "target_cohort_length = 2\n",
    "# defines an alternative \"small\" cohort: prefixes which have only N of the above phones\n",
    "target_small_cohort_size = 3\n",
    "assert target_small_cohort_size < len(next_phon_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c19d5379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965f97baebaf49aa8b3336af9fc065de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cohorts = defaultdict(set)\n",
    "for phones in tqdm(cut_phonemic_forms.unique()):\n",
    "    phones = tuple(phones.split())\n",
    "    for i in range(len(phones)):\n",
    "        cohorts[phones[:i + 1]].add(phones)\n",
    "\n",
    "csz_next = pd.DataFrame([(\" \".join(coh), \" \".join(item), item[len(coh)]) for coh, items in cohorts.items()\n",
    "                            for item in items if len(item) > len(coh)],\n",
    "                            columns=[\"cohort\", \"item\", \"next_phoneme\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a04fd1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1758081/910310388.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .groupby(\"cohort\").apply(lambda xs: sorted(set(xs.next_phoneme)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cohort\n",
       "AH N    [AA, AE, AH, AO, AW, AY, B, CH, D, EH, ER, EY,...\n",
       "K ER    [AA, AE, AH, AO, AW, B, CH, D, EH, ER, EY, F, ...\n",
       "K OW    [AH, B, CH, D, ER, HH, IH, IY, JH, K, L, M, N,...\n",
       "L AY    [AE, AH, B, D, DH, ER, F, IH, K, L, M, N, P, R...\n",
       "P ER    [AA, AE, AH, AY, B, CH, D, EH, ER, EY, F, G, H...\n",
       "P EY    [AH, D, ER, G, IH, JH, L, M, N, P, S, SH, T, T...\n",
       "R OW    [AH, B, D, ER, G, HH, IH, IY, K, L, M, N, P, S...\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expt_cohort = csz_next[csz_next.cohort.str.count(\" \") == target_cohort_length - 1] \\\n",
    "    .groupby(\"cohort\").filter(lambda xs: set(xs.next_phoneme) >= next_phon_set) \\\n",
    "    .groupby(\"cohort\").apply(lambda xs: sorted(set(xs.next_phoneme)))\n",
    "expt_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17f7d405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1758081/2887618418.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .groupby(\"cohort\").apply(lambda xs: sorted(set(xs.next_phoneme)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cohort\n",
       "AA F      [AH, L, T]\n",
       "AO G     [AH, ER, M]\n",
       "AY OW     [AH, L, T]\n",
       "EH TH    [AH, IH, N]\n",
       "ER EY      [D, N, Z]\n",
       "ER JH    [AH, D, IH]\n",
       "ER OW      [M, N, Z]\n",
       "F UW       [D, L, Z]\n",
       "K OY       [L, N, T]\n",
       "TH AH      [D, M, N]\n",
       "W AW       [N, T, Z]\n",
       "Z AY      [AH, D, S]\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now search for type-small cohorts -- cohorts which only have N of the phone set\n",
    "expt_cohort_small = csz_next[csz_next.cohort.str.count(\" \") == target_cohort_length - 1].groupby(\"cohort\").filter(lambda xs: len(set(xs.next_phoneme)) == target_small_cohort_size and set(xs.next_phoneme) <= next_phon_set) \\\n",
    "    .groupby(\"cohort\").apply(lambda xs: sorted(set(xs.next_phoneme)))\n",
    "expt_cohort_small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f08afd",
   "metadata": {},
   "source": [
    "### Prepare instance-level metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e9ceac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446b3e4a476b4423b5c658702829edcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AH N AH 155\n",
      "AH N D 456\n",
      "AH N IH 89\n",
      "AH N L 163\n",
      "AH N M 32\n",
      "AH N N 117\n",
      "AH N S 67\n",
      "AH N T 190\n",
      "K ER AH 87\n",
      "K ER IH 94\n",
      "K ER L 43\n",
      "K ER N 75\n",
      "K ER S 26\n",
      "K ER T 73\n",
      "K OW D 23\n",
      "K OW L 187\n",
      "K OW M 21\n",
      "K OW S 86\n",
      "K OW T 103\n",
      "L AY AH 76\n",
      "L AY IH 98\n",
      "L AY N 190\n",
      "L AY S 23\n",
      "L AY T 331\n",
      "L AY Z 54\n",
      "P ER D 16\n",
      "P ER L 72\n",
      "P ER M 137\n",
      "P ER S 521\n",
      "P ER T 225\n",
      "P ER Z 39\n",
      "P EY D 97\n",
      "P EY IH 27\n",
      "P EY L 120\n",
      "P EY N 284\n",
      "P EY S 72\n",
      "P EY T 76\n",
      "R OW D 215\n",
      "R OW L 131\n",
      "R OW M 223\n",
      "R OW S 16\n",
      "R OW T 87\n",
      "R OW Z 195\n"
     ]
    }
   ],
   "source": [
    "all_instances = []\n",
    "all_prediction_equivalences = {}\n",
    "\n",
    "# Sample at most this many combinations of cohort + next phone\n",
    "max_items_per_cohort_and_next_phone = 15\n",
    "\n",
    "label2idx = {l: i for i, l in enumerate(state_space_spec.labels)}\n",
    "for cohort, next_phons in tqdm(expt_cohort.items(), total=len(expt_cohort)):\n",
    "    for phon in next_phons:\n",
    "        if phon not in next_phon_set:\n",
    "            continue\n",
    "\n",
    "        inflected_phones = f\"{cohort} {phon}\"\n",
    "        instances = cut_phonemic_forms[cut_phonemic_forms.str.match(f\"{inflected_phones}\\\\b\")].index\n",
    "\n",
    "        # Pick the top K labels with the highest frequency from the cohort.\n",
    "        coh_labels = instances.get_level_values(\"label\").str.replace(\"'s$\", \"\", regex=True)\n",
    "        if len(coh_labels) > max_items_per_cohort_and_next_phone:\n",
    "            label_freqs = word_freq_df.reindex(coh_labels.unique()).LogFreq.fillna(word_freq_df.LogFreq.min())\n",
    "            keep_labels = label_freqs.nlargest(max_items_per_cohort_and_next_phone).index\n",
    "            instances = instances[coh_labels.isin(keep_labels)]\n",
    "            print(cohort, phon, len(instances))\n",
    "        \n",
    "        equiv_key = (inflected_phones,)\n",
    "        if equiv_key not in all_prediction_equivalences:\n",
    "            all_prediction_equivalences[equiv_key] = \\\n",
    "                analogy_pseudocausal.prepare_prediction_equivalences(cuts_df, cut_phonemic_forms, cohort, phon)\n",
    "\n",
    "        for label, instance_idx in instances:\n",
    "            all_instances.append({\n",
    "                \"base_phones\": cohort,\n",
    "                \"inflected_phones\": inflected_phones,\n",
    "                \"post_divergence\": phon,\n",
    "\n",
    "                \"inflection\": phon,\n",
    "                \"next_phoneme_in_restricted_set\": phon in next_phon_set,\n",
    "\n",
    "                \"cohort_length\": target_cohort_length,\n",
    "                \"next_phoneme_idx\": target_cohort_length,\n",
    "\n",
    "                \"inflected\": label,\n",
    "                \"inflected_idx\": label2idx[label],\n",
    "                \"inflected_instance_idx\": instance_idx,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d8f9790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c1e9d0a244e465d8566577ba5373776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for cohort, next_phons in tqdm(expt_cohort_small.items(), total=len(expt_cohort_small)):\n",
    "    for phon in next_phons:\n",
    "        if phon not in next_phon_set:\n",
    "            continue\n",
    "        inflected_phones = f\"{cohort} {phon}\"\n",
    "        instances = cut_phonemic_forms[cut_phonemic_forms.str.match(f\"{inflected_phones}\\\\b\")].index\n",
    "\n",
    "        # Pick the top K labels with the highest frequency from the cohort.\n",
    "        coh_labels = instances.get_level_values(\"label\").str.replace(\"'s$\", \"\", regex=True)\n",
    "        if len(coh_labels) > max_items_per_cohort_and_next_phone:\n",
    "            label_freqs = word_freq_df.reindex(coh_labels.unique()).LogFreq.fillna(word_freq_df.LogFreq.min())\n",
    "            keep_labels = label_freqs.nlargest(max_items_per_cohort_and_next_phone).index\n",
    "            instances = instances[coh_labels.isin(keep_labels)]\n",
    "\n",
    "        equiv_key = (inflected_phones,)\n",
    "        if equiv_key not in all_prediction_equivalences:\n",
    "            all_prediction_equivalences[equiv_key] = \\\n",
    "                analogy_pseudocausal.prepare_prediction_equivalences(cuts_df, cut_phonemic_forms,\n",
    "                                                                     cohort, phon)\n",
    "\n",
    "        for label, instance_idx in instances:\n",
    "            all_instances.append({\n",
    "                \"base_phones\": cohort,\n",
    "                \"inflected_phones\": inflected_phones,\n",
    "                \"post_divergence\": phon,\n",
    "\n",
    "                \"inflection\": f\"small-{phon}\",\n",
    "                \"next_phoneme_in_restricted_set\": phon in next_phon_set,\n",
    "\n",
    "                \"cohort_length\": target_cohort_length,\n",
    "                \"next_phoneme_idx\": target_cohort_length,\n",
    "\n",
    "                \"inflected\": label,\n",
    "                \"inflected_idx\": label2idx[label],\n",
    "                \"inflected_instance_idx\": instance_idx,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3eab8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_phones</th>\n",
       "      <th>inflected_phones</th>\n",
       "      <th>post_divergence</th>\n",
       "      <th>inflection</th>\n",
       "      <th>next_phoneme_in_restricted_set</th>\n",
       "      <th>cohort_length</th>\n",
       "      <th>next_phoneme_idx</th>\n",
       "      <th>inflected</th>\n",
       "      <th>inflected_idx</th>\n",
       "      <th>inflected_instance_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AH N</td>\n",
       "      <td>AH N AH</td>\n",
       "      <td>AH</td>\n",
       "      <td>AH</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>another</td>\n",
       "      <td>2725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AH N</td>\n",
       "      <td>AH N AH</td>\n",
       "      <td>AH</td>\n",
       "      <td>AH</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>another</td>\n",
       "      <td>2725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AH N</td>\n",
       "      <td>AH N AH</td>\n",
       "      <td>AH</td>\n",
       "      <td>AH</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>another</td>\n",
       "      <td>2725</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AH N</td>\n",
       "      <td>AH N AH</td>\n",
       "      <td>AH</td>\n",
       "      <td>AH</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>another</td>\n",
       "      <td>2725</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AH N</td>\n",
       "      <td>AH N AH</td>\n",
       "      <td>AH</td>\n",
       "      <td>AH</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>another</td>\n",
       "      <td>2725</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6305</th>\n",
       "      <td>W AW</td>\n",
       "      <td>W AW Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>small-Z</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>wowzer</td>\n",
       "      <td>28693</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>Z AY</td>\n",
       "      <td>Z AY AH</td>\n",
       "      <td>AH</td>\n",
       "      <td>small-AH</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>zion</td>\n",
       "      <td>25333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>Z AY</td>\n",
       "      <td>Z AY AH</td>\n",
       "      <td>AH</td>\n",
       "      <td>small-AH</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>zion</td>\n",
       "      <td>25333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>Z AY</td>\n",
       "      <td>Z AY D</td>\n",
       "      <td>D</td>\n",
       "      <td>small-D</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>zuyder</td>\n",
       "      <td>20487</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>Z AY</td>\n",
       "      <td>Z AY S</td>\n",
       "      <td>S</td>\n",
       "      <td>small-S</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>zeiss</td>\n",
       "      <td>28782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6310 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     base_phones inflected_phones post_divergence inflection  \\\n",
       "0           AH N          AH N AH              AH         AH   \n",
       "1           AH N          AH N AH              AH         AH   \n",
       "2           AH N          AH N AH              AH         AH   \n",
       "3           AH N          AH N AH              AH         AH   \n",
       "4           AH N          AH N AH              AH         AH   \n",
       "...          ...              ...             ...        ...   \n",
       "6305        W AW           W AW Z               Z    small-Z   \n",
       "6306        Z AY          Z AY AH              AH   small-AH   \n",
       "6307        Z AY          Z AY AH              AH   small-AH   \n",
       "6308        Z AY           Z AY D               D    small-D   \n",
       "6309        Z AY           Z AY S               S    small-S   \n",
       "\n",
       "      next_phoneme_in_restricted_set  cohort_length  next_phoneme_idx  \\\n",
       "0                               True              2                 2   \n",
       "1                               True              2                 2   \n",
       "2                               True              2                 2   \n",
       "3                               True              2                 2   \n",
       "4                               True              2                 2   \n",
       "...                              ...            ...               ...   \n",
       "6305                            True              2                 2   \n",
       "6306                            True              2                 2   \n",
       "6307                            True              2                 2   \n",
       "6308                            True              2                 2   \n",
       "6309                            True              2                 2   \n",
       "\n",
       "     inflected  inflected_idx  inflected_instance_idx  \n",
       "0      another           2725                       0  \n",
       "1      another           2725                       1  \n",
       "2      another           2725                       2  \n",
       "3      another           2725                       3  \n",
       "4      another           2725                       4  \n",
       "...        ...            ...                     ...  \n",
       "6305    wowzer          28693                       2  \n",
       "6306      zion          25333                       0  \n",
       "6307      zion          25333                       1  \n",
       "6308    zuyder          20487                       0  \n",
       "6309     zeiss          28782                       0  \n",
       "\n",
       "[6310 rows x 10 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_instances_df = pd.DataFrame(all_instances)\n",
    "all_instances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3820ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_instances_df.to_csv(f\"{output_dir}/instances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91b1cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(all_prediction_equivalences, f\"{output_dir}/prediction_equivalences.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3bd3aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save([agg, agg_src], f\"{output_dir}/trajectories.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a trial has four defining factors. NB that a trial is more than an item now; itâ€™s the conjunction of two items and an actual target we are trying to reach:\n",
    "\n",
    "- source inflected phones (e.g. P ER P)\n",
    "- target base phones (e.g. D AW)\n",
    "- target GT next phone (e.g. D)\n",
    "- target actual desired next phone (e.g. B)\n",
    "\n",
    "from boolean statements relating these values we can derive critical conditions:\n",
    "\n",
    "- **Control**: source next phone != target next phone. Tests how reachable the target\n",
    "- **Weak experiment**: Can we reach the GT next phone? True when target GT == target actual\n",
    "- **Strong experiment**: Can we reach non-GT next phones which are attested in the lexicon? True when target GT != target actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.analysis import analogy, analogy_pseudocausal\n",
    "from src.analysis.state_space import StateSpaceAnalysisSpec, \\\n",
    "    prepare_state_trajectory, aggregate_state_trajectory, flatten_trajectory\n",
    "from src.datasets.speech_equivalence import SpeechHiddenStateDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "base_model = \"w2v2_pc_8\"\n",
    "\n",
    "model_class = \"ffff_32-pc-mAP1\"#discrim-rnn_32-pc-mAP1\"\n",
    "model_name = \"word_broad_10frames_fixedlen25\"\n",
    "\n",
    "train_dataset = \"librispeech-train-clean-100\"\n",
    "dataset = train_dataset\n",
    "experiment = \"phoneme_at_1\"\n",
    "\n",
    "# hidden_states_path = f\"outputs/hidden_states/{base_model}/{train_dataset}.h5\"\n",
    "hidden_states_path = f\"/scratch/jgauthier/{base_model}_{train_dataset}.h5\"\n",
    "embeddings_path = f\"outputs/model_embeddings/{train_dataset}/{base_model}/{model_class}/{model_name}/{dataset}.npy\"\n",
    "\n",
    "inputs_dir = f\"outputs/analogy_pseudocausal_broad/inputs/{dataset}/w2v2_pc/{experiment}\"\n",
    "instances_path = f\"{inputs_dir}/instances.csv\"\n",
    "state_space_specs_path = f\"{inputs_dir}/state_space_spec.h5\"\n",
    "\n",
    "output_dir = f\".\"\n",
    "\n",
    "pos_counts_path = \"data/pos_counts.pkl\"\n",
    "\n",
    "seed = 42\n",
    "\n",
    "metric = \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load OmegaConf from yaml with `experiment`\n",
    "config = OmegaConf.load(f\"conf/experiments/analogy_pseudocausal/{experiment}.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_fns = [\n",
    "    (\"mean_within_cut\", config.unit_level)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if embeddings_path == \"ID\":\n",
    "    model_representations = SpeechHiddenStateDataset.from_hdf5(hidden_states_path).states\n",
    "else:\n",
    "    with open(embeddings_path, \"rb\") as f:\n",
    "        model_representations: np.ndarray = np.load(f)\n",
    "state_space_spec = StateSpaceAnalysisSpec.from_hdf5(state_space_specs_path)\n",
    "assert state_space_spec.is_compatible_with(model_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = prepare_state_trajectory(model_representations, state_space_spec)\n",
    "trajectory = aggregate_state_trajectory(trajectory, state_space_spec, agg_fns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg, agg_src = flatten_trajectory(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts_df = state_space_spec.cuts.xs(config.unit_level, level=\"level\").drop(columns=[\"onset_frame_idx\", \"offset_frame_idx\"])\n",
    "cuts_df[\"label_idx\"] = cuts_df.index.get_level_values(\"label\").map({l: i for i, l in enumerate(state_space_spec.labels)})\n",
    "cuts_df[\"frame_idx\"] = cuts_df.groupby([\"label\", \"instance_idx\"]).cumcount()\n",
    "cuts_df = cuts_df.reset_index().set_index([\"label_idx\", \"instance_idx\", \"frame_idx\"]).sort_index()\n",
    "\n",
    "agg_flat_idxs = pd.Series(list(range(len(agg_src))),\n",
    "                          index=pd.MultiIndex.from_tuples([tuple(xs) for xs in agg_src],\n",
    "                                                          names=[\"label_idx\", \"instance_idx\", \"frame_idx\"]))\n",
    "cuts_df = pd.merge(cuts_df, agg_flat_idxs.rename(\"traj_flat_idx\"), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2idx = {l: i for i, l in enumerate(state_space_spec.labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(cuts_df.description.iloc[0]) == tuple:\n",
    "    cuts_df[\"description\"] = cuts_df.description.apply(''.join)\n",
    "cut_forms = cuts_df.groupby([\"label\", \"instance_idx\"]).description.agg(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_df = pd.read_csv(\"data/WorldLex_Eng_US.Freq.2.txt\", sep=\"\\t\", index_col=\"Word\")\n",
    "word_freq_df = word_freq_df.loc[~word_freq_df.index.duplicated()]\n",
    "# compute weighted average frequency across domains\n",
    "word_freq_df[\"BlogFreq_rel\"] = word_freq_df.BlogFreq / word_freq_df.BlogFreq.sum()\n",
    "word_freq_df[\"TwitterFreq_rel\"] = word_freq_df.TwitterFreq / word_freq_df.TwitterFreq.sum()\n",
    "word_freq_df[\"NewsFreq_rel\"] = word_freq_df.NewsFreq / word_freq_df.NewsFreq.sum()\n",
    "word_freq_df[\"Freq\"] = word_freq_df[[\"BlogFreq_rel\", \"TwitterFreq_rel\", \"NewsFreq_rel\"]].mean(axis=1) \\\n",
    "    * word_freq_df[[\"BlogFreq\", \"TwitterFreq\", \"NewsFreq\"]].sum().mean()\n",
    "word_freq_df[\"LogFreq\"] = np.log10(word_freq_df.Freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_instances_df = pd.read_csv(instances_path)\n",
    "all_instances_df[\"base_phones\"] = all_instances_df[\"base_phones\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_unit_set = set(all_instances_df.post_divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the 20 most frequent cohorts.\n",
    "study_cohorts = all_instances_df.groupby(\"base_phones\").inflection.value_counts() \\\n",
    "    .groupby(\"base_phones\").filter(lambda xs: len(xs) >= 5) \\\n",
    "    .groupby(\"base_phones\").sum().sort_values().tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_cohort = defaultdict(set)\n",
    "for _, row in all_instances_df[all_instances_df.base_phones.isin(study_cohorts.index)].iterrows():\n",
    "    expt_cohort[row[\"base_phones\"]].add(row[\"post_divergence\"])\n",
    "expt_cohort = dict(expt_cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_length = 2\n",
    "all_prediction_equivalences = {\n",
    "    (inflected_phones,): {\n",
    "        \"matches_next_phoneme\": set(),\n",
    "        \"matches_next_phoneme_weak\": set(),\n",
    "        \"matches_cohort\": set(),\n",
    "    }\n",
    "    for inflected_phones in all_instances_df[\"inflected_phones\"].unique()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = cuts_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf[\"base_phones\"] = cdf.groupby([\"label_idx\", \"instance_idx\"]).description.transform(lambda xs: \" \".join(xs[:2]) if len(xs) > cohort_length + 1 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf[\"next_unit\"] = cdf.groupby([\"label_idx\", \"instance_idx\"]).description.transform(lambda xs: xs.iloc[cohort_length] if len(xs) > cohort_length else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infl_phones = set(tuple(inflected_phones.strip().split()) for inflected_phones in all_instances_df[\"inflected_phones\"].unique())\n",
    "all_prediction_equivalences = {\n",
    "    (\" \".join(inflected_phones),): {\n",
    "        \"matches_next_phoneme\": set(),\n",
    "        \"matches_next_phoneme_weak\": set(),\n",
    "        \"matches_cohort\": set(),\n",
    "    }\n",
    "    for inflected_phones in infl_phones\n",
    "}\n",
    "for next_unit, rows in tqdm(cdf.groupby(\"next_unit\")):\n",
    "    for inflected_phones in infl_phones:\n",
    "        if len(inflected_phones) > cohort_length and inflected_phones[cohort_length] == next_unit:\n",
    "            all_prediction_equivalences[\" \".join(inflected_phones),][\"matches_next_phoneme_weak\"] |= \\\n",
    "                set(rows.traj_flat_idx)\n",
    "            all_prediction_equivalences[\" \".join(inflected_phones),][\"matches_next_phoneme\"] |= \\\n",
    "                set(rows[rows.frame_idx == cohort_length].traj_flat_idx)\n",
    "for cohort, rows in tqdm(cdf.groupby(\"base_phones\")):\n",
    "    for inflected_phones in infl_phones:\n",
    "        if len(inflected_phones) > cohort_length and \" \".join(inflected_phones[:cohort_length]) == cohort:\n",
    "            all_prediction_equivalences[\" \".join(inflected_phones),][\"matches_cohort\"] |= \\\n",
    "                set(rows[rows.frame_idx >= cohort_length].traj_flat_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (inflected_phones,), equivs in all_prediction_equivalences.items():\n",
    "    equivs[\"matches_cohort_and_next_phoneme\"] = \\\n",
    "        equivs[\"matches_cohort\"] & equivs[\"matches_next_phoneme\"]\n",
    "    equivs[\"matches_cohort_and_next_phoneme_weak\"] = \\\n",
    "        equivs[\"matches_cohort\"] & equivs[\"matches_next_phoneme_weak\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prediction_equivalences = {\n",
    "    key: {k: torch.tensor(list(vs)) for k, vs in equivs.items()}\n",
    "    for key, equivs in all_prediction_equivalences.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdf = cuts_df.reset_index()\n",
    "# for inflected_phones, rows in tqdm(all_instances_df.groupby(\"inflected_phones\")):\n",
    "#     phoneme_match_instances = all_instances_df[all_instances_df.post_divergence == rows.post_divergence.iloc[0]]\n",
    "#     cohort_match_instances = all_instances_df[all_instances_df.base_phones == rows.base_phones.iloc[0]]\n",
    "\n",
    "#     phoneme_match_cuts = cdf.merge(phoneme_match_instances[[\"inflected_idx\", \"inflected_instance_idx\"]],\n",
    "#                         left_on=[\"label_idx\", \"instance_idx\"],\n",
    "#                         right_on=[\"inflected_idx\", \"inflected_instance_idx\"])\n",
    "#     cohort_match_cuts = cdf.merge(cohort_match_instances[[\"inflected_idx\", \"inflected_instance_idx\"]],\n",
    "#                         left_on=[\"label_idx\", \"instance_idx\"],\n",
    "#                         right_on=[\"inflected_idx\", \"inflected_instance_idx\"]) \\\n",
    "#         .query(\"frame_idx >= @cohort_length\")\n",
    "\n",
    "#     strong_phoneme_match_cuts = phoneme_match_cuts[phoneme_match_cuts.frame_idx == cohort_length]\n",
    "#     weak_phoneme_match_cuts = phoneme_match_cuts\n",
    "\n",
    "#     all_prediction_equivalences[(inflected_phones,)]['matches_next_phoneme'].update(\n",
    "#         strong_phoneme_match_cuts.traj_flat_idx)\n",
    "#     all_prediction_equivalences[(inflected_phones,)]['matches_next_phoneme_weak'].update(\n",
    "#         weak_phoneme_match_cuts.traj_flat_idx)\n",
    "#     all_prediction_equivalences[(inflected_phones,)]['matches_cohort'].update(\n",
    "#         cohort_match_cuts.traj_flat_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare prediction equivalences: effectively a set of evaluations which \n",
    "# # can be run on any individual prediction trial, establishing which outputs\n",
    "# # are \"correct\" or incorrect\n",
    "# all_prediction_equivalences = {}\n",
    "\n",
    "# for (base_phones, inflected_phones, next_unit), _ in tqdm(all_instances_df.groupby([\"base_phones\", \"inflected_phones\", \"inflection\"])):\n",
    "#     equiv_key = (inflected_phones,)\n",
    "#     all_prediction_equivalences[equiv_key] = \\\n",
    "#         analogy_pseudocausal.prepare_prediction_equivalences(cuts_df, cut_forms, base_phones, next_unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_inflections = [\n",
    "    {\"base_phones\": cohort,\n",
    "     \"inflected_phones\": f\"{cohort} {unit}\".strip(),\n",
    "     \"counterfactual_inflection\": unit,\n",
    "     \"post_divergence\": unit}\n",
    "    for cohort, next_units in expt_cohort.items()\n",
    "    for unit in next_units\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctf_trials = pd.merge(\n",
    "    all_instances_df[[\"base_phones\", \"inflection\", \"cohort_length\", \"next_phoneme_idx\", \"inflected\", \"inflected_idx\", \"inflected_instance_idx\"]],\n",
    "    pd.DataFrame(counterfactual_inflections))\n",
    "ctf_trials = ctf_trials[ctf_trials.inflection != ctf_trials.counterfactual_inflection]\n",
    "ctf_trials[\"inflection\"] = \"ctf-\" + ctf_trials.counterfactual_inflection\n",
    "ctf_trials = ctf_trials.drop(columns=[\"counterfactual_inflection\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials = pd.concat([ctf_trials, all_instances_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground-truth experiments:\n",
    "# these use arbitrary sources to try to predict the ground-truth next phoneme observed in word tokens\n",
    "gt_experiments = {\n",
    "    f\"gt-{source_inflection}_{prefix}_{target_inflection}\": {\n",
    "        \"base_query\": f\"inflection == '{source_inflection}'\",\n",
    "        \"inflected_query\": f\"base_phones == '{prefix}' and inflection == '{target_inflection}'\",\n",
    "        \"equivalence_keys\": [\"inflected_phones\", \"inflected\"],\n",
    "        \"prediction_equivalence_keys\": [\"to_inflected_phones\"],\n",
    "    }\n",
    "    for source_inflection in next_unit_set\n",
    "    for prefix, valid_next_phones in expt_cohort.items()\n",
    "    for target_inflection in valid_next_phones\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counterfactual experiments:\n",
    "# these use arbitrary sources to try to generate other phoneme completions which are not the\n",
    "# ground-truth next phoneme observed in word tokens, but which are consistent with an attested\n",
    "# word prefix in the lexicon\n",
    "ctf_experiments = {\n",
    "    f\"ctf-{source_inflection}_{prefix}_{target_inflection}\": {\n",
    "        \"base_query\": f\"inflection == '{source_inflection}'\",\n",
    "        \"inflected_query\": f\"base_phones == '{prefix}' and inflection == 'ctf-{target_inflection}'\",\n",
    "        \"equivalence_keys\": [\"inflected_phones\", \"inflected\"],\n",
    "        \"prediction_equivalence_keys\": [\"to_inflected_phones\"],\n",
    "    }\n",
    "    for source_inflection in next_unit_set\n",
    "    for prefix, valid_next_phones in expt_cohort.items()\n",
    "    for target_inflection in valid_next_phones\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    # **gt_experiments,\n",
    "    **ctf_experiments,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO reinstate this\n",
    "# small_targets = all_instances_df[all_instances_df.inflection.str.startswith(\"small-\")].inflection.str.split(\"small-\").str[1].unique()\n",
    "# for phone in small_targets:\n",
    "#     for source_phone in next_phon_set:\n",
    "#         experiments[f\"{source_phone}-to-small-{phone}\"] = {\n",
    "#             \"base_query\": f\"inflection == '{source_phone}'\",\n",
    "#             \"inflected_query\": f\"inflection == 'small-{phone}'\",\n",
    "#             \"equivalence_keys\": [\"inflected_phones\", \"inflected\"],\n",
    "#             \"prediction_equivalence_keys\": [\"to_inflected_phones\"],\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctf_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def go():\n",
    "#     name = \"ctf-DH_AH N_M\"\n",
    "#     ret = analogy_pseudocausal.run_experiment_equiv_level(\n",
    "#         name,\n",
    "#         experiments[name],\n",
    "#         state_space_spec, all_trials,\n",
    "#         agg, agg_src,\n",
    "#         cut_phonemic_forms=cut_forms,\n",
    "#         prediction_equivalences=all_prediction_equivalences,\n",
    "#         verbose=True,\n",
    "#         num_samples=5,\n",
    "#         max_num_vector_samples=100,\n",
    "#         seed=seed,\n",
    "#     device=\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext line_profiler\n",
    "# %lprun -f analogy_pseudocausal.run_experiment_equiv_level go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "t_agg = torch.tensor(agg, device=device)\n",
    "t_agg_src = torch.tensor(agg_src, device=device)\n",
    "\n",
    "# pre-compute flat idx lookup\n",
    "flat_idx_lookup = {(label_idx, instance_idx, phoneme_idx): flat_idx\n",
    "                    for flat_idx, (label_idx, instance_idx, phoneme_idx) in enumerate(agg_src)}\n",
    "\n",
    "experiment_results = pd.concat({\n",
    "    experiment: analogy_pseudocausal.run_experiment_equiv_level(\n",
    "        experiment, config,\n",
    "        state_space_spec, all_trials,\n",
    "        t_agg, t_agg_src,\n",
    "        flat_idx_lookup=flat_idx_lookup,\n",
    "        cut_phonemic_forms=cut_forms,\n",
    "        prediction_equivalences=all_prediction_equivalences,\n",
    "        num_samples=50,\n",
    "        max_num_vector_samples=100,\n",
    "        seed=seed,\n",
    "        device=device)\n",
    "    for experiment, config in tqdm(experiments.items(), unit=\"experiment\")\n",
    "}, names=[\"experiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results[\"control\"] = experiment_results.inflection_to.str.split(\"-\").str[-1] != experiment_results.inflection_from\n",
    "experiment_results[\"ctf\"] = experiment_results.inflection_to.str.startswith(\"ctf-\")\n",
    "experiment_results[\"inflection_to_clean\"] = experiment_results.inflection_to.str.replace(\"^[a-z]+-\", \"\", regex=True)\n",
    "experiment_results.to_csv(f\"{output_dir}/experiment_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

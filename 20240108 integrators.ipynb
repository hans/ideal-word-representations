{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm.auto import tqdm, trange\n",
    "import transformers\n",
    "\n",
    "from src.datasets.speech_equivalence import \\\n",
    "    SpeechEquivalenceDataset, SpeechHiddenStateDataset, make_timit_equivalence_dataset\n",
    "from src.models.integrator import ContrastiveEmbeddingModel, ContrastiveEmbeddingModelConfig, \\\n",
    "    prepare_dataset, compute_metrics\n",
    "from src.utils.timit import load_or_prepare_timit_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/wav2vec2-base\"\n",
    "\n",
    "equivalence_classer = \"word_suffix\"\n",
    "num_frames_per_phoneme = 1\n",
    "\n",
    "layer = 6\n",
    "output_dim = 32\n",
    "\n",
    "equiv_dataset_path = f\"data/timit_equiv_{equivalence_classer}_{layer}_{num_frames_per_phoneme}.pkl\"\n",
    "output_dir = f\"out/ce_model_{equivalence_classer}_{layer}_{output_dim}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare equivalence class dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "/Users/jon/miniforge3/envs/explore310/lib/python3.10/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:792: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.Wav2Vec2Tokenizer.from_pretrained(\"charsiu/tokenizer_en_cmu\")\n",
    "feature_extractor = transformers.Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=False)\n",
    "processor = transformers.Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jon/miniforge3/envs/explore310/lib/python3.10/site-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model: transformers.Wav2Vec2Model = transformers.Wav2Vec2Model.from_pretrained(model_name)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_or_prepare_timit_corpus(\"data/timit_phonemes\", \"data/timit_raw\",\n",
    "                                       processor)\n",
    "\n",
    "def add_indices(item, idx):\n",
    "    item[\"idx\"] = idx\n",
    "    return item\n",
    "dataset = dataset.map(add_indices, batched=True, batch_size=2000, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = dataset[\"train\"] if isinstance(dataset, datasets.DatasetDict) else dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49aadc866c34d56a6f69e4141b67c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting hidden states:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db027e9ac1144be9f6bbf87f1ff3927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing start frames:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if Path(equiv_dataset_path).exists():\n",
    "    with open(equiv_dataset_path, \"rb\") as f:\n",
    "        equiv_dataset = pickle.load(f)\n",
    "else:\n",
    "    equiv_dataset = make_timit_equivalence_dataset(\n",
    "        f\"timit_phoneme/{equivalence_classer}\",\n",
    "        dev_dataset, model, layer,\n",
    "        equivalence_classer,\n",
    "        num_frames_per_phoneme=num_frames_per_phoneme)\n",
    "\n",
    "    with open(equiv_dataset_path, \"wb\") as f:\n",
    "        pickle.dump(equiv_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpeechEquivalenceDataset(timit_phoneme/word_suffix, 3725 classes, 15802 instances, with SpeechHiddenStateDataset(facebook/wav2vec2-base, 500 items, 75836 frames, 1 layers, 768 hidden size))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equiv_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compute how many positive examples each Q lines up. we want to make sure we have a minimal\n",
    "# number of positive examples for each Q, even the sparse word-level ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pick a max length that accommodates the majority of the samples, excluding outlier lengths\n",
    "evident_lengths = equiv_dataset.lengths\n",
    "evident_lengths = evident_lengths[evident_lengths != -1]\n",
    "target_length = int(torch.quantile(evident_lengths.double(), 0.95).item())\n",
    "sns.histplot(evident_lengths.numpy(), discrete=True)\n",
    "target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5572a2926d57452999a09bb5887f78f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb8abbc96bc43ba98b43f0195753e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/7 shards):   0%|          | 0/13037 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_path = Path(output_dir) / \"dataset\"\n",
    "if dataset_path.exists():\n",
    "    ce_dataset = datasets.load_from_disk(dataset_path)\n",
    "else:\n",
    "    ce_dataset = prepare_dataset(equiv_dataset, target_length)\n",
    "    Path(output_dir).mkdir(exist_ok=True, parents=True)\n",
    "    ce_dataset.save_to_disk(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_model_config = ContrastiveEmbeddingModelConfig(\n",
    "    base_model_ref=model_name,\n",
    "    base_model_layer=layer,\n",
    "\n",
    "    equivalence_classer=equivalence_classer,\n",
    "\n",
    "    max_length=target_length,\n",
    "    input_dim=equiv_dataset.hidden_state_dataset.hidden_size,\n",
    "    hidden_dim=32,\n",
    "    output_dim=output_dim,\n",
    "    tau=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_model = ContrastiveEmbeddingModel(ce_model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Trainer.__init__() got an unexpected keyword argument 'label_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m dataset_split[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     24\u001b[0m eval_dataset \u001b[38;5;241m=\u001b[39m dataset_split[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 25\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mce_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexample_idx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# data_collator=MyCollator(max_length),\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStoppingCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Trainer.__init__() got an unexpected keyword argument 'label_names'"
     ]
    }
   ],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=32,\n",
    "    save_steps=100,\n",
    "    eval_steps=2,  # 100\n",
    "    save_total_limit=5,\n",
    "    logging_steps=2, # 10\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_first_step=True,\n",
    "    load_best_model_at_end=True,\n",
    "    greater_is_better=False,\n",
    "    remove_unused_columns=False,\n",
    "    save_safetensors=False,\n",
    "    \n",
    "    include_inputs_for_metrics=True,\n",
    "    label_names=[\"example_idx\"],\n",
    "\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "\n",
    "dataset_split = ce_dataset.train_test_split(test_size=0.05, shuffle=True)\n",
    "train_dataset = dataset_split[\"train\"]\n",
    "eval_dataset = dataset_split[\"test\"]\n",
    "trainer = transformers.Trainer(\n",
    "    model=ce_model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    # data_collator=MyCollator(max_length),\n",
    "    callbacks=[transformers.EarlyStoppingCallback(3)],\n",
    "    args=training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c90e9be18454ad1a4194282e62a466d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/776 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': -0.6998, 'learning_rate': 0.0009987113402061855, 'epoch': 0.0}\n",
      "{'loss': -0.3867, 'learning_rate': 0.0009974226804123712, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a232623613440f995d9a989ccfbd64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/jon/Projects/ideal-word-representations/src/models/integrator.py\u001b[0m(277)\u001b[0;36mcompute_metrics\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    276 \u001b[0;31m    return {\n",
      "\u001b[0m\u001b[0;32m--> 277 \u001b[0;31m        \u001b[0;34m\"embedding_norm\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    278 \u001b[0;31m    }\n",
      "\u001b[0m\n",
      "*** AttributeError: 'EvalPrediction' object has no attribute 'labels'\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

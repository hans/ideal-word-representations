{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm.auto import tqdm, trange\n",
    "import transformers\n",
    "\n",
    "from src.datasets.speech_equivalence import \\\n",
    "    SpeechEquivalenceDataset, SpeechHiddenStateDataset, make_timit_equivalence_dataset\n",
    "from src.models.integrator import ContrastiveEmbeddingModel, ContrastiveEmbeddingModelConfig, prepare_dataset\n",
    "from src.utils.timit import load_or_prepare_timit_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/wav2vec2-base\"\n",
    "\n",
    "equivalence_classer = \"phoneme\"\n",
    "num_frames_per_phoneme = 1\n",
    "\n",
    "layer = 6\n",
    "output_dim = 8\n",
    "\n",
    "equiv_dataset_path = f\"data/timit_equiv_{equivalence_classer}_{layer}_{num_frames_per_phoneme}.pkl\"\n",
    "output_dir = f\"out/ce_model_{equivalence_classer}_{layer}_{output_dim}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare equivalence class dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "/Users/jon/miniforge3/envs/explore310/lib/python3.10/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:792: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.Wav2Vec2Tokenizer.from_pretrained(\"charsiu/tokenizer_en_cmu\")\n",
    "feature_extractor = transformers.Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=False)\n",
    "processor = transformers.Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jon/miniforge3/envs/explore310/lib/python3.10/site-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model: transformers.Wav2Vec2Model = transformers.Wav2Vec2Model.from_pretrained(model_name)\n",
    "# model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_or_prepare_timit_corpus(\"data/timit_phoneme_dev\", \"data/timit_raw\",\n",
    "                                       processor)\n",
    "\n",
    "def add_indices(item, idx):\n",
    "    item[\"idx\"] = idx\n",
    "    return item\n",
    "dataset = dataset.map(add_indices, batched=True, batch_size=2000, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = dataset.select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e2d76b855d4dedafa1f8346b241093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting hidden states:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c87fa0b1a0f4e1885bcc5efc4d83058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing start frames:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "equiv_dataset = make_timit_equivalence_dataset(\n",
    "    f\"timit_phoneme/{equivalence_classer}\",\n",
    "    dev_dataset, model, layer,\n",
    "    equivalence_classer,\n",
    "    num_frames_per_phoneme=num_frames_per_phoneme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(equiv_dataset_path, \"wb\") as f:\n",
    "    pickle.dump(equiv_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpeechEquivalenceDataset(timit_phoneme/phoneme, 39 classes, 282 instances, with SpeechHiddenStateDataset(facebook/wav2vec2-base, 10 items, 1196 frames, 1 layers, 768 hidden size))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equiv_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compute how many positive examples each Q lines up. we want to make sure we have a minimal\n",
    "# number of positive examples for each Q, even the sparse word-level ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pick a max length that accommodates the majority of the samples, excluding outlier lengths\n",
    "evident_lengths = equiv_dataset.lengths\n",
    "evident_lengths = evident_lengths[evident_lengths != -1]\n",
    "target_length = int(torch.quantile(evident_lengths.double(), 0.95).item())\n",
    "sns.histplot(evident_lengths.numpy(), discrete=True)\n",
    "target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8109f0712a499aa5244505f521366e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ce_dataset = prepare_dataset(equiv_dataset, target_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bc4ab9b8b64506aeb3f5dbf01d2bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/278 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Path(output_dir).mkdir(exist_ok=True, parents=True)\n",
    "ce_dataset.save_to_disk(Path(output_dir) / \"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_model_config = ContrastiveEmbeddingModelConfig(\n",
    "    base_model_ref=model_name,\n",
    "    base_model_layer=layer,\n",
    "\n",
    "    equivalence_classer=equivalence_classer,\n",
    "\n",
    "    max_length=target_length,\n",
    "    input_dim=equiv_dataset.hidden_state_dataset.hidden_size,\n",
    "    hidden_dim=32,\n",
    "    output_dim=output_dim,\n",
    "    tau=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_model = ContrastiveEmbeddingModel(ce_model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=32,\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    save_total_limit=5,\n",
    "    logging_steps=10,\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_first_step=True,\n",
    "    load_best_model_at_end=True,\n",
    "    greater_is_better=False,\n",
    "    remove_unused_columns=False,\n",
    "\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "\n",
    "dataset_split = ce_dataset.train_test_split(test_size=0.1, shuffle=True)\n",
    "train_dataset = dataset_split[\"train\"]\n",
    "eval_dataset = dataset_split[\"test\"]\n",
    "trainer = transformers.Trainer(\n",
    "    model=ce_model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    # compute_metrics=compute_metrics,\n",
    "    # data_collator=MyCollator(max_length),\n",
    "    args=training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb742313369471e9557585bc8557a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': -0.4832, 'learning_rate': 0.0009375, 'epoch': 0.12}\n",
      "{'loss': -0.5325, 'learning_rate': 0.000375, 'epoch': 1.25}\n",
      "{'train_runtime': 4.4698, 'train_samples_per_second': 111.862, 'train_steps_per_second': 3.58, 'train_loss': -0.5007037743926048, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16, training_loss=-0.5007037743926048, metrics={'train_runtime': 4.4698, 'train_samples_per_second': 111.862, 'train_steps_per_second': 3.58, 'train_loss': -0.5007037743926048, 'epoch': 2.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

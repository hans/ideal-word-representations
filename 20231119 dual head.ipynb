{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import transformers\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.frame_level import FrameLevelLexicalAccess, \\\n",
    "    LexicalAccessConfig, LexicalAccessDataCollator\n",
    "from src.models.transformer import drop_wav2vec_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_target_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_init(\n",
    "        model_name_or_path,\n",
    "        config, \n",
    "        word_vocabulary, word_representations,\n",
    "        device=\"cpu\"):\n",
    "    def model_init(trial):\n",
    "        encoder = transformers.Wav2Vec2Model.from_pretrained(\n",
    "            model_name_or_path, config=config.encoder_config).to(device)\n",
    "        model = FrameLevelLexicalAccess(\n",
    "            config, word_vocabulary, word_representations,\n",
    "            encoder=encoder).to(device)\n",
    "\n",
    "        model.freeze_feature_extractor()\n",
    "\n",
    "        if config.drop_encoder_layers is not None:\n",
    "            model.encoder = drop_wav2vec_layers(model.encoder, config.drop_encoder_layers)\n",
    "\n",
    "        if config.reinit_feature_extractor_weights:\n",
    "            model.encoder.feature_extractor.apply(lambda x: model.encoder._init_weights(x))\n",
    "        if config.reinit_encoder_weights:\n",
    "            model.encoder.encoder.apply(lambda x: model.encoder._init_weights(x))\n",
    "\n",
    "        # Freeze all model weights.\n",
    "        for param in model.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        return model\n",
    "    return model_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_from_disk(\"./data/timit_phoneme/\")\n",
    "dataset_split = dataset[\"train\"].train_test_split(test_size=0.1, shuffle=True)\n",
    "train_dataset = dataset_split[\"train\"]\n",
    "eval_dataset = dataset_split[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare semantic representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a9c8fc026f4912884701a602df6ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4620 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c86ac08bbf488f9c54c2bd4cbc9293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"'em\",\n",
       " 'a',\n",
       " 'abbreviate',\n",
       " 'abdomen',\n",
       " 'abides',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'ably',\n",
       " 'abolish',\n",
       " 'aborigine']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = set()\n",
    "def update_all_words(item):\n",
    "    all_words.update(set(item[\"word_detail\"][\"utterance\"]))\n",
    "    return None\n",
    "dataset.map(update_all_words)\n",
    "\n",
    "all_words = sorted(all_words)\n",
    "all_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_representations = torch.randn(len(all_words), regressor_target_size)\n",
    "word_representations /= word_representations.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:792: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.Wav2Vec2Tokenizer.from_pretrained(\"charsiu/tokenizer_en_cmu\")\n",
    "model = transformers.Wav2Vec2ForCTC.from_pretrained(\"charsiu/en_w2v2_ctc_libris_and_cv\")\n",
    "feature_extractor = transformers.Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=False)\n",
    "processor = transformers.Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_config = transformers.AutoConfig.from_pretrained(\n",
    "    \"facebook/wav2vec2-base\")\n",
    "model_config = LexicalAccessConfig(\n",
    "    encoder_config=encoder_config.to_dict(),\n",
    "    drop_encoder_layers=6,\n",
    "    num_labels=tokenizer.vocab_size,\n",
    "    regressor_target_size=regressor_target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_init = make_model_init(\n",
    "    \"charsiu/en_w2v2_ctc_libris_and_cv\", model_config,\n",
    "    all_words, word_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = LexicalAccessDataCollator(\n",
    "    processor=processor,\n",
    "    model=model_init(None),\n",
    "    padding=True,\n",
    "    num_labels=tokenizer.vocab_size,\n",
    "    regression_target_size=regressor_target_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classifier_metrics(p: transformers.EvalPrediction) -> dict:\n",
    "    assert isinstance(p.predictions, tuple)\n",
    "    preds = p.predictions[0]\n",
    "    label_mask, labels, _ = p.label_ids\n",
    "\n",
    "    def evaluate_label(j):\n",
    "        preds_j = preds[:, :, j]\n",
    "        labels_j = labels[:, :, j]\n",
    "\n",
    "        preds_j = preds_j[label_mask == 1]\n",
    "        labels_j = labels_j[label_mask == 1]\n",
    "        if labels_j.std() == 0:\n",
    "            # Only one class. Quit\n",
    "            return None\n",
    "        return roc_auc_score(labels_j, preds_j)\n",
    "\n",
    "    roc_auc_scores = [evaluate_label(j) for j in range(preds.shape[-1])]\n",
    "    return {\"roc_auc\": np.mean([score for score in roc_auc_scores if score is not None])}\n",
    "\n",
    "\n",
    "def compute_regressor_metrics(p: transformers.EvalPrediction) -> dict:\n",
    "    assert isinstance(p.predictions, tuple)\n",
    "    preds = p.predictions[1]\n",
    "    target_mask, _, targets = p.label_ids\n",
    "\n",
    "    preds = preds[target_mask == 1]\n",
    "    targets = targets[target_mask == 1]\n",
    "\n",
    "    return {\"mse\": ((preds - targets) ** 2).mean().item()}\n",
    "\n",
    "\n",
    "def compute_metrics_dual_head(p: transformers.EvalPrediction):\n",
    "    return {\n",
    "        **compute_classifier_metrics(p),\n",
    "        **compute_regressor_metrics(p)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./tst_dual_head\",\n",
    "    per_device_train_batch_size=8,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=5,\n",
    "    gradient_accumulation_steps=2,\n",
    "    save_steps=50,\n",
    "    eval_steps=50,\n",
    "    logging_steps=2,\n",
    "    learning_rate=1e-2,\n",
    "    save_total_limit=5,\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    label_names=[\"target_mask\", \"classifier_labels\", \"regressor_targets\"],\n",
    "    disable_tqdm=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    args=training_args,\n",
    "    data_collator=collator,\n",
    "    model=None, model_init=model_init,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics_dual_head,\n",
    "    tokenizer=processor.tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3496, 'learning_rate': 0.006666666666666666, 'epoch': 0.31}\n",
      "{'eval_loss': 0.26008492708206177, 'eval_roc_auc': 0.4858707499653592, 'eval_mse': 0.10612313449382782, 'eval_runtime': 14.3662, 'eval_samples_per_second': 32.159, 'eval_steps_per_second': 4.037, 'epoch': 0.31}\n",
      "{'loss': 0.232, 'learning_rate': 0.003333333333333333, 'epoch': 0.62}\n",
      "{'eval_loss': 0.181578129529953, 'eval_roc_auc': 0.49654516446804225, 'eval_mse': 0.04297766461968422, 'eval_runtime': 13.9539, 'eval_samples_per_second': 33.109, 'eval_steps_per_second': 4.157, 'epoch': 0.62}\n",
      "{'loss': 0.1735, 'learning_rate': 0.0, 'epoch': 0.92}\n",
      "{'eval_loss': 0.1679603010416031, 'eval_roc_auc': 0.5146918944178374, 'eval_mse': 0.041869502514600754, 'eval_runtime': 13.8624, 'eval_samples_per_second': 33.328, 'eval_steps_per_second': 4.184, 'epoch': 0.92}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jgauthier/u/projects/ideal-word-representations/20231119 dual head.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bspirit/home/jgauthier/u/projects/ideal-word-representations/20231119%20dual%20head.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1556\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1557\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1558\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1559\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1560\u001b[0m     )\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/trainer.py:1972\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1969\u001b[0m     \u001b[39melif\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   1970\u001b[0m         smp\u001b[39m.\u001b[39mbarrier()\n\u001b[0;32m-> 1972\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_best_model()\n\u001b[1;32m   1974\u001b[0m \u001b[39m# add remaining tr_loss\u001b[39;00m\n\u001b[1;32m   1975\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_total_loss_scalar \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/trainer.py:2194\u001b[0m, in \u001b[0;36mTrainer._load_best_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2189\u001b[0m         state_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(best_model_path, map_location\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2191\u001b[0m     \u001b[39m# If the model is on the GPU, it still works!\u001b[39;00m\n\u001b[1;32m   2192\u001b[0m     \u001b[39m# workaround for FSDP bug https://github.com/pytorch/pytorch/issues/82963\u001b[39;00m\n\u001b[1;32m   2193\u001b[0m     \u001b[39m# which takes *args instead of **kwargs\u001b[39;00m\n\u001b[0;32m-> 2194\u001b[0m     load_result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mload_state_dict(state_dict, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   2195\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_sagemaker_mp_enabled() \u001b[39mand\u001b[39;00m has_been_loaded:\n\u001b[1;32m   2196\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_issue_warnings_after_load(load_result)\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/torch/nn/modules/module.py:2027\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2020\u001b[0m         out \u001b[39m=\u001b[39m hook(module, incompatible_keys)\n\u001b[1;32m   2021\u001b[0m         \u001b[39massert\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m, (\n\u001b[1;32m   2022\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mHooks registered with ``register_load_state_dict_post_hook`` are not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2023\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mexpected to return new values, if incompatible_keys need to be modified,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2024\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mit should be done inplace.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2025\u001b[0m         )\n\u001b[0;32m-> 2027\u001b[0m load(\u001b[39mself\u001b[39;49m, state_dict)\n\u001b[1;32m   2028\u001b[0m \u001b[39mdel\u001b[39;00m load\n\u001b[1;32m   2030\u001b[0m \u001b[39mif\u001b[39;00m strict:\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/torch/nn/modules/module.py:2015\u001b[0m, in \u001b[0;36mModule.load_state_dict.<locals>.load\u001b[0;34m(module, local_state_dict, prefix)\u001b[0m\n\u001b[1;32m   2013\u001b[0m         child_prefix \u001b[39m=\u001b[39m prefix \u001b[39m+\u001b[39m name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2014\u001b[0m         child_state_dict \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m local_state_dict\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k\u001b[39m.\u001b[39mstartswith(child_prefix)}\n\u001b[0;32m-> 2015\u001b[0m         load(child, child_state_dict, child_prefix)\n\u001b[1;32m   2017\u001b[0m \u001b[39m# Note that the hook can modify missing_keys and unexpected_keys.\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m incompatible_keys \u001b[39m=\u001b[39m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/torch/nn/modules/module.py:2015\u001b[0m, in \u001b[0;36mModule.load_state_dict.<locals>.load\u001b[0;34m(module, local_state_dict, prefix)\u001b[0m\n\u001b[1;32m   2013\u001b[0m         child_prefix \u001b[39m=\u001b[39m prefix \u001b[39m+\u001b[39m name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2014\u001b[0m         child_state_dict \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m local_state_dict\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k\u001b[39m.\u001b[39mstartswith(child_prefix)}\n\u001b[0;32m-> 2015\u001b[0m         load(child, child_state_dict, child_prefix)\n\u001b[1;32m   2017\u001b[0m \u001b[39m# Note that the hook can modify missing_keys and unexpected_keys.\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m incompatible_keys \u001b[39m=\u001b[39m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "    \u001b[0;31m[... skipping similar frames: Module.load_state_dict.<locals>.load at line 2015 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/torch/nn/modules/module.py:2015\u001b[0m, in \u001b[0;36mModule.load_state_dict.<locals>.load\u001b[0;34m(module, local_state_dict, prefix)\u001b[0m\n\u001b[1;32m   2013\u001b[0m         child_prefix \u001b[39m=\u001b[39m prefix \u001b[39m+\u001b[39m name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2014\u001b[0m         child_state_dict \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m local_state_dict\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k\u001b[39m.\u001b[39mstartswith(child_prefix)}\n\u001b[0;32m-> 2015\u001b[0m         load(child, child_state_dict, child_prefix)\n\u001b[1;32m   2017\u001b[0m \u001b[39m# Note that the hook can modify missing_keys and unexpected_keys.\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m incompatible_keys \u001b[39m=\u001b[39m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/torch/nn/modules/module.py:2009\u001b[0m, in \u001b[0;36mModule.load_state_dict.<locals>.load\u001b[0;34m(module, local_state_dict, prefix)\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(module, local_state_dict, prefix\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   2008\u001b[0m     local_metadata \u001b[39m=\u001b[39m {} \u001b[39mif\u001b[39;00m metadata \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m metadata\u001b[39m.\u001b[39mget(prefix[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], {})\n\u001b[0;32m-> 2009\u001b[0m     module\u001b[39m.\u001b[39;49m_load_from_state_dict(\n\u001b[1;32m   2010\u001b[0m         local_state_dict, prefix, local_metadata, \u001b[39mTrue\u001b[39;49;00m, missing_keys, unexpected_keys, error_msgs)\n\u001b[1;32m   2011\u001b[0m     \u001b[39mfor\u001b[39;00m name, child \u001b[39min\u001b[39;00m module\u001b[39m.\u001b[39m_modules\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   2012\u001b[0m         \u001b[39mif\u001b[39;00m child \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/torch/nn/modules/module.py:1942\u001b[0m, in \u001b[0;36mModule._load_from_state_dict\u001b[0;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[1;32m   1940\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1941\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m-> 1942\u001b[0m         param\u001b[39m.\u001b[39;49mcopy_(input_param)\n\u001b[1;32m   1943\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m   1944\u001b[0m     error_msgs\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39mWhile copying the parameter named \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1945\u001b[0m                       \u001b[39m'\u001b[39m\u001b[39mwhose dimensions in the model are \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1946\u001b[0m                       \u001b[39m'\u001b[39m\u001b[39mwhose dimensions in the checkpoint are \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1947\u001b[0m                       \u001b[39m'\u001b[39m\u001b[39man exception occurred : \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1948\u001b[0m                       \u001b[39m.\u001b[39mformat(key, param\u001b[39m.\u001b[39msize(), input_param\u001b[39m.\u001b[39msize(), ex\u001b[39m.\u001b[39margs))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roll out on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_decision_thresholds(trainer: transformers.Trainer):\n",
    "    assert trainer.eval_dataset is not None\n",
    "\n",
    "    trainer.model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = trainer.predict(trainer.eval_dataset)\n",
    "        label_mask, labels, _ = preds.label_ids\n",
    "        preds = preds.predictions[0] if isinstance(preds.predictions, tuple) else preds.predictions\n",
    "\n",
    "    # Get optimal cut-off for each label\n",
    "    optimal_thresholds = []\n",
    "    fpr, tpr, thresholds = [], [], []\n",
    "    # roc_aucs = []\n",
    "    for j in range(preds.shape[-1]):\n",
    "        preds_j = preds[:, :, j]\n",
    "        labels_j = labels[:, :, j]\n",
    "\n",
    "        mask = label_mask == 1\n",
    "        preds_j = preds_j[mask]\n",
    "        labels_j = labels_j[mask]\n",
    "\n",
    "        fpr_j, tpr_j, thresholds_j = roc_curve(labels_j, preds_j, pos_label=1)\n",
    "        fpr.append(fpr_j)\n",
    "        tpr.append(tpr_j)\n",
    "        thresholds.append(thresholds_j)\n",
    "\n",
    "        optimal_thresholds.append(thresholds_j[np.argmax(tpr_j - fpr_j)])\n",
    "\n",
    "    return torch.tensor(optimal_thresholds)\n",
    "\n",
    "def rollout_dataset(trainer, dataset, optimal_thresholds: torch.FloatTensor) -> datasets.Dataset:\n",
    "    \"\"\"\n",
    "    Roll out on a new dataset; return a new dataset containing both the original\n",
    "    inputs and the internal states, predictions, and accuracies produced\n",
    "    during the model evaluation.\n",
    "    \"\"\"\n",
    "    trainer.model.eval()\n",
    "    with torch.no_grad():\n",
    "        dataset_preds = trainer.predict(dataset)\n",
    "\n",
    "    def add_model_outputs(batch, idxs):\n",
    "        eval_logits, eval_targets, rnn_states = dataset_preds.predictions\n",
    "        logits = eval_logits[idxs]\n",
    "        preds = (logits > optimal_thresholds.numpy()).astype(int)\n",
    "\n",
    "        # Internals\n",
    "        batch[\"rnn_hidden_states\"] = rnn_states[idxs]\n",
    "\n",
    "        # Classifier outputs\n",
    "        batch[\"logits\"] = logits\n",
    "        batch[\"distance_from_decision_threshold\"] = logits - optimal_thresholds.numpy()\n",
    "        batch[\"predicted_labels\"] = preds\n",
    "\n",
    "        # Regressor outputs\n",
    "        batch[\"regression_output\"] = eval_targets[idxs]\n",
    "\n",
    "        return batch\n",
    "\n",
    "    result = dataset.map(add_model_outputs, batched=True, batch_size=8, with_indices=True)\n",
    "\n",
    "    def compute_accuracy(item, idx):\n",
    "        label_mask, labels, _ = dataset_preds.label_ids\n",
    "        label_mask = label_mask[idx] == 1\n",
    "        labels = labels[idx]\n",
    "\n",
    "        item[\"real_frames\"] = label_mask.sum()\n",
    "        item[\"labels\"] = labels[label_mask]\n",
    "        item[\"compression_ratio\"] = item[\"real_frames\"] / len(item[\"input_values\"])\n",
    "        item[\"correct\"] = (np.array(item[\"predicted_labels\"])[label_mask] == labels[label_mask])\n",
    "        item[\"fp\"] = (np.array(item[\"predicted_labels\"])[label_mask] == 1) & (labels[label_mask] == 0)\n",
    "        item[\"fn\"] = (np.array(item[\"predicted_labels\"])[label_mask] == 0) & (labels[label_mask] == 1)\n",
    "        item[\"tp\"] = (np.array(item[\"predicted_labels\"])[label_mask] == 1) & (labels[label_mask] == 1)\n",
    "        item[\"tn\"] = (np.array(item[\"predicted_labels\"])[label_mask] == 0) & (labels[label_mask] == 0)\n",
    "        item[\"accuracy\"] = item[\"correct\"].mean()\n",
    "        return item\n",
    "\n",
    "    result = result.map(compute_accuracy, batched=False, with_indices=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/userdata/jgauthier/transformers/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1132: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/userdata/jgauthier/transformers/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1132: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimal_thresholds = estimate_decision_thresholds(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55ae4f9d9e545078db3ca6a357e7489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5844bf581cc4d12a86ac0ab97878256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_result = rollout_dataset(trainer, dataset[\"test\"], optimal_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns which are redundant and take up lots of space\n",
    "test_result = test_result.remove_columns([\"audio\", \"input_values\", \"phone_targets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5dc18d5cae4f39850add2322349c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/1680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_result.save_to_disk(Path(trainer.args.output_dir) / \"test_result\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.frame_level import FrameLevelLexicalAccess, \\\n",
    "    LexicalAccessConfig, LexicalAccessDataCollator\n",
    "from src.models.transformer import drop_wav2vec_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_target_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_init(\n",
    "        model_name_or_path,\n",
    "        config, \n",
    "        word_vocabulary, word_representations,\n",
    "        device=\"cpu\"):\n",
    "    def model_init(trial):\n",
    "        encoder = transformers.Wav2Vec2Model.from_pretrained(\n",
    "            model_name_or_path, config=config.encoder_config).to(device)\n",
    "        model = FrameLevelLexicalAccess(\n",
    "            config, word_vocabulary, word_representations,\n",
    "            encoder=encoder).to(device)\n",
    "\n",
    "        model.freeze_feature_extractor()\n",
    "\n",
    "        if hasattr(config, \"drop_layers\"):\n",
    "            model.encoder = drop_wav2vec_layers(model.encoder, config.drop_layers)\n",
    "\n",
    "        if getattr(config, \"reinit_feature_extractor_weights\", False):\n",
    "            model.encoder.feature_extractor.apply(lambda x: model.encoder._init_weights(x))\n",
    "        if getattr(config, \"reinit_encoder_weights\", False):\n",
    "            model.encoder.encoder.apply(lambda x: model.encoder._init_weights(x))\n",
    "\n",
    "        # Freeze all model weights.\n",
    "        for param in model.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        return model\n",
    "    return model_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:792: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.Wav2Vec2Tokenizer.from_pretrained(\n",
    "    \"charsiu/tokenizer_en_cmu\")\n",
    "feature_extractor = transformers.Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000)\n",
    "processor = transformers.Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_from_disk(\"./data/timit_phoneme/\")\n",
    "dataset_split = dataset[\"train\"].train_test_split(test_size=0.1, shuffle=True)\n",
    "train_dataset = dataset_split[\"train\"]\n",
    "eval_dataset = dataset_split[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare semantic representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72059e8c671040d082b9806a1d6571d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4620 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef14986feaa4b668659077a74aa4f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"'em\",\n",
       " 'a',\n",
       " 'abbreviate',\n",
       " 'abdomen',\n",
       " 'abides',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'ably',\n",
       " 'abolish',\n",
       " 'aborigine']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = set()\n",
    "def update_all_words(item):\n",
    "    all_words.update(set(item[\"word_detail\"][\"utterance\"]))\n",
    "    return None\n",
    "dataset.map(update_all_words)\n",
    "\n",
    "all_words = sorted(all_words)\n",
    "all_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_representations = np.random.randint(\n",
    "    0, 2, (len(all_words), regressor_target_size))\n",
    "word_representations = torch.tensor(word_representations, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6102, 32])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_representations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoder_config = transformers.AutoConfig.from_pretrained(\n",
    "    \"facebook/wav2vec2-base\")\n",
    "model_config = LexicalAccessConfig(\n",
    "    encoder_config=encoder_config,\n",
    "    classifier_num_labels=tokenizer.vocab_size,\n",
    "    regressor_target_size=regressor_target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:792: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.Wav2Vec2Tokenizer.from_pretrained(\"charsiu/tokenizer_en_cmu\")\n",
    "model = transformers.Wav2Vec2ForCTC.from_pretrained(\"charsiu/en_w2v2_ctc_libris_and_cv\")\n",
    "feature_extractor = transformers.Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=False)\n",
    "processor = transformers.Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_init = make_model_init(\n",
    "    \"charsiu/en_w2v2_ctc_libris_and_cv\", model_config,\n",
    "    all_words, word_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = LexicalAccessDataCollator(\n",
    "    processor=processor,\n",
    "    model=model_init(None),\n",
    "    padding=True,\n",
    "    num_labels=tokenizer.vocab_size,\n",
    "    regression_target_size=regressor_target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input_values'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(collator(train_dataset.select(range(2)))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare state space trajectories for a phoneme position analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from typing import Any\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from src.analysis.state_space import StateSpaceAnalysisSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a word-level equivalence dataset regardless of model, so that we can look up cohort facts\n",
    "equiv_dataset_path = \"data/timit_equiv_phoneme_within_word_prefix_6_1.pkl\"\n",
    "timit_corpus_path = \"data/timit_syllables\"\n",
    "\n",
    "out1 = \"out/state_space_specs/all_phonemes_by_position.pkl\"\n",
    "out2 = \"out/state_space_specs/all_phonemes_by_identity.pkl\"\n",
    "\n",
    "out_syllable_position = \"out/state_space_specs/all_phonemes_by_syllable_position.pkl\"\n",
    "out_identity_syllable_position = \"out/state_space_specs/all_phonemes_by_identity_and_syllable_position.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(equiv_dataset_path, \"rb\") as f:\n",
    "    equiv_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit_corpus = datasets.load_from_disk(timit_corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(type(label) == tuple for label in equiv_dataset.class_labels), \"Assumes dataset with word prefix labels\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare cohort data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "equiv_frames_by_item = equiv_dataset.hidden_state_dataset.frames_by_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b27633f0d414d08a773974cbe191b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4620 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['file', 'audio', 'text', 'phonetic_detail', 'word_detail', 'dialect_region', 'sentence_type', 'speaker_id', 'id', 'word_phonetic_detail', 'input_values', 'phone_targets', 'phonemic_detail', 'word_phonemic_detail', 'word_syllable_detail'],\n",
       "    num_rows: 4620\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_spans_by_phoneme = defaultdict(list)\n",
    "frame_spans_by_phoneme_position = defaultdict(list)\n",
    "frame_spans_by_syllable_index = defaultdict(list)\n",
    "frame_spans_by_phoneme_and_syllable_index = defaultdict(list)\n",
    "\n",
    "def process_item(item, idx):\n",
    "    # How many frames do we have stored for this item?\n",
    "    start_frame, stop_frame = equiv_frames_by_item[idx]\n",
    "    num_frames = stop_frame - start_frame\n",
    "\n",
    "    compression_ratio = num_frames / len(item[\"input_values\"])\n",
    "\n",
    "    for word in item[\"word_phonemic_detail\"]:\n",
    "        for i, phone in enumerate(word):\n",
    "            phone_start_frame = start_frame + int(phone[\"start\"] * compression_ratio)\n",
    "            phone_stop_frame = start_frame + int(phone[\"stop\"] * compression_ratio)\n",
    "\n",
    "            frame_spans_by_phoneme[phone[\"phone\"]].append((phone_start_frame, phone_stop_frame))\n",
    "            frame_spans_by_phoneme_position[i].append((phone_start_frame, phone_stop_frame))\n",
    "            frame_spans_by_syllable_index[phone[\"syllable_idx\"]].append((phone_start_frame, phone_stop_frame))\n",
    "            frame_spans_by_phoneme_and_syllable_index[(phone[\"phone\"], phone[\"syllable_idx\"])].append((phone_start_frame, phone_stop_frame))\n",
    "\n",
    "timit_corpus[\"train\"].map(process_item, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: we should have Q assignments for the final frame\n",
    "Q_assignments = {phoneme: [equiv_dataset.Q[end].item() for start, end in spans]\n",
    "                 for phoneme, spans in frame_spans_by_phoneme.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94518458590025"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_assignments_flat = np.array(list(itertools.chain.from_iterable(Q_assignments.values())))\n",
    "(Q_assignments_flat >= 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_positions = sorted(frame_spans_by_phoneme_position.keys())\n",
    "\n",
    "position_spec = StateSpaceAnalysisSpec(\n",
    "    total_num_frames=equiv_dataset.hidden_state_dataset.num_frames,\n",
    "    labels=phoneme_positions,\n",
    "    target_frame_spans=[frame_spans_by_phoneme_position[i] for i in phoneme_positions],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "phonemes = sorted(frame_spans_by_phoneme.keys())\n",
    "\n",
    "phoneme_spec = StateSpaceAnalysisSpec(\n",
    "    total_num_frames=equiv_dataset.hidden_state_dataset.num_frames,\n",
    "    labels=phonemes,\n",
    "    target_frame_spans=[frame_spans_by_phoneme[phone] for phone in phonemes],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out1, \"wb\") as f:\n",
    "    pickle.dump(position_spec, f)\n",
    "with open(out2, \"wb\") as f:\n",
    "    pickle.dump(phoneme_spec, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_syllable_position, \"wb\") as f:\n",
    "    pickle.dump(StateSpaceAnalysisSpec(\n",
    "        total_num_frames=equiv_dataset.hidden_state_dataset.num_frames,\n",
    "        labels=list(frame_spans_by_syllable_index.keys()),\n",
    "        target_frame_spans=list(frame_spans_by_syllable_index.values()),\n",
    "    ), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_identity_syllable_position, \"wb\") as f:\n",
    "    pickle.dump(StateSpaceAnalysisSpec(\n",
    "        total_num_frames=equiv_dataset.hidden_state_dataset.num_frames,\n",
    "        labels=list(frame_spans_by_phoneme_and_syllable_index.keys()),\n",
    "        target_frame_spans=list(frame_spans_by_phoneme_and_syllable_index.values()),\n",
    "    ), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

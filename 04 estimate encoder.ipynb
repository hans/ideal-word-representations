{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubert_encoding_path = \"timit_hubert_encodings.h5\"\n",
    "hubert_agg_fn = \"mean\"\n",
    "\n",
    "word_encoding_path = \"word_encodings/nce.h5\"\n",
    "out_path = \"results/nce.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1ed047d0424315aacb58ae9e38980a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109a135a37e64a38a21ea8cf4b9de19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a05b86d3384eb5bfbb195e49c3b846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1776bbfd904ad08d06843d42e18693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f656bb77b2a40e9b53acba276c9f4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9134c85c2504913ba294dc339422b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a7a9cf18cf4d8fb145c8d29fe3f311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca56911818a64263a55d6a0fa3cf7f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load hubert encodings and transform into same format as word encodings\n",
    "hubert_encodings, hubert_encoding_ids = [], []\n",
    "with h5py.File(hubert_encoding_path, \"r\") as f:\n",
    "    for dialect in f.keys():\n",
    "        for speaker in tqdm(f[dialect].keys()):\n",
    "            for sentence in f[dialect][speaker].keys():\n",
    "                sentence_encodings = f[dialect][speaker][sentence][\"representations\"][\"word\"][hubert_agg_fn]\n",
    "                for token, encodings in enumerate(sentence_encodings):\n",
    "                    hubert_encodings.append(encodings)\n",
    "                    hubert_encoding_ids.append((speaker, sentence, str(token)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubert_encodings = np.array(hubert_encodings)\n",
    "hubert_encoding_ids = np.array(hubert_encoding_ids).astype(\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"word_encodings/autoencoder.h5\", \"r\") as f:\n",
    "    word_encodings = f[\"encodings\"][()]\n",
    "    word_encoding_ids = f[\"ids\"][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33887"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_ids = set([tuple(id_tup) for id_tup in hubert_encoding_ids]) \\\n",
    "    & set([tuple(id_tup) for id_tup in word_encoding_ids])\n",
    "len(keep_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubert_encoding_mask = np.array([tuple(id_tup) in keep_ids for id_tup in hubert_encoding_ids])\n",
    "hubert_encodings = hubert_encodings[hubert_encoding_mask]\n",
    "hubert_encoding_ids = hubert_encoding_ids[hubert_encoding_mask]\n",
    "\n",
    "word_encoding_mask = np.array([tuple(id_tup) in keep_ids for id_tup in word_encoding_ids])\n",
    "word_encodings = word_encodings[word_encoding_mask]\n",
    "word_encoding_ids = word_encoding_ids[word_encoding_mask]\n",
    "\n",
    "assert hubert_encodings.shape[0] == word_encodings.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn single-layer encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00014754920766075485"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO why are there NaN values?\n",
    "np.isnan(hubert_encodings[:, 1, :]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "pca_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4960ac55054a32a34218b159c81b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clfs = []\n",
    "alphas = np.logspace(3, 11, 9)\n",
    "for layer in trange(hubert_encodings.shape[1]):\n",
    "    X = word_encodings\n",
    "    X -= X.mean(axis=0)\n",
    "    X /= X.std(axis=0)\n",
    "\n",
    "    Y = hubert_encodings[:, layer, :]\n",
    "    Y[np.isnan(Y)] = 0\n",
    "    Y -= Y.mean(axis=0)\n",
    "    Y /= Y.std(axis=0)\n",
    "    \n",
    "    Y_pca = PCA(pca_dim).fit_transform(Y)\n",
    "    X_pca = PCA(pca_dim).fit_transform(X)\n",
    "\n",
    "    clfs.append(RidgeCV(alphas=alphas, cv=KFold(4, shuffle=True),\n",
    "                        fit_intercept=False,\n",
    "                        scoring=\"neg_mean_squared_error\").fit(X_pca, Y_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.048445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.185552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.583222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.897390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.760206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.947767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.376405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.780232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.350254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21.650338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mse\n",
       "layer           \n",
       "0      22.048445\n",
       "1      16.185552\n",
       "2      13.583222\n",
       "3      13.897390\n",
       "4      13.760206\n",
       "5      12.947767\n",
       "6      13.376405\n",
       "7      12.780232\n",
       "8      14.350254\n",
       "9      21.650338"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame([clf.best_score_ for clf in clfs], columns=[\"mse\"])\n",
    "results.index.name = \"layer\"\n",
    "results[\"mse\"] = -results[\"mse\"]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "explore310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

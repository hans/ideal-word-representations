{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare state space trajectories for a lexical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from typing import Any\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.analysis.state_space import StateSpaceAnalysisSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a word-level equivalence dataset regardless of model, so that we can look up cohort facts\n",
    "equiv_dataset_path = \"data/timit_equiv_phoneme_within_word_prefix_6_1.pkl\"\n",
    "timit_corpus_path = \"data/timit_syllables\"\n",
    "\n",
    "out = \"out/state_space_specs/all_words.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(equiv_dataset_path, \"rb\") as f:\n",
    "    equiv_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit_corpus = datasets.load_from_disk(timit_corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(type(label) == tuple for label in equiv_dataset.class_labels), \"Assumes dataset with word prefix labels\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare cohort data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "equiv_frames_by_item = equiv_dataset.hidden_state_dataset.frames_by_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473704b5888f4e578d6efeeb4c684641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4620 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame_spans_by_word = defaultdict(list)\n",
    "cuts_df = []\n",
    "\n",
    "def process_item(item, idx):\n",
    "    # How many frames do we have stored for this item?\n",
    "    start_frame, stop_frame = equiv_frames_by_item[idx]\n",
    "    num_frames = stop_frame - start_frame\n",
    "\n",
    "    compression_ratio = num_frames / len(item[\"input_values\"])\n",
    "\n",
    "    for i, word_detail in enumerate(item[\"word_syllable_detail\"]):\n",
    "        if not word_detail:\n",
    "            continue\n",
    "\n",
    "        word_start_frame = start_frame + int(word_detail[0][\"start\"] * compression_ratio)\n",
    "        word_stop_frame = start_frame + int(word_detail[-1][\"stop\"] * compression_ratio)\n",
    "        word = item[\"word_detail\"][\"utterance\"][i]\n",
    "\n",
    "        instance_idx = len(frame_spans_by_word[word])\n",
    "        frame_spans_by_word[word].append((word_start_frame, word_stop_frame))\n",
    "\n",
    "        for syllable in word_detail:\n",
    "            cuts_df.append({\n",
    "                \"label\": word,\n",
    "                \"instance_idx\": instance_idx,\n",
    "                \"level\": \"syllable\",\n",
    "                \"description\": tuple(syllable[\"phones\"]),\n",
    "                \"onset_frame_idx\": start_frame + int(syllable[\"start\"] * compression_ratio),\n",
    "                \"offset_frame_idx\": start_frame + int(syllable[\"stop\"] * compression_ratio),\n",
    "                \"item_idx\": idx,\n",
    "            })\n",
    "\n",
    "        for phoneme in item[\"word_phonemic_detail\"][i]:\n",
    "            cuts_df.append({\n",
    "                \"label\": word,\n",
    "                \"instance_idx\": instance_idx,\n",
    "                \"level\": \"phoneme\",\n",
    "                \"description\": phoneme[\"phone\"],\n",
    "                \"onset_frame_idx\": start_frame + int(phoneme[\"start\"] * compression_ratio),\n",
    "                \"offset_frame_idx\": start_frame + int(phoneme[\"stop\"] * compression_ratio),\n",
    "                \"item_idx\": idx,\n",
    "            })\n",
    "\n",
    "timit_corpus[\"train\"].map(process_item, with_indices=True)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: we should have Q assignments for the final frame\n",
    "Q_assignments = {word: [equiv_dataset.Q[end].item() for start, end in spans]\n",
    "                 for word, spans in frame_spans_by_word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7986942875078469"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_assignments_flat = np.array(list(itertools.chain.from_iterable(Q_assignments.values())))\n",
    "(Q_assignments_flat >= 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(frame_spans_by_word.keys())\n",
    "spans = list(frame_spans_by_word.values())\n",
    "\n",
    "spec = StateSpaceAnalysisSpec(\n",
    "    total_num_frames=equiv_dataset.hidden_state_dataset.num_frames,\n",
    "    labels=words,\n",
    "    target_frame_spans=spans,\n",
    "    cuts=pd.DataFrame(cuts_df).set_index([\"label\", \"instance_idx\", \"level\"]).sort_index(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out, \"wb\") as f:\n",
    "    pickle.dump(spec, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find word cohorts with interesting overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20b609ae1164a52b995b20daab84b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4620 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cf205c09aa481098b22350e62c7ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['file', 'audio', 'text', 'phonetic_detail', 'word_detail', 'dialect_region', 'sentence_type', 'speaker_id', 'id', 'word_phonetic_detail', 'input_values', 'phone_targets', 'phonemic_detail', 'word_phonemic_detail', 'word_syllable_detail'],\n",
       "        num_rows: 4620\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['file', 'audio', 'text', 'phonetic_detail', 'word_detail', 'dialect_region', 'sentence_type', 'speaker_id', 'id', 'word_phonetic_detail', 'input_values', 'phone_targets', 'phonemic_detail', 'word_phonemic_detail', 'word_syllable_detail'],\n",
       "        num_rows: 1680\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timit_word_to_phon = {}\n",
    "\n",
    "def process_item(item):\n",
    "    for word, word_phons in zip(item[\"word_detail\"][\"utterance\"], item[\"word_phonemic_detail\"]):\n",
    "        if len(word_phons) == 0:\n",
    "            continue\n",
    "\n",
    "        timit_word_to_phon[word] = tuple(phone[\"phone\"] for phone in word_phons)\n",
    "timit_corpus.map(process_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "shared_suffixes, shared_suffix_words = Counter(), defaultdict(set)\n",
    "for w1, w2 in itertools.combinations(timit_word_to_phon.keys(), 2):\n",
    "    phons1, phons2 = timit_word_to_phon[w1], timit_word_to_phon[w2]\n",
    "    if len(phons1) > k and len(phons2) > k and phons1[-k:] == phons2[-k:]:\n",
    "        shared_suffixes[phons1[-k:]] += 1\n",
    "        shared_suffix_words[phons1[-k:]].add(w1)\n",
    "        shared_suffix_words[phons1[-k:]].add(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('EY', 'SH', 'AH', 'N'),\n",
       "  {'administration',\n",
       "   'agglomeration',\n",
       "   'application',\n",
       "   'approximation',\n",
       "   'articulation',\n",
       "   'authorization',\n",
       "   'clarification',\n",
       "   'compensation',\n",
       "   'cooperation',\n",
       "   'creation',\n",
       "   'demineralization',\n",
       "   'denunciation',\n",
       "   'desegregation',\n",
       "   'determination',\n",
       "   'education',\n",
       "   'evaluation',\n",
       "   'formation',\n",
       "   'graduation',\n",
       "   'imagination',\n",
       "   'information',\n",
       "   'interpretation',\n",
       "   'invitation',\n",
       "   'irradiation',\n",
       "   'justification',\n",
       "   'operation',\n",
       "   'panelization',\n",
       "   'preparation',\n",
       "   'preservation',\n",
       "   'radiation',\n",
       "   'recommendation',\n",
       "   'recreation',\n",
       "   'rehabilitation',\n",
       "   'renunciation',\n",
       "   'reorganization',\n",
       "   'situation',\n",
       "   'vacation',\n",
       "   'vaporization'}),\n",
       " (('IH', 'K', 'AH', 'L'),\n",
       "  {'article',\n",
       "   'atypical',\n",
       "   'biblical',\n",
       "   'chemical',\n",
       "   'critical',\n",
       "   'cyclical',\n",
       "   'ecumenical',\n",
       "   'empirical',\n",
       "   'hypothetical',\n",
       "   'hysterical',\n",
       "   'identical',\n",
       "   'ideological',\n",
       "   'logical',\n",
       "   'mechanical',\n",
       "   'medical',\n",
       "   'morphological',\n",
       "   'musical',\n",
       "   'optical',\n",
       "   'periodical',\n",
       "   'physical',\n",
       "   'political',\n",
       "   'practical',\n",
       "   'psychical',\n",
       "   'receptacle',\n",
       "   'satirical',\n",
       "   'technical',\n",
       "   'technological',\n",
       "   'testicle',\n",
       "   'tropical',\n",
       "   'tyrannical',\n",
       "   'whimsical'}),\n",
       " (('EY', 'T', 'IH', 'D'),\n",
       "  {'activated',\n",
       "   'approximated',\n",
       "   'complicated',\n",
       "   'cooperated',\n",
       "   'corrugated',\n",
       "   'cultivated',\n",
       "   'decorated',\n",
       "   'delegated',\n",
       "   'donated',\n",
       "   'evaluated',\n",
       "   'exacerbated',\n",
       "   'exaggerated',\n",
       "   'faded',\n",
       "   'hated',\n",
       "   'illuminated',\n",
       "   'indicated',\n",
       "   'integrated',\n",
       "   'irritated',\n",
       "   'operated',\n",
       "   'penetrated',\n",
       "   'radiated',\n",
       "   'rated',\n",
       "   'related',\n",
       "   'situated',\n",
       "   'sophisticated',\n",
       "   'speculated',\n",
       "   'tolerated',\n",
       "   'translated',\n",
       "   'unappreciated',\n",
       "   'waited'}),\n",
       " (('EY', 'SH', 'IH', 'N'),\n",
       "  {'accreditation',\n",
       "   'civilization',\n",
       "   'confabulation',\n",
       "   'configuration',\n",
       "   'confirmation',\n",
       "   'congregation',\n",
       "   'consolidation',\n",
       "   'demonstration',\n",
       "   'depreciation',\n",
       "   'desolation',\n",
       "   'elongation',\n",
       "   'explanation',\n",
       "   'formulation',\n",
       "   'hospitalization',\n",
       "   'infuriation',\n",
       "   'integration',\n",
       "   'investigation',\n",
       "   'legislation',\n",
       "   'location',\n",
       "   'modernization',\n",
       "   'population',\n",
       "   'pronunciation',\n",
       "   'radiosterilization',\n",
       "   'realization',\n",
       "   'representation',\n",
       "   'salvation',\n",
       "   'sophistication',\n",
       "   'sterilization',\n",
       "   'taxation'}),\n",
       " (('IH', 'N', 'T', 'S'),\n",
       "  {'agents',\n",
       "   'apartments',\n",
       "   'assistance',\n",
       "   'convince',\n",
       "   'distance',\n",
       "   'documents',\n",
       "   'endurance',\n",
       "   \"experiment's\",\n",
       "   'fingerprints',\n",
       "   'giants',\n",
       "   'grievance',\n",
       "   'hyacinths',\n",
       "   'ingredients',\n",
       "   'instruments',\n",
       "   'investigations',\n",
       "   'moments',\n",
       "   'nutrients',\n",
       "   \"patient's\",\n",
       "   'payments',\n",
       "   'performance',\n",
       "   'prints',\n",
       "   'reference',\n",
       "   \"students'\",\n",
       "   'supplements',\n",
       "   \"tenant's\",\n",
       "   'transcendence',\n",
       "   'transience',\n",
       "   'urchins'}),\n",
       " (('AH', 'B', 'AH', 'L'),\n",
       "  {'adjustable',\n",
       "   'capable',\n",
       "   'comparable',\n",
       "   'detectable',\n",
       "   'double',\n",
       "   'inadvisable',\n",
       "   'indefinable',\n",
       "   'indispensable',\n",
       "   'inevitable',\n",
       "   'inexhaustible',\n",
       "   'miserable',\n",
       "   'pitiable',\n",
       "   'portable',\n",
       "   'possible',\n",
       "   'susceptible',\n",
       "   'terrible',\n",
       "   'trouble',\n",
       "   'unbeatable',\n",
       "   'unbelievable',\n",
       "   'uncomfortable',\n",
       "   'workable'}),\n",
       " (('AH', 'N', 'T', 'S'),\n",
       "  {'accomplishments',\n",
       "   'adjustments',\n",
       "   'allowance',\n",
       "   'attendance',\n",
       "   'attendants',\n",
       "   'buttons',\n",
       "   'departments',\n",
       "   'environments',\n",
       "   'expectations',\n",
       "   'innocence',\n",
       "   'lotions',\n",
       "   'maintenance',\n",
       "   'observance',\n",
       "   'once',\n",
       "   'reconnaissance',\n",
       "   'recriminations',\n",
       "   'remembrance',\n",
       "   'reminiscence',\n",
       "   \"serpent's\",\n",
       "   'silence'}),\n",
       " (('IH', 'Z', 'AH', 'M'),\n",
       "  {'communism',\n",
       "   'conservatism',\n",
       "   'geocentricism',\n",
       "   'heroism',\n",
       "   'humanism',\n",
       "   'magnetism',\n",
       "   'mannerism',\n",
       "   'mechanism',\n",
       "   'optimism',\n",
       "   'organism',\n",
       "   'radicalism',\n",
       "   'realism',\n",
       "   'stoicism',\n",
       "   'symbolism',\n",
       "   'traditionalism',\n",
       "   'truism',\n",
       "   'utopianism'}),\n",
       " (('SH', 'IH', 'N', 'Z'),\n",
       "  {'applications',\n",
       "   'compositions',\n",
       "   'factions',\n",
       "   'fasciculations',\n",
       "   'implications',\n",
       "   'impressions',\n",
       "   'instructions',\n",
       "   'interpretations',\n",
       "   'musicians',\n",
       "   'obsessions',\n",
       "   \"ocean's\",\n",
       "   'predispositions',\n",
       "   'privations',\n",
       "   'ramifications',\n",
       "   'selections'}),\n",
       " (('IH', 'K', 'L', 'IY'),\n",
       "  {'dogmatically',\n",
       "   'drastically',\n",
       "   'economically',\n",
       "   'frantically',\n",
       "   'idiotically',\n",
       "   'ironically',\n",
       "   'logically',\n",
       "   'microscopically',\n",
       "   'periodically',\n",
       "   'practically',\n",
       "   'psychologically',\n",
       "   'quickly',\n",
       "   'rhythmically',\n",
       "   'sympathetically'})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(key, shared_suffix_words[key]) for key, count in shared_suffixes.most_common(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_overlap_words = set(itertools.chain.from_iterable([shared_suffix_words[key] for key, count in shared_suffixes.most_common(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "shared_prefixes, shared_prefix_words = Counter(), defaultdict(set)\n",
    "for w1, w2 in itertools.combinations(timit_word_to_phon.keys(), 2):\n",
    "    phons1, phons2 = timit_word_to_phon[w1], timit_word_to_phon[w2]\n",
    "    if len(phons1) > k and len(phons2) > k and phons1[:k] == phons2[:k]:\n",
    "        shared_prefixes[phons1[:k]] += 1\n",
    "        shared_prefix_words[phons1[:k]].add(w1)\n",
    "        shared_prefix_words[phons1[:k]].add(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_overlap_words = set(itertools.chain.from_iterable([shared_prefix_words[key] for key, count in shared_prefixes.most_common(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_overlap_words = suffix_overlap_words & prefix_overlap_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comparable',\n",
       " 'compensation',\n",
       " 'complicated',\n",
       " 'compositions',\n",
       " 'conservatism',\n",
       " 'consolidation',\n",
       " 'distance'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_overlap_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'distance': (['distinct',\n",
       "   'distorted',\n",
       "   'distance',\n",
       "   'disturb',\n",
       "   'distinguished',\n",
       "   'destroy',\n",
       "   'districts',\n",
       "   'distress',\n",
       "   'distances',\n",
       "   'distaste',\n",
       "   'destroying'],\n",
       "  ['fingerprints',\n",
       "   \"patient's\",\n",
       "   'supplements',\n",
       "   'apartments',\n",
       "   'convince',\n",
       "   'agents',\n",
       "   'transcendence',\n",
       "   'prints',\n",
       "   'moments',\n",
       "   'documents',\n",
       "   \"experiment's\",\n",
       "   \"students'\",\n",
       "   'ingredients',\n",
       "   'investigations',\n",
       "   'distance',\n",
       "   \"tenant's\",\n",
       "   'urchins',\n",
       "   'nutrients',\n",
       "   'payments',\n",
       "   'endurance',\n",
       "   'instruments',\n",
       "   'giants',\n",
       "   'hyacinths',\n",
       "   'performance',\n",
       "   'reference',\n",
       "   'transience',\n",
       "   'assistance',\n",
       "   'grievance']),\n",
       " 'consolidation': (['construction',\n",
       "   'consists',\n",
       "   'consume',\n",
       "   'consolidation',\n",
       "   'constructions',\n",
       "   'considerably',\n",
       "   'considered',\n",
       "   'consistently',\n",
       "   'consider',\n",
       "   'conservatism',\n",
       "   'conceived',\n",
       "   'consumers'],\n",
       "  ['integration',\n",
       "   'consolidation',\n",
       "   'demonstration',\n",
       "   'population',\n",
       "   'elongation',\n",
       "   'desolation',\n",
       "   'formulation',\n",
       "   'depreciation',\n",
       "   'investigation',\n",
       "   'modernization',\n",
       "   'radiosterilization',\n",
       "   'representation',\n",
       "   'congregation',\n",
       "   'explanation',\n",
       "   'pronunciation',\n",
       "   'sophistication',\n",
       "   'confirmation',\n",
       "   'confabulation',\n",
       "   'civilization',\n",
       "   'hospitalization',\n",
       "   'infuriation',\n",
       "   'legislation',\n",
       "   'accreditation',\n",
       "   'salvation',\n",
       "   'location',\n",
       "   'configuration',\n",
       "   'taxation',\n",
       "   'realization',\n",
       "   'sterilization']),\n",
       " 'compositions': (['complete',\n",
       "   'comparable',\n",
       "   'compile',\n",
       "   \"company's\",\n",
       "   'competitive',\n",
       "   'compliance',\n",
       "   'complexity',\n",
       "   'completely',\n",
       "   'compare',\n",
       "   'compositions',\n",
       "   'competitors',\n",
       "   'company',\n",
       "   'competing',\n",
       "   'computer',\n",
       "   'compose',\n",
       "   'compulsion',\n",
       "   'complicity'],\n",
       "  ['ramifications',\n",
       "   'impressions',\n",
       "   'fasciculations',\n",
       "   'privations',\n",
       "   'obsessions',\n",
       "   'instructions',\n",
       "   \"ocean's\",\n",
       "   'compositions',\n",
       "   'musicians',\n",
       "   'applications',\n",
       "   'interpretations',\n",
       "   'factions',\n",
       "   'selections',\n",
       "   'predispositions',\n",
       "   'implications']),\n",
       " 'conservatism': (['construction',\n",
       "   'consists',\n",
       "   'consume',\n",
       "   'consolidation',\n",
       "   'constructions',\n",
       "   'considerably',\n",
       "   'considered',\n",
       "   'consistently',\n",
       "   'consider',\n",
       "   'conservatism',\n",
       "   'conceived',\n",
       "   'consumers'],\n",
       "  ['realism',\n",
       "   'truism',\n",
       "   'humanism',\n",
       "   'traditionalism',\n",
       "   'geocentricism',\n",
       "   'symbolism',\n",
       "   'organism',\n",
       "   'radicalism',\n",
       "   'heroism',\n",
       "   'communism',\n",
       "   'optimism',\n",
       "   'mannerism',\n",
       "   'utopianism',\n",
       "   'conservatism',\n",
       "   'magnetism',\n",
       "   'mechanism',\n",
       "   'stoicism']),\n",
       " 'comparable': (['complete',\n",
       "   'comparable',\n",
       "   'compile',\n",
       "   \"company's\",\n",
       "   'competitive',\n",
       "   'compliance',\n",
       "   'complexity',\n",
       "   'completely',\n",
       "   'compare',\n",
       "   'compositions',\n",
       "   'competitors',\n",
       "   'company',\n",
       "   'competing',\n",
       "   'computer',\n",
       "   'compose',\n",
       "   'compulsion',\n",
       "   'complicity'],\n",
       "  ['terrible',\n",
       "   'adjustable',\n",
       "   'comparable',\n",
       "   'inexhaustible',\n",
       "   'detectable',\n",
       "   'portable',\n",
       "   'trouble',\n",
       "   'unbeatable',\n",
       "   'possible',\n",
       "   'uncomfortable',\n",
       "   'unbelievable',\n",
       "   'indefinable',\n",
       "   'indispensable',\n",
       "   'capable',\n",
       "   'miserable',\n",
       "   'inadvisable',\n",
       "   'susceptible',\n",
       "   'double',\n",
       "   'pitiable',\n",
       "   'workable',\n",
       "   'inevitable']),\n",
       " 'complicated': (['compost',\n",
       "   'complex',\n",
       "   'compounded',\n",
       "   'compresses',\n",
       "   'competently',\n",
       "   'composition',\n",
       "   'compound',\n",
       "   'complicated',\n",
       "   'compounds',\n",
       "   'compensation',\n",
       "   'compact'],\n",
       "  ['activated',\n",
       "   'rated',\n",
       "   'tolerated',\n",
       "   'unappreciated',\n",
       "   'illuminated',\n",
       "   'faded',\n",
       "   'approximated',\n",
       "   'situated',\n",
       "   'decorated',\n",
       "   'delegated',\n",
       "   'speculated',\n",
       "   'sophisticated',\n",
       "   'exacerbated',\n",
       "   'hated',\n",
       "   'cultivated',\n",
       "   'penetrated',\n",
       "   'donated',\n",
       "   'complicated',\n",
       "   'radiated',\n",
       "   'exaggerated',\n",
       "   'integrated',\n",
       "   'translated',\n",
       "   'cooperated',\n",
       "   'irritated',\n",
       "   'related',\n",
       "   'indicated',\n",
       "   'operated',\n",
       "   'corrugated',\n",
       "   'evaluated',\n",
       "   'waited']),\n",
       " 'compensation': (['compost',\n",
       "   'complex',\n",
       "   'compounded',\n",
       "   'compresses',\n",
       "   'competently',\n",
       "   'composition',\n",
       "   'compound',\n",
       "   'complicated',\n",
       "   'compounds',\n",
       "   'compensation',\n",
       "   'compact'],\n",
       "  ['agglomeration',\n",
       "   'desegregation',\n",
       "   'imagination',\n",
       "   'operation',\n",
       "   'rehabilitation',\n",
       "   'vaporization',\n",
       "   'renunciation',\n",
       "   'interpretation',\n",
       "   'creation',\n",
       "   'vacation',\n",
       "   'demineralization',\n",
       "   'denunciation',\n",
       "   'justification',\n",
       "   'reorganization',\n",
       "   'application',\n",
       "   'evaluation',\n",
       "   'cooperation',\n",
       "   'education',\n",
       "   'preparation',\n",
       "   'formation',\n",
       "   'information',\n",
       "   'articulation',\n",
       "   'administration',\n",
       "   'authorization',\n",
       "   'invitation',\n",
       "   'clarification',\n",
       "   'recommendation',\n",
       "   'compensation',\n",
       "   'approximation',\n",
       "   'graduation',\n",
       "   'radiation',\n",
       "   'recreation',\n",
       "   'situation',\n",
       "   'preservation',\n",
       "   'panelization',\n",
       "   'irradiation',\n",
       "   'determination'])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source some prefix overlaps and suffix overlaps for each case\n",
    "complex_cohort_set = {word: (list(shared_prefix_words[timit_word_to_phon[word][:k]]),\n",
    "                             list(shared_suffix_words[timit_word_to_phon[word][-k:]]))\n",
    "                      for word in multiple_overlap_words}\n",
    "complex_cohort_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"complex_cohort_set.json\", \"w\") as f:\n",
    "    json.dump(complex_cohort_set, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

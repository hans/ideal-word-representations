defaults:
  - _self_
  - dataset: timit_syllables
  - equivalence: word_prefix
  - model: w2v2_drop6_nornn

  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog

hydra:
  job:
    chdir: false
  run:
    dir: outputs/models/${hydra:job.name}

device: cuda

tokenizer:
  _target_: transformers.Wav2Vec2CTCTokenizer.from_pretrained
  pretrained_model_name_or_path: charsiu/tokenizer_en_cmu

feature_extractor:
  _target_: transformers.Wav2Vec2FeatureExtractor
  feature_size: 1
  sampling_rate: 16000

training_args:
  per_device_train_batch_size: 32
  evaluation_strategy: steps
  num_train_epochs: 2
  gradient_accumulation_steps: 2
  save_steps: 100
  eval_steps: 100
  logging_steps: 10
  learning_rate: 1e-3
  save_total_limit: 5
  logging_first_step: true
  greater_is_better: false
  remove_unused_columns: false
  load_best_model_at_end: true
  disable_tqdm: true
  save_safetensors: false
  label_names:
    - example_idx

trainer:
  callbacks:
    - _target_: transformers.EarlyStoppingCallback
      early_stopping_patience: 3
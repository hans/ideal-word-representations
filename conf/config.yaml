defaults:
  - _self_
  - dataset: timit_phonemes
  - collator: multilabel_phoneme
  - model: w2v2_drop6_nornn

  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog

hydra:
  job:
    chdir: false
  run:
    dir: outputs/models/${hydra:job.name}

device: cuda

tokenizer:
  _target_: transformers.Wav2Vec2CTCTokenizer.from_pretrained
  pretrained_model_name_or_path: charsiu/tokenizer_en_cmu

feature_extractor:
  _target_: transformers.Wav2Vec2FeatureExtractor
  feature_size: 1
  sampling_rate: 16000

training_args:
  per_device_train_batch_size: 16
  evaluation_strategy: steps
  num_train_epochs: 50
  gradient_accumulation_steps: 2
  save_steps: 50
  eval_steps: 50
  logging_steps: 2
  learning_rate: 1e-2
  save_total_limit: 5
  remove_unused_columns: false
  load_best_model_at_end: true
  label_names: ["target_mask", "classifier_labels", "regressor_targets"]
  disable_tqdm: true

trainer:
  callbacks:
    - _target_: transformers.EarlyStoppingCallback
      early_stopping_patience: 3
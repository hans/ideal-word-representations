datasets:
  timit:
    raw_path: data/timit_raw


models:
  - base_model: w2v2_6
    dataset: timit
    model: rnn_3-weightdecay0.01
    equivalence: phoneme_10frames

  # - base_model: w2v2_6
  #   dataset: timit
  #   model: rnn_8-weightdecay0.01
  #   equivalence: phoneme_10frames
  - base_model: w2v2_6
    dataset: timit
    model: rnn_8-weightdecay0.01
    equivalence: syllable_10frames
  - base_model: w2v2_6
    dataset: timit
    model: rnn_3-weightdecay0.01
    equivalence: next_phoneme_10frames
  # - base_model: w2v2_6
  #   dataset: timit
  #   model: rnn_8-weightdecay0.01
  #   equivalence: phoneme_within_word_prefix
  # - base_model: w2v2_6
  #   dataset: timit
  #   model: rnn_8-weightdecay0.01
  #   equivalence: phoneme_within_word_suffix
  - base_model: w2v2_6
    dataset: timit
    model: rnn_8-weightdecay0.01
    equivalence: word_10frames
  - base_model: w2v2_6
    dataset: timit
    model: rnn_8-weightdecay0.01
    equivalence: word_broad_10frames
  - base_model: w2v2_6
    dataset: timit
    model: rnn_8-weightdecay0.01
    equivalence: biphone_recon_10frames
  - base_model: w2v2_6
    dataset: timit
    model: rnn_8-weightdecay0.01
    equivalence: biphone_pred_10frames

  # - base_model: w2v2_6
  #   model: rnn_32
  #   equivalence: phoneme_within_word_prefix
  # - base_model: w2v2_6
  #   model: rnn_32
  #   equivalence: phoneme_within_word_suffix

  # random LSTM models
  - base_model: w2v2_6
    dataset: timit
    model: randomrnn_8
    equivalence: random
  - base_model: w2v2_6
    dataset: timit
    model: randomrnn_32
    equivalence: random

  # random feedforward models
  - base_model: w2v2_6
    dataset: timit
    model: randomff_8
    equivalence: random
  - base_model: w2v2_6
    dataset: timit
    model: randomff_32
    equivalence: random

encoding:
  data:
    - subject: EC152
      blocks:
        - B22

    - subject: EC196
      blocks:
        - B1

    - subject: EC195
      blocks:
        - B1

    - subject: EC183
      blocks:
        - B43

    - subject: EC212
      blocks:
        - B13

    # good frontal coverage
    # - subject: EC208
    #   blocks: null
    - subject: EC260
      blocks:
        - B1

  model_comparisons:
    - model2: phoneme
      model1: baseline
    - model2: next_phoneme
      model1: baseline
    - model2: biphone_recon
      model1: baseline
    - model2: biphone_pred
      model1: baseline
    - model2: syllable
      model1: baseline
    - model2: random8
      model1: baseline
    - model2: word_broad
      model1: baseline


synthetic_encoding:

  evaluations:

    basic10:
      num_components: 10
      num_embeddings_to_select: 4

      datasets:
        - timit

      subsample_strategies:
        - all
        - multisyllabic
        - monosyllabic

      target_models:
        - w2v2_0
        - w2v2_1
        - w2v2_2
        - w2v2_3
        - w2v2_4
        - w2v2_5
        - w2v2_6
        - w2v2_7
        - w2v2_8
        - w2v2_9
        - w2v2_10
        - w2v2_11
        - w2v2-large_0
        - w2v2-large_11
        - w2v2-large_20

      models:
        - phoneme
        - next_phoneme
        - biphone_recon
        - biphone_pred
        - syllable
        - word_broad

    basic50:
      num_components: 50
      num_embeddings_to_select: 4

      datasets:
        - timit

      subsample_strategies:
        - all
        - multisyllabic
        - monosyllabic

      target_models:
        - w2v2_0
        - w2v2_1
        - w2v2_2
        - w2v2_3
        - w2v2_4
        - w2v2_5
        - w2v2_6
        - w2v2_7
        - w2v2_8
        - w2v2_9
        - w2v2_10
        - w2v2_11
        - w2v2-large_0
        - w2v2-large_11
        - w2v2-large_20

      models:
        - phoneme
        - next_phoneme
        - biphone_recon
        - biphone_pred
        - syllable
        - word_broad
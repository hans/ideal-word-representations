datasets:
  timit:
    raw_path: data/timit_raw
  timit-no_repeats:
    raw_path: data/timit_raw


models:
  - base_model: w2v2_6
    dataset: timit
    model: rnn_3-weightdecay0.01
    equivalence: phoneme_10frames
  - base_model: w2v2_6
    dataset: timit
    model: rnn_8-weightdecay0.01
    equivalence: syllable_10frames
  - base_model: w2v2_6
    dataset: timit
    model: rnn_3-weightdecay0.01
    equivalence: next_phoneme_10frames
  - base_model: w2v2_6
    dataset: timit
    model: rnn_8-weightdecay0.01
    equivalence: word_10frames
  - base_model: w2v2_6
    dataset: timit
    model: rnn_8-weightdecay0.01
    equivalence: word_broad_10frames
  - base_model: w2v2_6
    dataset: timit
    model: rnn_8-weightdecay0.01
    equivalence: biphone_recon_10frames
  - base_model: w2v2_6
    dataset: timit
    model: rnn_8-weightdecay0.01
    equivalence: biphone_pred_10frames

  # aniso outcomes
  - base_model: w2v2_6
    dataset: timit
    model: rnn_8-aniso1
    equivalence: word_broad_10frames
  - base_model: w2v2_6
    dataset: timit
    model: rnn_8-aniso2
    equivalence: word_broad_10frames
  - base_model: w2v2_6
    dataset: timit
    model: rnn_8-aniso3
    equivalence: word_broad_10frames
  - base_model: w2v2_8
    dataset: timit
    model: rnn_8-aniso1
    equivalence: word_broad_10frames
  - base_model: w2v2_8
    dataset: timit
    model: rnn_8-aniso2
    equivalence: word_broad_10frames
  - base_model: w2v2_8
    dataset: timit
    model: rnn_8-aniso3
    equivalence: word_broad_10frames

  - base_model: w2v2_8
    dataset: timit
    model: rnn_3-weightdecay0.01
    equivalence: phoneme_10frames
  - base_model: w2v2_8
    dataset: timit
    model: rnn_8-weightdecay0.01
    equivalence: syllable_10frames
  - base_model: w2v2_8
    dataset: timit
    model: rnn_3-weightdecay0.01
    equivalence: next_phoneme_10frames
  - base_model: w2v2_8
    dataset: timit
    model: rnn_8-weightdecay0.01
    equivalence: word_10frames
  - base_model: w2v2_8
    dataset: timit
    model: rnn_8-weightdecay0.01
    equivalence: word_broad_10frames
  - base_model: w2v2_8
    dataset: timit
    model: rnn_8-weightdecay0.01
    equivalence: biphone_recon_10frames
  - base_model: w2v2_8
    dataset: timit
    model: rnn_8-weightdecay0.01
    equivalence: biphone_pred_10frames

  # random LSTM models
  - base_model: w2v2_6
    dataset: timit
    model: randomrnn_8
    equivalence: random
  - base_model: w2v2_6
    dataset: timit
    model: randomrnn_32
    equivalence: random
  - base_model: w2v2_8
    dataset: timit
    model: randomrnn_8
    equivalence: random
  - base_model: w2v2_8
    dataset: timit
    model: randomrnn_32
    equivalence: random

  # random feedforward models
  - base_model: w2v2_6
    dataset: timit
    model: randomff_8
    equivalence: random
  - base_model: w2v2_6
    dataset: timit
    model: randomff_32
    equivalence: random
  - base_model: w2v2_8
    dataset: timit
    model: randomff_8
    equivalence: random
  - base_model: w2v2_8
    dataset: timit
    model: randomff_32
    equivalence: random

  # no repeats
  - base_model: w2v2_8
    dataset: timit-no_repeats
    model: rnn_8-aniso2
    equivalence: word_broad_10frames

encoding:
  data:
    - subject: EC152
      blocks:
        - B22

    - subject: EC196
      blocks:
        - B1

    - subject: EC195
      blocks:
        - B1

    - subject: EC183
      blocks:
        - B43

    - subject: EC212
      blocks:
        - B13

    # good frontal coverage
    # - subject: EC208
    #   blocks: null
    - subject: EC260
      blocks:
        - B1

  model_comparisons:
    - model2: phoneme
      model1: baseline
    - model2: next_phoneme
      model1: baseline
    - model2: biphone_recon
      model1: baseline
    - model2: biphone_pred
      model1: baseline
    - model2: syllable
      model1: baseline
    - model2: random8
      model1: baseline
    - model2: word_broad
      model1: baseline

    - model2: phoneme-w2v2_8
      model1: baseline
    - model2: next_phoneme-w2v2_8
      model1: baseline
    - model2: biphone_recon-w2v2_8
      model1: baseline
    - model2: biphone_pred-w2v2_8
      model1: baseline
    - model2: syllable-w2v2_8
      model1: baseline
    - model2: random8-w2v2_8
      model1: baseline
    - model2: word_broad-w2v2_8
      model1: baseline

    - model2: word_broad-aniso1
      model1: baseline
    - model2: word_broad-aniso2
      model1: baseline
    - model2: word_broad-aniso3
      model1: baseline

    - model2: word_broad-aniso1-w2v2_8
      model1: baseline
    - model2: word_broad-aniso2-w2v2_8
      model1: baseline
    - model2: word_broad-aniso3-w2v2_8
      model1: baseline

    - model2: word_broad-aniso2-w2v2_8-meanlast5
      model1: baseline
    - model2: word_broad-aniso3-w2v2_8-meanlast5
      model1: baseline

  permutation_tests:
    units:
      permutation: permute_units
      num_permutations: 5
    shift:
      permutation: shift
      num_permutations: 5


synthetic_encoding:

  evaluations:

    basic10:
      num_components: 10
      num_embeddings_to_select: 6

      datasets:
        - timit

      subsample_strategies:
        - all
        - multisyllabic
        - monosyllabic
        - multisyllabic-nonfirst_syllable

      target_models:
        - w2v2_0
        - w2v2_1
        - w2v2_2
        - w2v2_3
        - w2v2_4
        - w2v2_5
        - w2v2_6
        - w2v2_7
        - w2v2_8
        - w2v2_9
        - w2v2_10
        - w2v2_11
        - w2v2-large_0
        - w2v2-large_11
        - w2v2-large_20

      models:
        - phoneme
        - next_phoneme
        - biphone_recon
        - biphone_pred
        - syllable
        - word_broad

    basic50:
      num_components: 50
      num_embeddings_to_select: 6

      datasets:
        - timit

      subsample_strategies:
        - all
        - multisyllabic
        - monosyllabic
        - multisyllabic-nonfirst_syllable

      target_models:
        - w2v2_0
        - w2v2_1
        - w2v2_2
        - w2v2_3
        - w2v2_4
        - w2v2_5
        - w2v2_6
        - w2v2_7
        - w2v2_8
        - w2v2_9
        - w2v2_10
        - w2v2_11
        - w2v2-large_0
        - w2v2-large_11
        - w2v2-large_20

      models:
        - phoneme
        - next_phoneme
        - biphone_recon
        - biphone_pred
        - syllable
        - word_broad

    basic128:
      num_components: 128
      num_embeddings_to_select: 6

      datasets:
        - timit

      subsample_strategies:
        - all
        - multisyllabic
        - monosyllabic
        - multisyllabic-nonfirst_syllable

      target_models:
        - w2v2_0
        - w2v2_1
        - w2v2_2
        - w2v2_3
        - w2v2_4
        - w2v2_5
        - w2v2_6
        - w2v2_7
        - w2v2_8
        - w2v2_9
        - w2v2_10
        - w2v2_11
        - w2v2-large_0
        - w2v2-large_11
        - w2v2-large_20

      models:
        - phoneme
        - next_phoneme
        - biphone_recon
        - biphone_pred
        - syllable
        - word_broad
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locate phoneme positions which best separate candidate speech representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from typing import Any\n",
    "\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.models import get_best_checkpoint\n",
    "from src.analysis.state_space import StateSpaceAnalysisSpec\n",
    "from src.models.integrator import ContrastiveEmbeddingModel, load_or_compute_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoints = {\n",
    "    \"word_prefix\": \"outputs/models/w2v2_32/phoneme_within_word_prefix\",\n",
    "    # \"word_suffix\": \"out/ce_model_phoneme_within_word_suffix_6_32\",\n",
    "    \"phoneme\": \"outputs/models/w2v2_8/phoneme\",\n",
    "    \n",
    "    \"random32\": \"outputs/models/w2v2_32/random\",\n",
    "    \"random8\": \"outputs/models/w2v2_8/random\",\n",
    "    # \"next_phoneme\": \"out/ce_model_next_phoneme_6_8/checkpoint-700/\",\n",
    "}\n",
    "\n",
    "equiv_dataset_path = \"data/timit_equiv_phoneme_6_1.pkl\"\n",
    "traj_path = \"out/state_space_specs/all_phonemes_by_position.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    k: ContrastiveEmbeddingModel.from_pretrained(get_best_checkpoint(v))\n",
    "    for k, v in model_checkpoints.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = list(models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(equiv_dataset_path, \"rb\") as f:\n",
    "    equiv_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(traj_path, \"rb\") as f:\n",
    "    traj_spec: StateSpaceAnalysisSpec = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert traj_spec.is_compatible_with(equiv_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d39419066e4ce88657856e5fd045ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/embedding_cache/outputs-models-w2v2_32-phoneme_within_word_prefix-data-timit_equiv_phoneme_6_1.pkl.npy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf30fe5a9fc4ebb9cf0093a9499fab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_representations = {\n",
    "    k: load_or_compute_embeddings(v, equiv_dataset, model_checkpoints[k], equiv_dataset_path)\n",
    "    for k, v in tqdm(list(models.items()))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PWCCA definition\n",
    "\n",
    "https://github.com/1Konny/Projection_Weighted_CCA/blob/master/cca.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy&paste from: https://github.com/google/svcca/blob/master/cca_core.py\n",
    "def positivedef_matrix_sqrt(array):\n",
    "    \"\"\"Stable method for computing matrix square roots, supports complex matrices.\n",
    "\n",
    "    Args:\n",
    "        array: A numpy 2d array, can be complex valued that is a positive\n",
    "            definite symmetric (or hermitian) matrix\n",
    "\n",
    "    Returns:\n",
    "        sqrtarray: The matrix square root of array\n",
    "    \"\"\"\n",
    "    w, v = np.linalg.eigh(array)\n",
    "    wsqrt = np.sqrt(w)\n",
    "    sqrtarray = np.dot(v, np.dot(np.diag(wsqrt), np.conj(v).T))\n",
    "    return sqrtarray\n",
    "\n",
    "\n",
    "# copy&paste from: https://github.com/google/svcca/blob/master/cca_core.py\n",
    "def remove_small(sigma_xx, sigma_xy, sigma_yx, sigma_yy, threshold=1e-6):\n",
    "    \"\"\"Takes covariance between X, Y, and removes values of small magnitude.\n",
    "\n",
    "    Args:\n",
    "        sigma_xx: 2d numpy array, variance matrix for x\n",
    "        sigma_xy: 2d numpy array, crossvariance matrix for x,y\n",
    "        sigma_yx: 2d numpy array, crossvariance matrixy for x,y,\n",
    "            (conjugate) transpose of sigma_xy\n",
    "        sigma_yy: 2d numpy array, variance matrix for y\n",
    "        threshold: cutoff value for norm below which directions are thrown\n",
    "            away\n",
    "\n",
    "    Returns:\n",
    "            sigma_xx_crop: 2d array with low x norm directions removed\n",
    "            sigma_xy_crop: 2d array with low x and y norm directions removed\n",
    "            sigma_yx_crop: 2d array with low x and y norm directiosn removed\n",
    "            sigma_yy_crop: 2d array with low y norm directions removed\n",
    "            x_idxs: indexes of sigma_xx that were removed\n",
    "            y_idxs: indexes of sigma_yy that were removed\n",
    "    \"\"\"\n",
    "\n",
    "    x_diag = np.abs(np.diagonal(sigma_xx))\n",
    "    y_diag = np.abs(np.diagonal(sigma_yy))\n",
    "    x_idxs = (x_diag >= threshold)\n",
    "    y_idxs = (y_diag >= threshold)\n",
    "\n",
    "    sigma_xx_crop = sigma_xx[x_idxs][:, x_idxs]\n",
    "    sigma_xy_crop = sigma_xy[x_idxs][:, y_idxs]\n",
    "    sigma_yx_crop = sigma_yx[y_idxs][:, x_idxs]\n",
    "    sigma_yy_crop = sigma_yy[y_idxs][:, y_idxs]\n",
    "\n",
    "    return (sigma_xx_crop, sigma_xy_crop, sigma_yx_crop, sigma_yy_crop, x_idxs, y_idxs)\n",
    "\n",
    "\n",
    "def gs_orthonormalize(array):\n",
    "    \"\"\"Gram-Schmidt orthonormalization.\"\"\"\n",
    "    q, _ = np.linalg.qr(array)\n",
    "    if q.shape[1] < array.shape[1]:\n",
    "        zero_pad = np.zeros(shape=(q.shape[0], array.shape[1]-q.shape[1]))\n",
    "        q = np.concatenate([q, zero_pad], 1)\n",
    "    return q\n",
    "\n",
    "\n",
    "# modified from and built on the codes in https://github.com/google/svcca/blob/master/cca_core.py\n",
    "def solve_cca(x, y):\n",
    "    \"\"\"Calculate CCA correlations, position vectors, images, and Mean|Projection Weighted similarity.\n",
    "    \n",
    "    The terms, 'correlation', 'position vector', 'image' are detailed in [1].\n",
    "    [1] A Tutorial on Canonical Correlation Methods, Uurtio et al\n",
    "    \n",
    "    Args:\n",
    "        x: A representation of shape (num_neurons, num_datapoints)\n",
    "        y: A representation of shape (num_neurons, num_datapoints)\n",
    "    \"\"\"\n",
    "    assert x.ndim == y.ndim == 2, 'both x and y should be 2D array, [num_neurons, num_datapoints]'\n",
    "    assert x.shape[1] == y.shape[1], 'the number of datapoints between x and y do not match'\n",
    "    assert x.shape[0] <= x.shape[1], 'num_datapoints should be greater than or equal to num_neurons. please check x.shape'\n",
    "    assert y.shape[0] <= y.shape[1], 'num_datapoints should be greater than or equal to num_neurons. please check y.shape'\n",
    "    epsilon = 1e-6\n",
    "    \n",
    "    numx = x.shape[0]\n",
    "    numy = y.shape[0]\n",
    "\n",
    "    sigma = np.cov(x, y)\n",
    "    sigmaxx = sigma[:numx, :numx]\n",
    "    sigmaxy = sigma[:numx, numx:]\n",
    "    sigmayx = sigma[numx:, :numx]\n",
    "    sigmayy = sigma[numx:, numx:]\n",
    "\n",
    "    # normalize covariance matrices for stability\n",
    "    xmax = np.max(np.abs(sigmaxx))\n",
    "    ymax = np.max(np.abs(sigmayy))\n",
    "    sigmaxx /= xmax\n",
    "    sigmayy /= ymax\n",
    "    sigmaxy /= np.sqrt(xmax*ymax)\n",
    "    sigmayx /= np.sqrt(ymax*xmax)\n",
    "    \n",
    "    # remove negligibly small covariances\n",
    "    sigmaxx, sigmaxy, sigmayx, sigmayy, x_idxs, y_idxs = remove_small(sigmaxx, sigmaxy, sigmayx, sigmayy)\n",
    "    x = x[x_idxs]\n",
    "    y = y[y_idxs]\n",
    "\n",
    "    numx = sigmaxx.shape[0]\n",
    "    numy = sigmayy.shape[0]\n",
    "    if numx == 0 or numy == 0:\n",
    "        raise NotImplementedError('check here.')\n",
    "\n",
    "    sigmaxx += epsilon*np.eye(numx)\n",
    "    sigmayy += epsilon*np.eye(numy)\n",
    "    inv_sigmaxx = np.linalg.pinv(sigmaxx)\n",
    "    inv_sigmayy = np.linalg.pinv(sigmayy)\n",
    "    invsqrt_sigmaxx = positivedef_matrix_sqrt(inv_sigmaxx)\n",
    "    invsqrt_sigmayy = positivedef_matrix_sqrt(inv_sigmayy)\n",
    "\n",
    "    arrx = invsqrt_sigmaxx.dot(sigmaxy).dot(inv_sigmayy.dot(sigmayx.dot(invsqrt_sigmaxx)))\n",
    "    arry = invsqrt_sigmayy.dot(sigmayx).dot(inv_sigmaxx.dot(sigmaxy.dot(invsqrt_sigmayy)))\n",
    "    arrx += epsilon*np.eye(arrx.shape[0])\n",
    "    arry += epsilon*np.eye(arry.shape[0])\n",
    "\n",
    "    ux, sx, vhx = np.linalg.svd(arrx)\n",
    "    uy, sy, vhy = np.linalg.svd(arry)\n",
    "\n",
    "    cca_corr_x = np.sqrt(np.abs(sx)) # each value represents k-th order canonical correlation coefficient of x\n",
    "    cca_corr_x = np.where(cca_corr_x>1, 1, cca_corr_x)\n",
    "    cca_corr_x = np.where(cca_corr_x<epsilon, 0, cca_corr_x)\n",
    "    \n",
    "    cca_corr_y = np.sqrt(np.abs(sy)) \n",
    "    cca_corr_y = np.where(cca_corr_y>1, 1, cca_corr_y)\n",
    "    cca_corr_y = np.where(cca_corr_y<epsilon, 0, cca_corr_y)\n",
    "    \n",
    "    # check\n",
    "    cca_pos_x = vhx.dot(invsqrt_sigmaxx) # each row represents k-th order canonical correlation position vector of x\n",
    "    cca_pos_y = vhy.dot(invsqrt_sigmayy)\n",
    "    \n",
    "    # check\n",
    "    cca_image_x = cca_pos_x.dot(x) # each row represents k-th order canonical correlation image of x\n",
    "    cca_image_y = cca_pos_y.dot(y)\n",
    "\n",
    "    min_numxy = min(numx, numy)\n",
    "    truncated_corr_x = cca_corr_x[:min_numxy]\n",
    "    truncated_corr_y = cca_corr_y[:min_numxy]\n",
    "    equally_weighted_cca_sim_x = truncated_corr_x.mean()\n",
    "    equally_weighted_cca_sim_y = truncated_corr_y.mean()\n",
    "    \n",
    "    truncated_cca_image_x = cca_image_x[:min_numxy]\n",
    "    truncated_cca_image_y = cca_image_y[:min_numxy]\n",
    "\n",
    "    # check\n",
    "    orthonorm_cca_image_x = gs_orthonormalize(truncated_cca_image_x)\n",
    "    orthonorm_cca_image_y = gs_orthonormalize(truncated_cca_image_y)\n",
    "\n",
    "    projection_weights_x = np.abs(orthonorm_cca_image_x.dot(x.T)).sum(1)\n",
    "    projection_weights_x /= projection_weights_x.sum()\n",
    "    projection_weighted_cca_sim_x = (projection_weights_x*truncated_corr_x).sum() # dist = 1 - sim\n",
    "\n",
    "    projection_weights_y = np.abs(orthonorm_cca_image_y.dot(y.T)).sum(1)\n",
    "    projection_weights_y /= projection_weights_y.sum()\n",
    "    projection_weighted_cca_sim_y = (projection_weights_y*truncated_corr_y).sum() # dist = 1 - sim\n",
    "    \n",
    "    output_dicts = {}\n",
    "    output_dicts['cca_corr_x'] = cca_corr_x\n",
    "    output_dicts['cca_corr_y'] = cca_corr_y\n",
    "    output_dicts['cca_pos_x'] = cca_pos_x\n",
    "    output_dicts['cca_pos_y'] = cca_pos_y\n",
    "    output_dicts['cca_image_x'] = cca_image_x\n",
    "    output_dicts['cca_image_y'] = cca_image_y\n",
    "    output_dicts['ewcca_sim_x'] = equally_weighted_cca_sim_x\n",
    "    output_dicts['ewcca_sim_y'] = equally_weighted_cca_sim_y\n",
    "    output_dicts['pwcca_sim_x'] = projection_weighted_cca_sim_x\n",
    "    output_dicts['pwcca_sim_y'] = projection_weighted_cca_sim_y\n",
    "\n",
    "    return output_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_folds = 2\n",
    "cca_scores = np.zeros((len(traj_spec.labels), len(model_names), len(model_names), cv_folds))\n",
    "cca_scores.fill(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, phoneme_position in enumerate(tqdm(traj_spec.labels)):\n",
    "    print(i)\n",
    "    for model_j, model_k in itertools.product(list(range(len(model_names))), repeat=2):\n",
    "        if model_j >= model_k:\n",
    "            continue\n",
    "        spans = traj_spec.target_frame_spans[i]\n",
    "\n",
    "        # Only extract frames from span which have a Q label\n",
    "        frames = [[frame for frame in range(start_frame, end_frame + 1) if equiv_dataset.Q[frame] != -1]\n",
    "                  for start_frame, end_frame in spans]\n",
    "        \n",
    "        frames = list(itertools.chain.from_iterable(frames))\n",
    "\n",
    "        rep_j = model_representations[model_names[model_j]][frames]\n",
    "        rep_k = model_representations[model_names[model_k]][frames]\n",
    "\n",
    "        # # TODO consider other agg fns\n",
    "        # rep_j = np.stack([model_representations[model_names[model_j]][start_frame:end_frame + 1].mean(0)\n",
    "        #                   for start_frame, end_frame in spans])\n",
    "        # rep_k = np.stack([model_representations[model_names[model_k]][start_frame:end_frame + 1].mean(0)\n",
    "        #                   for start_frame, end_frame in spans])\n",
    "\n",
    "        assert rep_k.shape[0] == rep_j.shape[0]\n",
    "\n",
    "        if rep_j.shape[0] < cv_folds * 2 or rep_j.shape[0] < rep_j.shape[1] or rep_k.shape[0] < rep_k.shape[1]:\n",
    "            continue\n",
    "\n",
    "        cv = KFold(n_splits=cv_folds, shuffle=True)\n",
    "        for fold, (train_idx, test_idx) in enumerate(cv.split(rep_j)):\n",
    "            try:\n",
    "                result = solve_cca(rep_j[train_idx].T, rep_k[train_idx].T)\n",
    "            except AssertionError:\n",
    "                pass # too little data\n",
    "            else:\n",
    "                cca_scores[i, model_j, model_k, fold] = result['pwcca_sim_x']\n",
    "            # cca = CCA(n_components=min(rep_j.shape[1], rep_k.shape[1]))\n",
    "            # cca.fit(rep_j[train_idx], rep_k[train_idx])\n",
    "\n",
    "            # test_j_trans, test_k_trans = cca.transform(rep_j[test_idx], rep_k[test_idx])\n",
    "            # print(np.corrcoef(test_j_trans, test_k_trans).shape)\n",
    "            # cca_scores[i, model_j, model_k, fold] = np.corrcoef(test_j_trans, test_k_trans)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_scores_df = []\n",
    "for i, model_i, model_j, fold in np.ndindex(*cca_scores.shape):\n",
    "    cca_scores_df.append({\n",
    "        \"position\": traj_spec.labels[i],\n",
    "        \"fold\": fold,\n",
    "        \"model_i\": model_names[model_i],\n",
    "        \"model_j\": model_names[model_j],\n",
    "        \"cca_score\": cca_scores[i, model_i, model_j, fold],\n",
    "    })\n",
    "cca_scores_df = pd.DataFrame(cca_scores_df).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_scores_df[\"comparison\"] = cca_scores_df[\"model_i\"] + \" vs \" + cca_scores_df[\"model_j\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=cca_scores_df, x=\"position\", y=\"cca_score\", hue=\"comparison\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

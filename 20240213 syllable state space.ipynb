{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare state space trajectories for a syllabic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from typing import Any\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from src.analysis.state_space import StateSpaceAnalysisSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a word-level equivalence dataset regardless of model, so that we can look up cohort facts\n",
    "equiv_dataset_path = \"data/timit_equiv_phoneme_6_1.pkl\"\n",
    "timit_corpus_path = \"data/timit_syllables\"\n",
    "\n",
    "out_by_identity = \"out/state_space_specs/all_syllables.pkl\"\n",
    "# out_by_onset = \"out/state_space_specs/all_syllables_by_onset.pkl\"\n",
    "# out_by_nucleus = \"out/state_space_specs/all_syllables_by_nucleus.pkl\"\n",
    "out_by_ordinal = \"out/state_space_specs/all_syllables_by_ordinal.pkl\"\n",
    "out_by_identity_and_ordinal = \"out/state_space_specs/all_syllables_by_identity_and_ordinal.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(equiv_dataset_path, \"rb\") as f:\n",
    "    equiv_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit_corpus = datasets.load_from_disk(timit_corpus_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare cohort data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "equiv_frames_by_item = equiv_dataset.hidden_state_dataset.frames_by_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'idx': 0,\n",
       "   'phoneme_end_idx': 2,\n",
       "   'phoneme_start_idx': 0,\n",
       "   'phones': ['SH', 'IH'],\n",
       "   'start': 3050,\n",
       "   'stop': 5723,\n",
       "   'stress': None}],\n",
       " [{'idx': 0,\n",
       "   'phoneme_end_idx': 4,\n",
       "   'phoneme_start_idx': 0,\n",
       "   'phones': ['HH', 'EH', 'D', 'JH'],\n",
       "   'start': 5723,\n",
       "   'stop': 10337,\n",
       "   'stress': None}],\n",
       " [{'idx': 0,\n",
       "   'phoneme_end_idx': 2,\n",
       "   'phoneme_start_idx': 0,\n",
       "   'phones': ['JH', 'IH'],\n",
       "   'start': 9190,\n",
       "   'stop': 11517,\n",
       "   'stress': None}],\n",
       " [{'idx': 0,\n",
       "   'phoneme_end_idx': 3,\n",
       "   'phoneme_start_idx': 0,\n",
       "   'phones': ['D', 'AH', 'K'],\n",
       "   'start': 11517,\n",
       "   'stop': 16334,\n",
       "   'stress': None}],\n",
       " [{'idx': 0,\n",
       "   'phoneme_end_idx': 3,\n",
       "   'phoneme_start_idx': 0,\n",
       "   'phones': ['S', 'UW', 'T'],\n",
       "   'start': 16334,\n",
       "   'stop': 21199,\n",
       "   'stress': None}],\n",
       " [{'idx': 0,\n",
       "   'phoneme_end_idx': 2,\n",
       "   'phoneme_start_idx': 0,\n",
       "   'phones': ['AH', 'N'],\n",
       "   'start': 21199,\n",
       "   'stop': 22560,\n",
       "   'stress': None}],\n",
       " [{'idx': 0,\n",
       "   'phoneme_end_idx': 3,\n",
       "   'phoneme_start_idx': 0,\n",
       "   'phones': ['G', 'R', 'IH'],\n",
       "   'start': 22560,\n",
       "   'stop': 25566,\n",
       "   'stress': None},\n",
       "  {'idx': 1,\n",
       "   'phoneme_end_idx': 5,\n",
       "   'phoneme_start_idx': 3,\n",
       "   'phones': ['S', 'IH'],\n",
       "   'start': 25566,\n",
       "   'stop': 28064,\n",
       "   'stress': None}],\n",
       " [{'idx': 0,\n",
       "   'phoneme_end_idx': 3,\n",
       "   'phoneme_start_idx': 0,\n",
       "   'phones': ['W', 'AO', 'SH'],\n",
       "   'start': 28064,\n",
       "   'stop': 33360,\n",
       "   'stress': None}],\n",
       " [{'idx': 0,\n",
       "   'phoneme_end_idx': 2,\n",
       "   'phoneme_start_idx': 0,\n",
       "   'phones': ['W', 'AO'],\n",
       "   'start': 33754,\n",
       "   'stop': 36080,\n",
       "   'stress': None},\n",
       "  {'idx': 1,\n",
       "   'phoneme_end_idx': 4,\n",
       "   'phoneme_start_idx': 2,\n",
       "   'phones': ['T', 'ER'],\n",
       "   'start': 36080,\n",
       "   'stop': 37556,\n",
       "   'stress': None}],\n",
       " [{'idx': 0,\n",
       "   'phoneme_end_idx': 2,\n",
       "   'phoneme_start_idx': 0,\n",
       "   'phones': ['AO', 'L'],\n",
       "   'start': 37556,\n",
       "   'stop': 40313,\n",
       "   'stress': None}],\n",
       " [{'idx': 0,\n",
       "   'phoneme_end_idx': 2,\n",
       "   'phoneme_start_idx': 0,\n",
       "   'phones': ['Y', 'IH'],\n",
       "   'start': 40313,\n",
       "   'stop': 43479,\n",
       "   'stress': None},\n",
       "  {'idx': 1,\n",
       "   'phoneme_end_idx': 3,\n",
       "   'phoneme_start_idx': 2,\n",
       "   'phones': ['ER'],\n",
       "   'start': 43479,\n",
       "   'stop': 44586,\n",
       "   'stress': None}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timit_corpus[\"train\"][0][\"word_syllable_detail\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ca45dbbdb04cbe844f8e7d03c06496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['file', 'audio', 'text', 'phonetic_detail', 'word_detail', 'dialect_region', 'sentence_type', 'speaker_id', 'id', 'phonemic_detail', 'word_phonetic_detail', 'word_phonemic_detail', 'word_syllable_detail', 'input_values'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_spans_by_syllable = defaultdict(list)\n",
    "frame_spans_by_syllable_ordinal = defaultdict(list)\n",
    "frame_spans_by_syllable_and_ordinal = defaultdict(list)\n",
    "\n",
    "def process_item(item, idx):\n",
    "    # How many frames do we have stored for this item?\n",
    "    start_frame, stop_frame = equiv_frames_by_item[idx]\n",
    "    num_frames = stop_frame - start_frame\n",
    "\n",
    "    compression_ratio = num_frames / len(item[\"input_values\"])\n",
    "\n",
    "    for word in item[\"word_syllable_detail\"]:\n",
    "        for syllable in word:\n",
    "            syllable_start_frame = start_frame + int(syllable[\"start\"] * compression_ratio)\n",
    "            syllable_stop_frame = start_frame + int(syllable[\"stop\"] * compression_ratio)\n",
    "\n",
    "            syllable_phones = tuple(syllable[\"phones\"])\n",
    "            span = (syllable_start_frame, syllable_stop_frame)\n",
    "            frame_spans_by_syllable[syllable_phones].append(span)\n",
    "            frame_spans_by_syllable_ordinal[syllable[\"idx\"]].append(span)\n",
    "            frame_spans_by_syllable_and_ordinal[(syllable_phones, syllable[\"idx\"])].append(span)\n",
    "\n",
    "timit_corpus[\"train\"].map(process_item, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: we should have Q assignments for the final frame\n",
    "Q_assignments = {syll: [equiv_dataset.Q[end].item() for start, end in spans]\n",
    "                 for syll, spans in frame_spans_by_syllable.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_assignments_flat = np.array(list(itertools.chain.from_iterable(Q_assignments.values())))\n",
    "(Q_assignments_flat >= 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = StateSpaceAnalysisSpec(\n",
    "    total_num_frames=equiv_dataset.hidden_state_dataset.num_frames,\n",
    "    labels=list(frame_spans_by_syllable.keys()),\n",
    "    target_frame_spans=list(frame_spans_by_syllable.values()),\n",
    ")\n",
    "\n",
    "with open(out_by_identity, \"wb\") as f:\n",
    "    pickle.dump(spec, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = StateSpaceAnalysisSpec(\n",
    "    total_num_frames=equiv_dataset.hidden_state_dataset.num_frames,\n",
    "    labels=list(frame_spans_by_syllable_ordinal.keys()),\n",
    "    target_frame_spans=list(frame_spans_by_syllable_ordinal.values()),\n",
    ")\n",
    "\n",
    "with open(out_by_ordinal, \"wb\") as f:\n",
    "    pickle.dump(spec, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = StateSpaceAnalysisSpec(\n",
    "    total_num_frames=equiv_dataset.hidden_state_dataset.num_frames,\n",
    "    labels=list(frame_spans_by_syllable_and_ordinal.keys()),\n",
    "    target_frame_spans=list(frame_spans_by_syllable_and_ordinal.values()),\n",
    ")\n",
    "\n",
    "with open(out_by_identity_and_ordinal, \"wb\") as f:\n",
    "    pickle.dump(spec, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "explore310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

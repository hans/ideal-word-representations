{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import transformers\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Vocabulary\n",
    "from models.frame_level import FrameLevelRNNClassifier\n",
    "from models.transformer import TilingWordFeatureExtractor2, DataCollator\n",
    "from utils.timit import group_phonetic_detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner model and corpus prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:792: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.Wav2Vec2Tokenizer.from_pretrained(\"charsiu/tokenizer_en_cmu\")\n",
    "model = transformers.Wav2Vec2ForCTC.from_pretrained(\"charsiu/en_w2v2_ctc_libris_and_cv\")\n",
    "feature_extractor = transformers.Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=False)\n",
    "processor = transformers.Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = datasets.load_dataset(\"timit_asr\", data_dir=\"/userdata/jgauthier/data/TIMIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO cross-check resulting mappings with cmudict\n",
    "TIMIT_MAPPING = {\n",
    "    'ax': 'AH',\n",
    "    'ax-h': 'AH',\n",
    "    'axr': 'ER',\n",
    "    'dx': 'T',\n",
    "    'el': ['AH', 'L'],\n",
    "    'em': ['AH', 'M'],\n",
    "    'en': ['AH', 'N'],\n",
    "    'eng': ['IH', 'NG'],\n",
    "    'hv': 'HH',\n",
    "    'ix': 'IH',\n",
    "    'nx': ['N', 'T'],\n",
    "    'q': 'T',\n",
    "    'pau': '[SIL]',\n",
    "    'epi': '[SIL]',\n",
    "    'ux': 'UW'\n",
    "}\n",
    "\n",
    "VOCAB = set(tokenizer.get_vocab().keys())\n",
    "for src, tgt in TIMIT_MAPPING.items():\n",
    "    if isinstance(tgt, str):\n",
    "        tgt = [tgt]\n",
    "    for t in tgt:\n",
    "        assert t in VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d635df7a2102480f8d8d17f78b2f61d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4620 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72132eec4d75434f938c3d34017443e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TIMIT_IGNORE = [\"h#\"]\n",
    "TIMIT_JOIN_CLOSURES = ['bcl', 'dcl', 'gcl', 'kcl', 'pcl', 'tcl']\n",
    "\n",
    "\n",
    "def map_timit_phone_to_cmudict_phoneme(phone):\n",
    "    if phone in TIMIT_IGNORE:\n",
    "        return []\n",
    "    elif phone in TIMIT_MAPPING:\n",
    "        ret = TIMIT_MAPPING[phone]\n",
    "        if isinstance(ret, str):\n",
    "            ret = [ret]\n",
    "        return ret\n",
    "    elif not phone.upper() in VOCAB:\n",
    "        raise ValueError(f\"Invalid phone {phone.upper()}\")\n",
    "    return [phone.upper()]\n",
    "\n",
    "\n",
    "def map_timit_to_cmudict(timit_item):\n",
    "    phonemes = []\n",
    "\n",
    "    i = 0\n",
    "    phonetic_detail = timit_item[\"phonetic_detail\"]\n",
    "    num_phones = len(phonetic_detail[\"start\"])\n",
    "    while i < num_phones:\n",
    "        phone = phonetic_detail[\"utterance\"][i]\n",
    "        start = phonetic_detail[\"start\"][i]\n",
    "        stop = phonetic_detail[\"stop\"][i]\n",
    "\n",
    "        if phone in TIMIT_IGNORE:\n",
    "            i += 1\n",
    "        elif phone in TIMIT_JOIN_CLOSURES:\n",
    "            release_phone = phone[:-len(\"cl\")]\n",
    "            if phonetic_detail[\"utterance\"][i + 1] == release_phone:\n",
    "                phoneme_start = start\n",
    "                phoneme_end = phonetic_detail[\"stop\"][i + 1]\n",
    "                phoneme_label = map_timit_phone_to_cmudict_phoneme(release_phone)\n",
    "\n",
    "                for phoneme in phoneme_label:\n",
    "                    phonemes.append((phoneme_start, phoneme_end, phoneme))\n",
    "                i += 2\n",
    "            else:\n",
    "                phoneme_label = map_timit_phone_to_cmudict_phoneme(release_phone)\n",
    "                for phoneme in phoneme_label:\n",
    "                    phonemes.append((start, stop, phoneme))\n",
    "                i += 1\n",
    "        else:\n",
    "            for phoneme in map_timit_phone_to_cmudict_phoneme(phone):\n",
    "                phonemes.append((start, stop, phoneme))\n",
    "            i += 1\n",
    "\n",
    "    return phonemes\n",
    "\n",
    "\n",
    "def add_phonemic_detail(item):\n",
    "    phonemes = map_timit_to_cmudict(item)\n",
    "    # TODO group by word\n",
    "\n",
    "    starts, stops, utterances = zip(*phonemes)\n",
    "    item[\"phonemic_detail\"] = {\n",
    "        \"start\": starts,\n",
    "        \"stop\": stops,\n",
    "        \"utterance\": utterances\n",
    "    }\n",
    "\n",
    "    return item\n",
    "\n",
    "    \n",
    "corpus = corpus.map(add_phonemic_detail, batched=False, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_corpus(processor, drop_phones=None):\n",
    "    corpus = datasets.load_dataset(\"timit_asr\", data_dir=\"/userdata/jgauthier/data/TIMIT\")\n",
    "\n",
    "    corpus = corpus.map(add_phonemic_detail, batched=False)\n",
    "\n",
    "    # Compute phonetic and phonemic details grouped by word span\n",
    "    corpus = corpus.map(group_phonetic_detail, batched=False,\n",
    "                        fn_kwargs=dict(drop_phones=drop_phones))\n",
    "    corpus = corpus.map(group_phonetic_detail, batched=False,\n",
    "                        fn_kwargs=dict(key=\"phonemic_detail\"))\n",
    "    \n",
    "    def prepare_audio(batch):\n",
    "        audio = batch[\"audio\"]\n",
    "        batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "        return batch\n",
    "    corpus = corpus.map(prepare_audio)\n",
    "\n",
    "    twfe = TilingWordFeatureExtractor2(tokenizer, item_key=\"word_phonemic_detail\")\n",
    "    def add_features(example):\n",
    "        example[\"phone_targets\"] = twfe(example)\n",
    "        return example\n",
    "    corpus = corpus.map(add_features, load_from_cache_file=False)\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(processor, corpus_path=\"timit_phoneme_corpus\"):\n",
    "    if not Path(corpus_path).exists():\n",
    "        corpus = prepare_corpus(processor)\n",
    "        corpus.save_to_disk(corpus_path)\n",
    "    else:\n",
    "        corpus = datasets.load_from_disk(corpus_path)\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e6f6accb93472daddcc5ada81d386c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4620 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807f297bfa0749b190d77af0b2277dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3fbdb3d373430b9cf33daef4225fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4620 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c64e6389db4c82a2f04f7e25a68f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96000094f1b34d9babfa1c1664edbd3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4620 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351bb84748f44dc2b6a5311d8c35245d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00cac29719bc4cd88b9c99cd2c68cd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4620 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89c6cb9cb5c4770a0cc8b2071993f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7ffdf7a4aa4dfe9abcf264fa475ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/4620 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcff8f98b7f24042bf84a38957d2a3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/1680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus = load_corpus(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_split = corpus[\"train\"].train_test_split(test_size=0.1, shuffle=True)\n",
    "train_corpus, eval_corpus = corpora_split[\"train\"], corpora_split[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_init(model_name_or_path, config, device=\"cpu\"):\n",
    "    def model_init(trial):\n",
    "        model = FrameLevelRNNClassifier.from_pretrained(\n",
    "            model_name_or_path, config=config).to(device)\n",
    "\n",
    "        model.freeze_feature_extractor()\n",
    "\n",
    "        if hasattr(config, \"drop_layers\"):\n",
    "            model.wav2vec2 = drop_wav2vec_layers(model.wav2vec2, config.drop_layers)\n",
    "\n",
    "        # Freeze all model weights.\n",
    "        for param in model.wav2vec2.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        return model\n",
    "    return model_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p: transformers.EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    label_mask, labels = p.label_ids\n",
    "\n",
    "    def evaluate_label(j):\n",
    "        preds_j = preds[:, :, j]\n",
    "        labels_j = labels[:, :, j]\n",
    "\n",
    "        preds_j = preds_j[label_mask == 1]\n",
    "        labels_j = labels_j[label_mask == 1]\n",
    "        if labels_j.std() == 0:\n",
    "            # Only one class. Quit\n",
    "            return None\n",
    "        return roc_auc_score(labels_j, preds_j)\n",
    "\n",
    "    roc_auc_scores = [evaluate_label(j) for j in range(preds.shape[-1])]\n",
    "    return {\"roc_auc\": np.mean([score for score in roc_auc_scores if score is not None])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"charsiu/en_w2v2_ctc_libris_and_cv\"\n",
    "config = transformers.AutoConfig.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        num_labels=tokenizer.vocab_size)\n",
    "setattr(config, \"classifier_bias\", False)\n",
    "setattr(config, \"rnn_hidden_size\", 128)\n",
    "setattr(config, \"rnn_num_layers\", 2)\n",
    "setattr(config, \"drop_layers\", 6)\n",
    "model_init = make_model_init(model_name_or_path, config, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of FrameLevelRNNClassifier were not initialized from the model checkpoint at charsiu/en_w2v2_ctc_libris_and_cv and are newly initialized: ['rnn.bias_hh_l0', 'classifier.weight', 'rnn.bias_ih_l0', 'rnn.weight_hh_l0', 'rnn.weight_ih_l0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "coll = DataCollator(processor=processor, model=model_init(None), padding=True,\n",
    "                    num_labels=tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of FrameLevelRNNClassifier were not initialized from the model checkpoint at charsiu/en_w2v2_ctc_libris_and_cv and are newly initialized: ['rnn.bias_hh_l0', 'classifier.weight', 'rnn.bias_ih_l0', 'rnn.weight_hh_l0', 'rnn.weight_ih_l0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"out/rnn/rnn{config.rnn_num_layers}_hidden{config.rnn_hidden_size}_drop{config.drop_layers}\",\n",
    "    per_device_train_batch_size=16,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=50,\n",
    "    gradient_accumulation_steps=2,\n",
    "    save_steps=50,\n",
    "    eval_steps=50,\n",
    "    logging_steps=2,\n",
    "    learning_rate=1e-2,\n",
    "    save_total_limit=5,\n",
    "    use_cpu=False,\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    label_names=[\"label_mask\", \"labels\"],\n",
    "    disable_tqdm=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=None, model_init=model_init,\n",
    "    data_collator=coll,\n",
    "    args=training_args,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_corpus,\n",
    "    eval_dataset=eval_corpus,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of FrameLevelRNNClassifier were not initialized from the model checkpoint at charsiu/en_w2v2_ctc_libris_and_cv and are newly initialized: ['rnn.bias_hh_l0', 'classifier.weight', 'rnn.bias_ih_l0', 'rnn.weight_hh_l0', 'rnn.weight_ih_l0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6055, 'learning_rate': 0.009997222222222222, 'epoch': 0.01}\n",
      "{'loss': 0.3501, 'learning_rate': 0.009994444444444445, 'epoch': 0.03}\n",
      "{'loss': 0.2908, 'learning_rate': 0.009991666666666666, 'epoch': 0.04}\n",
      "{'loss': 0.285, 'learning_rate': 0.00998888888888889, 'epoch': 0.06}\n",
      "{'loss': 0.2811, 'learning_rate': 0.00998611111111111, 'epoch': 0.07}\n",
      "{'loss': 0.2962, 'learning_rate': 0.009983333333333334, 'epoch': 0.08}\n",
      "{'loss': 0.3028, 'learning_rate': 0.009980555555555557, 'epoch': 0.1}\n",
      "{'loss': 0.2887, 'learning_rate': 0.009977777777777778, 'epoch': 0.11}\n",
      "{'loss': 0.2784, 'learning_rate': 0.009975000000000001, 'epoch': 0.12}\n",
      "{'loss': 0.2868, 'learning_rate': 0.009972222222222223, 'epoch': 0.14}\n",
      "{'loss': 0.2797, 'learning_rate': 0.009969444444444444, 'epoch': 0.15}\n",
      "{'loss': 0.2831, 'learning_rate': 0.009966666666666667, 'epoch': 0.17}\n",
      "{'loss': 0.274, 'learning_rate': 0.009963888888888888, 'epoch': 0.18}\n",
      "{'loss': 0.2806, 'learning_rate': 0.009961111111111112, 'epoch': 0.19}\n",
      "{'loss': 0.279, 'learning_rate': 0.009958333333333333, 'epoch': 0.21}\n",
      "{'loss': 0.2795, 'learning_rate': 0.009955555555555556, 'epoch': 0.22}\n",
      "{'loss': 0.2667, 'learning_rate': 0.00995277777777778, 'epoch': 0.24}\n",
      "{'loss': 0.2714, 'learning_rate': 0.00995, 'epoch': 0.25}\n",
      "{'loss': 0.2691, 'learning_rate': 0.009947222222222222, 'epoch': 0.26}\n",
      "{'loss': 0.2765, 'learning_rate': 0.009944444444444445, 'epoch': 0.28}\n",
      "{'loss': 0.2771, 'learning_rate': 0.009941666666666666, 'epoch': 0.29}\n",
      "{'loss': 0.2846, 'learning_rate': 0.00993888888888889, 'epoch': 0.3}\n",
      "{'loss': 0.2733, 'learning_rate': 0.00993611111111111, 'epoch': 0.32}\n",
      "{'loss': 0.2718, 'learning_rate': 0.009933333333333334, 'epoch': 0.33}\n",
      "{'loss': 0.2805, 'learning_rate': 0.009930555555555555, 'epoch': 0.35}\n",
      "{'eval_loss': 0.27195340394973755, 'eval_roc_auc': 0.5748845496477324, 'eval_runtime': 51.5054, 'eval_samples_per_second': 32.618, 'eval_steps_per_second': 4.077, 'epoch': 0.35}\n",
      "{'loss': 0.2655, 'learning_rate': 0.009927777777777778, 'epoch': 0.36}\n",
      "{'loss': 0.2811, 'learning_rate': 0.009925000000000002, 'epoch': 0.37}\n",
      "{'loss': 0.2692, 'learning_rate': 0.009922222222222223, 'epoch': 0.39}\n",
      "{'loss': 0.2711, 'learning_rate': 0.009919444444444444, 'epoch': 0.4}\n",
      "{'loss': 0.277, 'learning_rate': 0.009916666666666667, 'epoch': 0.42}\n",
      "{'loss': 0.2633, 'learning_rate': 0.009913888888888889, 'epoch': 0.43}\n",
      "{'loss': 0.2744, 'learning_rate': 0.009911111111111112, 'epoch': 0.44}\n",
      "{'loss': 0.2662, 'learning_rate': 0.009908333333333333, 'epoch': 0.46}\n",
      "{'loss': 0.2678, 'learning_rate': 0.009905555555555555, 'epoch': 0.47}\n",
      "{'loss': 0.2728, 'learning_rate': 0.009902777777777778, 'epoch': 0.48}\n",
      "{'loss': 0.2707, 'learning_rate': 0.0099, 'epoch': 0.5}\n",
      "{'loss': 0.2595, 'learning_rate': 0.009897222222222222, 'epoch': 0.51}\n",
      "{'loss': 0.2535, 'learning_rate': 0.009894444444444445, 'epoch': 0.53}\n",
      "{'loss': 0.269, 'learning_rate': 0.009891666666666667, 'epoch': 0.54}\n",
      "{'loss': 0.2695, 'learning_rate': 0.00988888888888889, 'epoch': 0.55}\n",
      "{'loss': 0.2587, 'learning_rate': 0.009886111111111111, 'epoch': 0.57}\n",
      "{'loss': 0.2622, 'learning_rate': 0.009883333333333333, 'epoch': 0.58}\n",
      "{'loss': 0.266, 'learning_rate': 0.009880555555555556, 'epoch': 0.6}\n",
      "{'loss': 0.2673, 'learning_rate': 0.009877777777777777, 'epoch': 0.61}\n",
      "{'loss': 0.2641, 'learning_rate': 0.009875, 'epoch': 0.62}\n",
      "{'loss': 0.2656, 'learning_rate': 0.009872222222222223, 'epoch': 0.64}\n",
      "{'loss': 0.2713, 'learning_rate': 0.009869444444444445, 'epoch': 0.65}\n",
      "{'loss': 0.2534, 'learning_rate': 0.009866666666666668, 'epoch': 0.66}\n",
      "{'loss': 0.2662, 'learning_rate': 0.009863888888888889, 'epoch': 0.68}\n",
      "{'loss': 0.2548, 'learning_rate': 0.009861111111111112, 'epoch': 0.69}\n",
      "{'eval_loss': 0.2608911395072937, 'eval_roc_auc': 0.6412990508812393, 'eval_runtime': 52.368, 'eval_samples_per_second': 32.081, 'eval_steps_per_second': 4.01, 'epoch': 0.69}\n",
      "{'loss': 0.2571, 'learning_rate': 0.009858333333333334, 'epoch': 0.71}\n",
      "{'loss': 0.2606, 'learning_rate': 0.009855555555555555, 'epoch': 0.72}\n",
      "{'loss': 0.2605, 'learning_rate': 0.009852777777777778, 'epoch': 0.73}\n",
      "{'loss': 0.2615, 'learning_rate': 0.00985, 'epoch': 0.75}\n",
      "{'loss': 0.264, 'learning_rate': 0.009847222222222222, 'epoch': 0.76}\n",
      "{'loss': 0.2531, 'learning_rate': 0.009844444444444446, 'epoch': 0.78}\n",
      "{'loss': 0.2506, 'learning_rate': 0.009841666666666667, 'epoch': 0.79}\n",
      "{'loss': 0.2577, 'learning_rate': 0.00983888888888889, 'epoch': 0.8}\n",
      "{'loss': 0.2576, 'learning_rate': 0.009836111111111111, 'epoch': 0.82}\n",
      "{'loss': 0.2583, 'learning_rate': 0.009833333333333333, 'epoch': 0.83}\n",
      "{'loss': 0.2419, 'learning_rate': 0.009830555555555556, 'epoch': 0.84}\n",
      "{'loss': 0.2707, 'learning_rate': 0.009827777777777777, 'epoch': 0.86}\n",
      "{'loss': 0.2551, 'learning_rate': 0.009825, 'epoch': 0.87}\n",
      "{'loss': 0.2568, 'learning_rate': 0.009822222222222222, 'epoch': 0.89}\n",
      "{'loss': 0.2456, 'learning_rate': 0.009819444444444445, 'epoch': 0.9}\n",
      "{'loss': 0.2503, 'learning_rate': 0.009816666666666666, 'epoch': 0.91}\n",
      "{'loss': 0.2512, 'learning_rate': 0.00981388888888889, 'epoch': 0.93}\n",
      "{'loss': 0.2544, 'learning_rate': 0.009811111111111112, 'epoch': 0.94}\n",
      "{'loss': 0.2512, 'learning_rate': 0.009808333333333334, 'epoch': 0.96}\n",
      "{'loss': 0.2466, 'learning_rate': 0.009805555555555555, 'epoch': 0.97}\n",
      "{'loss': 0.2537, 'learning_rate': 0.009802777777777778, 'epoch': 0.98}\n",
      "{'loss': 0.2566, 'learning_rate': 0.0098, 'epoch': 1.0}\n",
      "{'loss': 0.2411, 'learning_rate': 0.009797222222222223, 'epoch': 1.01}\n",
      "{'loss': 0.2511, 'learning_rate': 0.009794444444444444, 'epoch': 1.02}\n",
      "{'loss': 0.2443, 'learning_rate': 0.009791666666666667, 'epoch': 1.04}\n",
      "{'eval_loss': 0.2500413656234741, 'eval_roc_auc': 0.6948908536470702, 'eval_runtime': 53.5025, 'eval_samples_per_second': 31.4, 'eval_steps_per_second': 3.925, 'epoch': 1.04}\n",
      "{'loss': 0.253, 'learning_rate': 0.009788888888888889, 'epoch': 1.05}\n",
      "{'loss': 0.2601, 'learning_rate': 0.009786111111111112, 'epoch': 1.07}\n",
      "{'loss': 0.2455, 'learning_rate': 0.009783333333333335, 'epoch': 1.08}\n",
      "{'loss': 0.2525, 'learning_rate': 0.009780555555555556, 'epoch': 1.09}\n",
      "{'loss': 0.253, 'learning_rate': 0.009777777777777778, 'epoch': 1.11}\n",
      "{'loss': 0.2668, 'learning_rate': 0.009775, 'epoch': 1.12}\n",
      "{'loss': 0.2512, 'learning_rate': 0.009772222222222222, 'epoch': 1.13}\n",
      "{'loss': 0.2585, 'learning_rate': 0.009769444444444443, 'epoch': 1.15}\n",
      "{'loss': 0.2529, 'learning_rate': 0.009766666666666667, 'epoch': 1.16}\n",
      "{'loss': 0.2496, 'learning_rate': 0.00976388888888889, 'epoch': 1.18}\n",
      "{'loss': 0.2472, 'learning_rate': 0.009761111111111111, 'epoch': 1.19}\n",
      "{'loss': 0.2596, 'learning_rate': 0.009758333333333334, 'epoch': 1.2}\n",
      "{'loss': 0.2498, 'learning_rate': 0.009755555555555556, 'epoch': 1.22}\n",
      "{'loss': 0.2564, 'learning_rate': 0.009752777777777779, 'epoch': 1.23}\n",
      "{'loss': 0.2487, 'learning_rate': 0.00975, 'epoch': 1.25}\n",
      "{'loss': 0.2542, 'learning_rate': 0.009747222222222223, 'epoch': 1.26}\n",
      "{'loss': 0.2382, 'learning_rate': 0.009744444444444444, 'epoch': 1.27}\n",
      "{'loss': 0.246, 'learning_rate': 0.009741666666666666, 'epoch': 1.29}\n",
      "{'loss': 0.2511, 'learning_rate': 0.009738888888888889, 'epoch': 1.3}\n",
      "{'loss': 0.2551, 'learning_rate': 0.00973611111111111, 'epoch': 1.31}\n",
      "{'loss': 0.2389, 'learning_rate': 0.009733333333333333, 'epoch': 1.33}\n",
      "{'loss': 0.2384, 'learning_rate': 0.009730555555555557, 'epoch': 1.34}\n",
      "{'loss': 0.2398, 'learning_rate': 0.009727777777777778, 'epoch': 1.36}\n",
      "{'loss': 0.2339, 'learning_rate': 0.009725000000000001, 'epoch': 1.37}\n",
      "{'loss': 0.2358, 'learning_rate': 0.009722222222222222, 'epoch': 1.38}\n",
      "{'eval_loss': 0.24068045616149902, 'eval_roc_auc': 0.7298438981724407, 'eval_runtime': 51.4206, 'eval_samples_per_second': 32.672, 'eval_steps_per_second': 4.084, 'epoch': 1.38}\n",
      "{'loss': 0.2351, 'learning_rate': 0.009719444444444445, 'epoch': 1.4}\n",
      "{'loss': 0.2336, 'learning_rate': 0.009716666666666667, 'epoch': 1.41}\n",
      "{'loss': 0.2454, 'learning_rate': 0.009713888888888888, 'epoch': 1.43}\n",
      "{'loss': 0.2436, 'learning_rate': 0.009711111111111111, 'epoch': 1.44}\n",
      "{'loss': 0.2461, 'learning_rate': 0.009708333333333333, 'epoch': 1.45}\n",
      "{'loss': 0.2421, 'learning_rate': 0.009705555555555556, 'epoch': 1.47}\n",
      "{'loss': 0.2444, 'learning_rate': 0.009702777777777779, 'epoch': 1.48}\n",
      "{'loss': 0.2402, 'learning_rate': 0.0097, 'epoch': 1.49}\n",
      "{'loss': 0.2281, 'learning_rate': 0.009697222222222223, 'epoch': 1.51}\n",
      "{'loss': 0.2426, 'learning_rate': 0.009694444444444445, 'epoch': 1.52}\n",
      "{'loss': 0.2344, 'learning_rate': 0.009691666666666666, 'epoch': 1.54}\n",
      "{'loss': 0.2357, 'learning_rate': 0.00968888888888889, 'epoch': 1.55}\n",
      "{'loss': 0.2338, 'learning_rate': 0.00968611111111111, 'epoch': 1.56}\n",
      "{'loss': 0.2392, 'learning_rate': 0.009683333333333334, 'epoch': 1.58}\n",
      "{'loss': 0.2422, 'learning_rate': 0.009680555555555555, 'epoch': 1.59}\n",
      "{'loss': 0.2469, 'learning_rate': 0.009677777777777778, 'epoch': 1.61}\n",
      "{'loss': 0.2381, 'learning_rate': 0.009675000000000001, 'epoch': 1.62}\n",
      "{'loss': 0.2445, 'learning_rate': 0.009672222222222223, 'epoch': 1.63}\n",
      "{'loss': 0.2409, 'learning_rate': 0.009669444444444446, 'epoch': 1.65}\n",
      "{'loss': 0.2312, 'learning_rate': 0.009666666666666667, 'epoch': 1.66}\n",
      "{'loss': 0.2353, 'learning_rate': 0.009663888888888889, 'epoch': 1.67}\n",
      "{'loss': 0.2323, 'learning_rate': 0.009661111111111112, 'epoch': 1.69}\n",
      "{'loss': 0.2459, 'learning_rate': 0.009658333333333333, 'epoch': 1.7}\n",
      "{'loss': 0.2214, 'learning_rate': 0.009655555555555554, 'epoch': 1.72}\n",
      "{'loss': 0.233, 'learning_rate': 0.009652777777777777, 'epoch': 1.73}\n",
      "{'eval_loss': 0.23443904519081116, 'eval_roc_auc': 0.7536637420068075, 'eval_runtime': 54.552, 'eval_samples_per_second': 30.796, 'eval_steps_per_second': 3.85, 'epoch': 1.73}\n",
      "{'loss': 0.2336, 'learning_rate': 0.00965, 'epoch': 1.74}\n",
      "{'loss': 0.2295, 'learning_rate': 0.009647222222222222, 'epoch': 1.76}\n",
      "{'loss': 0.2371, 'learning_rate': 0.009644444444444445, 'epoch': 1.77}\n",
      "{'loss': 0.2446, 'learning_rate': 0.009641666666666666, 'epoch': 1.79}\n",
      "{'loss': 0.2326, 'learning_rate': 0.00963888888888889, 'epoch': 1.8}\n",
      "{'loss': 0.228, 'learning_rate': 0.009636111111111111, 'epoch': 1.81}\n",
      "{'loss': 0.2259, 'learning_rate': 0.009633333333333334, 'epoch': 1.83}\n",
      "{'loss': 0.2201, 'learning_rate': 0.009630555555555555, 'epoch': 1.84}\n",
      "{'loss': 0.2318, 'learning_rate': 0.009627777777777777, 'epoch': 1.85}\n",
      "{'loss': 0.2296, 'learning_rate': 0.009625, 'epoch': 1.87}\n",
      "{'loss': 0.239, 'learning_rate': 0.009622222222222223, 'epoch': 1.88}\n",
      "{'loss': 0.231, 'learning_rate': 0.009619444444444444, 'epoch': 1.9}\n",
      "{'loss': 0.2273, 'learning_rate': 0.009616666666666667, 'epoch': 1.91}\n",
      "{'loss': 0.2464, 'learning_rate': 0.009613888888888889, 'epoch': 1.92}\n",
      "{'loss': 0.2411, 'learning_rate': 0.009611111111111112, 'epoch': 1.94}\n",
      "{'loss': 0.2317, 'learning_rate': 0.009608333333333333, 'epoch': 1.95}\n",
      "{'loss': 0.2242, 'learning_rate': 0.009605555555555556, 'epoch': 1.97}\n",
      "{'loss': 0.2279, 'learning_rate': 0.009602777777777778, 'epoch': 1.98}\n",
      "{'loss': 0.2229, 'learning_rate': 0.0096, 'epoch': 1.99}\n",
      "{'loss': 0.2334, 'learning_rate': 0.009597222222222222, 'epoch': 2.01}\n",
      "{'loss': 0.2318, 'learning_rate': 0.009594444444444445, 'epoch': 2.02}\n",
      "{'loss': 0.2209, 'learning_rate': 0.009591666666666667, 'epoch': 2.03}\n",
      "{'loss': 0.2294, 'learning_rate': 0.00958888888888889, 'epoch': 2.05}\n",
      "{'loss': 0.2279, 'learning_rate': 0.009586111111111111, 'epoch': 2.06}\n",
      "{'loss': 0.2363, 'learning_rate': 0.009583333333333334, 'epoch': 2.08}\n",
      "{'eval_loss': 0.22949978709220886, 'eval_roc_auc': 0.7678858217457616, 'eval_runtime': 50.8645, 'eval_samples_per_second': 33.029, 'eval_steps_per_second': 4.129, 'epoch': 2.08}\n",
      "{'loss': 0.2232, 'learning_rate': 0.009580555555555556, 'epoch': 2.09}\n",
      "{'loss': 0.2307, 'learning_rate': 0.009577777777777777, 'epoch': 2.1}\n",
      "{'loss': 0.2343, 'learning_rate': 0.009575, 'epoch': 2.12}\n",
      "{'loss': 0.2227, 'learning_rate': 0.009572222222222222, 'epoch': 2.13}\n",
      "{'loss': 0.2255, 'learning_rate': 0.009569444444444445, 'epoch': 2.15}\n",
      "{'loss': 0.2269, 'learning_rate': 0.009566666666666666, 'epoch': 2.16}\n",
      "{'loss': 0.2415, 'learning_rate': 0.00956388888888889, 'epoch': 2.17}\n",
      "{'loss': 0.2428, 'learning_rate': 0.009561111111111112, 'epoch': 2.19}\n",
      "{'loss': 0.2293, 'learning_rate': 0.009558333333333334, 'epoch': 2.2}\n",
      "{'loss': 0.2223, 'learning_rate': 0.009555555555555557, 'epoch': 2.21}\n",
      "{'loss': 0.2246, 'learning_rate': 0.009552777777777778, 'epoch': 2.23}\n",
      "{'loss': 0.2419, 'learning_rate': 0.00955, 'epoch': 2.24}\n",
      "{'loss': 0.2284, 'learning_rate': 0.009547222222222223, 'epoch': 2.26}\n",
      "{'loss': 0.2288, 'learning_rate': 0.009544444444444444, 'epoch': 2.27}\n",
      "{'loss': 0.2394, 'learning_rate': 0.009541666666666667, 'epoch': 2.28}\n",
      "{'loss': 0.2261, 'learning_rate': 0.009538888888888888, 'epoch': 2.3}\n",
      "{'loss': 0.2361, 'learning_rate': 0.009536111111111112, 'epoch': 2.31}\n",
      "{'loss': 0.23, 'learning_rate': 0.009533333333333335, 'epoch': 2.33}\n",
      "{'loss': 0.2296, 'learning_rate': 0.009530555555555556, 'epoch': 2.34}\n",
      "{'loss': 0.2263, 'learning_rate': 0.009527777777777777, 'epoch': 2.35}\n",
      "{'loss': 0.218, 'learning_rate': 0.009525, 'epoch': 2.37}\n",
      "{'loss': 0.2404, 'learning_rate': 0.009522222222222222, 'epoch': 2.38}\n",
      "{'loss': 0.2274, 'learning_rate': 0.009519444444444445, 'epoch': 2.39}\n",
      "{'loss': 0.2317, 'learning_rate': 0.009516666666666666, 'epoch': 2.41}\n",
      "{'loss': 0.2276, 'learning_rate': 0.00951388888888889, 'epoch': 2.42}\n",
      "{'eval_loss': 0.22606992721557617, 'eval_roc_auc': 0.7759748042063912, 'eval_runtime': 51.2817, 'eval_samples_per_second': 32.76, 'eval_steps_per_second': 4.095, 'epoch': 2.42}\n",
      "{'loss': 0.223, 'learning_rate': 0.00951111111111111, 'epoch': 2.44}\n",
      "{'loss': 0.242, 'learning_rate': 0.009508333333333334, 'epoch': 2.45}\n",
      "{'loss': 0.2191, 'learning_rate': 0.009505555555555557, 'epoch': 2.46}\n",
      "{'loss': 0.231, 'learning_rate': 0.009502777777777778, 'epoch': 2.48}\n",
      "{'loss': 0.2314, 'learning_rate': 0.0095, 'epoch': 2.49}\n",
      "{'loss': 0.2234, 'learning_rate': 0.009497222222222223, 'epoch': 2.51}\n",
      "{'loss': 0.2339, 'learning_rate': 0.009494444444444444, 'epoch': 2.52}\n",
      "{'loss': 0.2195, 'learning_rate': 0.009491666666666667, 'epoch': 2.53}\n",
      "{'loss': 0.2356, 'learning_rate': 0.009488888888888889, 'epoch': 2.55}\n",
      "{'loss': 0.2219, 'learning_rate': 0.00948611111111111, 'epoch': 2.56}\n",
      "{'loss': 0.2229, 'learning_rate': 0.009483333333333333, 'epoch': 2.57}\n",
      "{'loss': 0.2232, 'learning_rate': 0.009480555555555556, 'epoch': 2.59}\n",
      "{'loss': 0.2252, 'learning_rate': 0.009477777777777778, 'epoch': 2.6}\n",
      "{'loss': 0.2365, 'learning_rate': 0.009475, 'epoch': 2.62}\n",
      "{'loss': 0.2219, 'learning_rate': 0.009472222222222222, 'epoch': 2.63}\n",
      "{'loss': 0.2145, 'learning_rate': 0.009469444444444445, 'epoch': 2.64}\n",
      "{'loss': 0.2345, 'learning_rate': 0.009466666666666667, 'epoch': 2.66}\n",
      "{'loss': 0.2358, 'learning_rate': 0.009463888888888888, 'epoch': 2.67}\n",
      "{'loss': 0.2245, 'learning_rate': 0.009461111111111111, 'epoch': 2.69}\n",
      "{'loss': 0.2315, 'learning_rate': 0.009458333333333332, 'epoch': 2.7}\n",
      "{'loss': 0.2165, 'learning_rate': 0.009455555555555556, 'epoch': 2.71}\n",
      "{'loss': 0.2407, 'learning_rate': 0.009452777777777779, 'epoch': 2.73}\n",
      "{'loss': 0.2307, 'learning_rate': 0.00945, 'epoch': 2.74}\n",
      "{'loss': 0.2169, 'learning_rate': 0.009447222222222223, 'epoch': 2.75}\n",
      "{'loss': 0.2237, 'learning_rate': 0.009444444444444445, 'epoch': 2.77}\n",
      "{'eval_loss': 0.22203214466571808, 'eval_roc_auc': 0.7874832492804471, 'eval_runtime': 52.2774, 'eval_samples_per_second': 32.136, 'eval_steps_per_second': 4.017, 'epoch': 2.77}\n",
      "{'loss': 0.2204, 'learning_rate': 0.009441666666666668, 'epoch': 2.78}\n",
      "{'loss': 0.2186, 'learning_rate': 0.009438888888888889, 'epoch': 2.8}\n",
      "{'loss': 0.223, 'learning_rate': 0.00943611111111111, 'epoch': 2.81}\n",
      "{'loss': 0.2205, 'learning_rate': 0.009433333333333334, 'epoch': 2.82}\n",
      "{'loss': 0.2275, 'learning_rate': 0.009430555555555555, 'epoch': 2.84}\n",
      "{'loss': 0.2214, 'learning_rate': 0.009427777777777778, 'epoch': 2.85}\n",
      "{'loss': 0.2154, 'learning_rate': 0.009425000000000001, 'epoch': 2.87}\n",
      "{'loss': 0.2272, 'learning_rate': 0.009422222222222222, 'epoch': 2.88}\n",
      "{'loss': 0.2189, 'learning_rate': 0.009419444444444446, 'epoch': 2.89}\n",
      "{'loss': 0.2275, 'learning_rate': 0.009416666666666667, 'epoch': 2.91}\n",
      "{'loss': 0.2351, 'learning_rate': 0.00941388888888889, 'epoch': 2.92}\n",
      "{'loss': 0.2147, 'learning_rate': 0.009411111111111111, 'epoch': 2.93}\n",
      "{'loss': 0.2175, 'learning_rate': 0.009408333333333333, 'epoch': 2.95}\n",
      "{'loss': 0.2331, 'learning_rate': 0.009405555555555556, 'epoch': 2.96}\n",
      "{'loss': 0.213, 'learning_rate': 0.009402777777777777, 'epoch': 2.98}\n",
      "{'loss': 0.2319, 'learning_rate': 0.0094, 'epoch': 2.99}\n",
      "{'loss': 0.2118, 'learning_rate': 0.009397222222222222, 'epoch': 3.0}\n",
      "{'loss': 0.231, 'learning_rate': 0.009394444444444445, 'epoch': 3.02}\n",
      "{'loss': 0.2294, 'learning_rate': 0.009391666666666668, 'epoch': 3.03}\n",
      "{'loss': 0.2352, 'learning_rate': 0.00938888888888889, 'epoch': 3.04}\n",
      "{'loss': 0.2204, 'learning_rate': 0.00938611111111111, 'epoch': 3.06}\n",
      "{'loss': 0.215, 'learning_rate': 0.009383333333333334, 'epoch': 3.07}\n",
      "{'loss': 0.2223, 'learning_rate': 0.009380555555555555, 'epoch': 3.09}\n",
      "{'loss': 0.2307, 'learning_rate': 0.009377777777777778, 'epoch': 3.1}\n",
      "{'loss': 0.2146, 'learning_rate': 0.009375, 'epoch': 3.11}\n",
      "{'eval_loss': 0.22040928900241852, 'eval_roc_auc': 0.7927368813347747, 'eval_runtime': 55.3226, 'eval_samples_per_second': 30.367, 'eval_steps_per_second': 3.796, 'epoch': 3.11}\n",
      "{'loss': 0.2184, 'learning_rate': 0.009372222222222223, 'epoch': 3.13}\n",
      "{'loss': 0.2198, 'learning_rate': 0.009369444444444444, 'epoch': 3.14}\n",
      "{'loss': 0.2146, 'learning_rate': 0.009366666666666667, 'epoch': 3.16}\n",
      "{'loss': 0.2262, 'learning_rate': 0.00936388888888889, 'epoch': 3.17}\n",
      "{'loss': 0.2315, 'learning_rate': 0.009361111111111112, 'epoch': 3.18}\n",
      "{'loss': 0.2204, 'learning_rate': 0.009358333333333333, 'epoch': 3.2}\n",
      "{'loss': 0.2221, 'learning_rate': 0.009355555555555556, 'epoch': 3.21}\n",
      "{'loss': 0.2179, 'learning_rate': 0.009352777777777778, 'epoch': 3.22}\n",
      "{'loss': 0.216, 'learning_rate': 0.00935, 'epoch': 3.24}\n",
      "{'loss': 0.2153, 'learning_rate': 0.009347222222222222, 'epoch': 3.25}\n",
      "{'loss': 0.221, 'learning_rate': 0.009344444444444445, 'epoch': 3.27}\n",
      "{'loss': 0.221, 'learning_rate': 0.009341666666666667, 'epoch': 3.28}\n",
      "{'loss': 0.2147, 'learning_rate': 0.00933888888888889, 'epoch': 3.29}\n",
      "{'loss': 0.2103, 'learning_rate': 0.009336111111111111, 'epoch': 3.31}\n",
      "{'loss': 0.2206, 'learning_rate': 0.009333333333333334, 'epoch': 3.32}\n",
      "{'loss': 0.2091, 'learning_rate': 0.009330555555555555, 'epoch': 3.34}\n",
      "{'loss': 0.2259, 'learning_rate': 0.009327777777777779, 'epoch': 3.35}\n",
      "{'loss': 0.2164, 'learning_rate': 0.009325, 'epoch': 3.36}\n",
      "{'loss': 0.2211, 'learning_rate': 0.009322222222222221, 'epoch': 3.38}\n",
      "{'loss': 0.2298, 'learning_rate': 0.009319444444444444, 'epoch': 3.39}\n",
      "{'loss': 0.2231, 'learning_rate': 0.009316666666666666, 'epoch': 3.4}\n",
      "{'loss': 0.2242, 'learning_rate': 0.009313888888888889, 'epoch': 3.42}\n",
      "{'loss': 0.2166, 'learning_rate': 0.009311111111111112, 'epoch': 3.43}\n",
      "{'loss': 0.2142, 'learning_rate': 0.009308333333333333, 'epoch': 3.45}\n",
      "{'loss': 0.209, 'learning_rate': 0.009305555555555556, 'epoch': 3.46}\n",
      "{'eval_loss': 0.21337933838367462, 'eval_roc_auc': 0.8049167543356696, 'eval_runtime': 52.2651, 'eval_samples_per_second': 32.144, 'eval_steps_per_second': 4.018, 'epoch': 3.46}\n",
      "{'loss': 0.212, 'learning_rate': 0.009302777777777778, 'epoch': 3.47}\n",
      "{'loss': 0.2196, 'learning_rate': 0.009300000000000001, 'epoch': 3.49}\n",
      "{'loss': 0.2129, 'learning_rate': 0.009297222222222222, 'epoch': 3.5}\n",
      "{'loss': 0.2141, 'learning_rate': 0.009294444444444444, 'epoch': 3.52}\n",
      "{'loss': 0.2218, 'learning_rate': 0.009291666666666667, 'epoch': 3.53}\n",
      "{'loss': 0.2202, 'learning_rate': 0.009288888888888888, 'epoch': 3.54}\n",
      "{'loss': 0.2189, 'learning_rate': 0.009286111111111111, 'epoch': 3.56}\n",
      "{'loss': 0.2088, 'learning_rate': 0.009283333333333334, 'epoch': 3.57}\n",
      "{'loss': 0.216, 'learning_rate': 0.009280555555555556, 'epoch': 3.58}\n",
      "{'loss': 0.2095, 'learning_rate': 0.009277777777777779, 'epoch': 3.6}\n",
      "{'loss': 0.2251, 'learning_rate': 0.009275, 'epoch': 3.61}\n",
      "{'loss': 0.2209, 'learning_rate': 0.009272222222222222, 'epoch': 3.63}\n",
      "{'loss': 0.2232, 'learning_rate': 0.009269444444444445, 'epoch': 3.64}\n",
      "{'loss': 0.2069, 'learning_rate': 0.009266666666666666, 'epoch': 3.65}\n",
      "{'loss': 0.2166, 'learning_rate': 0.00926388888888889, 'epoch': 3.67}\n",
      "{'loss': 0.207, 'learning_rate': 0.00926111111111111, 'epoch': 3.68}\n",
      "{'loss': 0.2373, 'learning_rate': 0.009258333333333334, 'epoch': 3.7}\n",
      "{'loss': 0.2262, 'learning_rate': 0.009255555555555557, 'epoch': 3.71}\n",
      "{'loss': 0.206, 'learning_rate': 0.009252777777777778, 'epoch': 3.72}\n",
      "{'loss': 0.202, 'learning_rate': 0.009250000000000001, 'epoch': 3.74}\n",
      "{'loss': 0.2066, 'learning_rate': 0.009247222222222223, 'epoch': 3.75}\n",
      "{'loss': 0.2147, 'learning_rate': 0.009244444444444444, 'epoch': 3.76}\n",
      "{'loss': 0.2174, 'learning_rate': 0.009241666666666667, 'epoch': 3.78}\n",
      "{'loss': 0.2002, 'learning_rate': 0.009238888888888888, 'epoch': 3.79}\n",
      "{'loss': 0.2117, 'learning_rate': 0.009236111111111112, 'epoch': 3.81}\n",
      "{'eval_loss': 0.21090465784072876, 'eval_roc_auc': 0.8098512125701018, 'eval_runtime': 52.0438, 'eval_samples_per_second': 32.281, 'eval_steps_per_second': 4.035, 'epoch': 3.81}\n",
      "{'loss': 0.2008, 'learning_rate': 0.009233333333333333, 'epoch': 3.82}\n",
      "{'loss': 0.2102, 'learning_rate': 0.009230555555555556, 'epoch': 3.83}\n",
      "{'loss': 0.2127, 'learning_rate': 0.009227777777777777, 'epoch': 3.85}\n",
      "{'loss': 0.2179, 'learning_rate': 0.009225, 'epoch': 3.86}\n",
      "{'loss': 0.2139, 'learning_rate': 0.009222222222222224, 'epoch': 3.88}\n",
      "{'loss': 0.2163, 'learning_rate': 0.009219444444444445, 'epoch': 3.89}\n",
      "{'loss': 0.2058, 'learning_rate': 0.009216666666666666, 'epoch': 3.9}\n",
      "{'loss': 0.2115, 'learning_rate': 0.00921388888888889, 'epoch': 3.92}\n",
      "{'loss': 0.2221, 'learning_rate': 0.009211111111111111, 'epoch': 3.93}\n",
      "{'loss': 0.1975, 'learning_rate': 0.009208333333333332, 'epoch': 3.94}\n",
      "{'loss': 0.2166, 'learning_rate': 0.009205555555555555, 'epoch': 3.96}\n",
      "{'loss': 0.2076, 'learning_rate': 0.009202777777777778, 'epoch': 3.97}\n",
      "{'loss': 0.2136, 'learning_rate': 0.0092, 'epoch': 3.99}\n",
      "{'loss': 0.22, 'learning_rate': 0.009197222222222223, 'epoch': 4.0}\n",
      "{'loss': 0.2224, 'learning_rate': 0.009194444444444444, 'epoch': 4.01}\n",
      "{'loss': 0.192, 'learning_rate': 0.009191666666666667, 'epoch': 4.03}\n",
      "{'loss': 0.2223, 'learning_rate': 0.009188888888888889, 'epoch': 4.04}\n",
      "{'loss': 0.2131, 'learning_rate': 0.009186111111111112, 'epoch': 4.06}\n",
      "{'loss': 0.2033, 'learning_rate': 0.009183333333333333, 'epoch': 4.07}\n",
      "{'loss': 0.209, 'learning_rate': 0.009180555555555555, 'epoch': 4.08}\n",
      "{'loss': 0.1974, 'learning_rate': 0.009177777777777778, 'epoch': 4.1}\n",
      "{'loss': 0.2234, 'learning_rate': 0.009175, 'epoch': 4.11}\n",
      "{'loss': 0.2273, 'learning_rate': 0.009172222222222222, 'epoch': 4.12}\n",
      "{'loss': 0.2138, 'learning_rate': 0.009169444444444445, 'epoch': 4.14}\n",
      "{'loss': 0.2017, 'learning_rate': 0.009166666666666667, 'epoch': 4.15}\n",
      "{'eval_loss': 0.2058999240398407, 'eval_roc_auc': 0.8178295027936041, 'eval_runtime': 51.3184, 'eval_samples_per_second': 32.737, 'eval_steps_per_second': 4.092, 'epoch': 4.15}\n",
      "{'loss': 0.2131, 'learning_rate': 0.00916388888888889, 'epoch': 4.17}\n",
      "{'loss': 0.2085, 'learning_rate': 0.009161111111111111, 'epoch': 4.18}\n",
      "{'loss': 0.1976, 'learning_rate': 0.009158333333333334, 'epoch': 4.19}\n",
      "{'loss': 0.2043, 'learning_rate': 0.009155555555555556, 'epoch': 4.21}\n",
      "{'loss': 0.2177, 'learning_rate': 0.009152777777777777, 'epoch': 4.22}\n",
      "{'loss': 0.1962, 'learning_rate': 0.00915, 'epoch': 4.24}\n",
      "{'loss': 0.2116, 'learning_rate': 0.009147222222222222, 'epoch': 4.25}\n",
      "{'loss': 0.2034, 'learning_rate': 0.009144444444444445, 'epoch': 4.26}\n",
      "{'loss': 0.2124, 'learning_rate': 0.009141666666666668, 'epoch': 4.28}\n",
      "{'loss': 0.2093, 'learning_rate': 0.009138888888888889, 'epoch': 4.29}\n",
      "{'loss': 0.2049, 'learning_rate': 0.009136111111111112, 'epoch': 4.3}\n",
      "{'loss': 0.2086, 'learning_rate': 0.009133333333333334, 'epoch': 4.32}\n",
      "{'loss': 0.2266, 'learning_rate': 0.009130555555555555, 'epoch': 4.33}\n",
      "{'loss': 0.2023, 'learning_rate': 0.009127777777777778, 'epoch': 4.35}\n",
      "{'loss': 0.2218, 'learning_rate': 0.009125, 'epoch': 4.36}\n",
      "{'loss': 0.2063, 'learning_rate': 0.009122222222222223, 'epoch': 4.37}\n",
      "{'loss': 0.2068, 'learning_rate': 0.009119444444444444, 'epoch': 4.39}\n",
      "{'loss': 0.2121, 'learning_rate': 0.009116666666666667, 'epoch': 4.4}\n",
      "{'loss': 0.2069, 'learning_rate': 0.00911388888888889, 'epoch': 4.42}\n",
      "{'loss': 0.2095, 'learning_rate': 0.009111111111111111, 'epoch': 4.43}\n",
      "{'loss': 0.2122, 'learning_rate': 0.009108333333333335, 'epoch': 4.44}\n",
      "{'loss': 0.2022, 'learning_rate': 0.009105555555555556, 'epoch': 4.46}\n",
      "{'loss': 0.1923, 'learning_rate': 0.009102777777777777, 'epoch': 4.47}\n",
      "{'loss': 0.2013, 'learning_rate': 0.0091, 'epoch': 4.48}\n",
      "{'loss': 0.2066, 'learning_rate': 0.009097222222222222, 'epoch': 4.5}\n",
      "{'eval_loss': 0.20360198616981506, 'eval_roc_auc': 0.8224582592818038, 'eval_runtime': 52.6456, 'eval_samples_per_second': 31.911, 'eval_steps_per_second': 3.989, 'epoch': 4.5}\n",
      "{'loss': 0.1877, 'learning_rate': 0.009094444444444445, 'epoch': 4.51}\n",
      "{'loss': 0.215, 'learning_rate': 0.009091666666666666, 'epoch': 4.53}\n",
      "{'loss': 0.196, 'learning_rate': 0.00908888888888889, 'epoch': 4.54}\n",
      "{'loss': 0.2241, 'learning_rate': 0.009086111111111113, 'epoch': 4.55}\n",
      "{'loss': 0.1955, 'learning_rate': 0.009083333333333334, 'epoch': 4.57}\n",
      "{'loss': 0.2073, 'learning_rate': 0.009080555555555555, 'epoch': 4.58}\n",
      "{'loss': 0.2076, 'learning_rate': 0.009077777777777778, 'epoch': 4.6}\n",
      "{'loss': 0.2006, 'learning_rate': 0.009075, 'epoch': 4.61}\n",
      "{'loss': 0.2042, 'learning_rate': 0.009072222222222223, 'epoch': 4.62}\n",
      "{'loss': 0.2072, 'learning_rate': 0.009069444444444444, 'epoch': 4.64}\n",
      "{'loss': 0.2216, 'learning_rate': 0.009066666666666666, 'epoch': 4.65}\n",
      "{'loss': 0.2031, 'learning_rate': 0.009063888888888889, 'epoch': 4.66}\n",
      "{'loss': 0.2204, 'learning_rate': 0.009061111111111112, 'epoch': 4.68}\n",
      "{'loss': 0.2059, 'learning_rate': 0.009058333333333333, 'epoch': 4.69}\n",
      "{'loss': 0.2054, 'learning_rate': 0.009055555555555556, 'epoch': 4.71}\n",
      "{'loss': 0.2005, 'learning_rate': 0.009052777777777778, 'epoch': 4.72}\n",
      "{'loss': 0.2117, 'learning_rate': 0.00905, 'epoch': 4.73}\n",
      "{'loss': 0.1948, 'learning_rate': 0.009047222222222222, 'epoch': 4.75}\n",
      "{'loss': 0.2008, 'learning_rate': 0.009044444444444445, 'epoch': 4.76}\n",
      "{'loss': 0.1998, 'learning_rate': 0.009041666666666667, 'epoch': 4.78}\n",
      "{'loss': 0.2069, 'learning_rate': 0.009038888888888888, 'epoch': 4.79}\n",
      "{'loss': 0.2192, 'learning_rate': 0.009036111111111111, 'epoch': 4.8}\n",
      "{'loss': 0.2137, 'learning_rate': 0.009033333333333334, 'epoch': 4.82}\n",
      "{'loss': 0.2066, 'learning_rate': 0.009030555555555556, 'epoch': 4.83}\n",
      "{'loss': 0.1911, 'learning_rate': 0.009027777777777779, 'epoch': 4.84}\n",
      "{'eval_loss': 0.19910652935504913, 'eval_roc_auc': 0.8291806085120698, 'eval_runtime': 52.3541, 'eval_samples_per_second': 32.089, 'eval_steps_per_second': 4.011, 'epoch': 4.84}\n",
      "{'loss': 0.1977, 'learning_rate': 0.009025, 'epoch': 4.86}\n",
      "{'loss': 0.1723, 'learning_rate': 0.009022222222222223, 'epoch': 4.87}\n",
      "{'loss': 0.1958, 'learning_rate': 0.009019444444444445, 'epoch': 4.89}\n",
      "{'loss': 0.2052, 'learning_rate': 0.009016666666666666, 'epoch': 4.9}\n",
      "{'loss': 0.2128, 'learning_rate': 0.009013888888888889, 'epoch': 4.91}\n",
      "{'loss': 0.1962, 'learning_rate': 0.00901111111111111, 'epoch': 4.93}\n",
      "{'loss': 0.1919, 'learning_rate': 0.009008333333333333, 'epoch': 4.94}\n",
      "{'loss': 0.204, 'learning_rate': 0.009005555555555557, 'epoch': 4.96}\n",
      "{'loss': 0.1859, 'learning_rate': 0.009002777777777778, 'epoch': 4.97}\n",
      "{'loss': 0.2046, 'learning_rate': 0.009000000000000001, 'epoch': 4.98}\n",
      "{'loss': 0.2089, 'learning_rate': 0.008997222222222222, 'epoch': 5.0}\n",
      "{'loss': 0.1825, 'learning_rate': 0.008994444444444446, 'epoch': 5.01}\n",
      "{'loss': 0.1949, 'learning_rate': 0.008991666666666667, 'epoch': 5.02}\n",
      "{'loss': 0.2071, 'learning_rate': 0.008988888888888888, 'epoch': 5.04}\n",
      "{'loss': 0.2085, 'learning_rate': 0.008986111111111111, 'epoch': 5.05}\n",
      "{'loss': 0.1918, 'learning_rate': 0.008983333333333333, 'epoch': 5.07}\n",
      "{'loss': 0.1961, 'learning_rate': 0.008980555555555556, 'epoch': 5.08}\n",
      "{'loss': 0.204, 'learning_rate': 0.008977777777777777, 'epoch': 5.09}\n",
      "{'loss': 0.2008, 'learning_rate': 0.008975, 'epoch': 5.11}\n",
      "{'loss': 0.2116, 'learning_rate': 0.008972222222222223, 'epoch': 5.12}\n",
      "{'loss': 0.2078, 'learning_rate': 0.008969444444444445, 'epoch': 5.13}\n",
      "{'loss': 0.1998, 'learning_rate': 0.008966666666666666, 'epoch': 5.15}\n",
      "{'loss': 0.2057, 'learning_rate': 0.00896388888888889, 'epoch': 5.16}\n",
      "{'loss': 0.2043, 'learning_rate': 0.00896111111111111, 'epoch': 5.18}\n",
      "{'loss': 0.2033, 'learning_rate': 0.008958333333333334, 'epoch': 5.19}\n",
      "{'eval_loss': 0.19745555520057678, 'eval_roc_auc': 0.8372382849444542, 'eval_runtime': 52.9639, 'eval_samples_per_second': 31.72, 'eval_steps_per_second': 3.965, 'epoch': 5.19}\n",
      "{'loss': 0.2088, 'learning_rate': 0.008955555555555555, 'epoch': 5.2}\n",
      "{'loss': 0.1999, 'learning_rate': 0.008952777777777778, 'epoch': 5.22}\n",
      "{'loss': 0.2028, 'learning_rate': 0.00895, 'epoch': 5.23}\n",
      "{'loss': 0.2142, 'learning_rate': 0.008947222222222223, 'epoch': 5.25}\n",
      "{'loss': 0.1949, 'learning_rate': 0.008944444444444446, 'epoch': 5.26}\n",
      "{'loss': 0.1999, 'learning_rate': 0.008941666666666667, 'epoch': 5.27}\n",
      "{'loss': 0.2039, 'learning_rate': 0.008938888888888889, 'epoch': 5.29}\n",
      "{'loss': 0.1945, 'learning_rate': 0.008936111111111112, 'epoch': 5.3}\n",
      "{'loss': 0.2109, 'learning_rate': 0.008933333333333333, 'epoch': 5.31}\n",
      "{'loss': 0.1977, 'learning_rate': 0.008930555555555556, 'epoch': 5.33}\n",
      "{'loss': 0.1987, 'learning_rate': 0.008927777777777778, 'epoch': 5.34}\n",
      "{'loss': 0.1998, 'learning_rate': 0.008925, 'epoch': 5.36}\n",
      "{'loss': 0.1933, 'learning_rate': 0.008922222222222222, 'epoch': 5.37}\n",
      "{'loss': 0.2007, 'learning_rate': 0.008919444444444445, 'epoch': 5.38}\n",
      "{'loss': 0.2039, 'learning_rate': 0.008916666666666668, 'epoch': 5.4}\n",
      "{'loss': 0.2147, 'learning_rate': 0.00891388888888889, 'epoch': 5.41}\n",
      "{'loss': 0.2009, 'learning_rate': 0.008911111111111111, 'epoch': 5.43}\n",
      "{'loss': 0.1865, 'learning_rate': 0.008908333333333334, 'epoch': 5.44}\n",
      "{'loss': 0.2121, 'learning_rate': 0.008905555555555555, 'epoch': 5.45}\n",
      "{'loss': 0.2063, 'learning_rate': 0.008902777777777777, 'epoch': 5.47}\n",
      "{'loss': 0.1896, 'learning_rate': 0.0089, 'epoch': 5.48}\n",
      "{'loss': 0.185, 'learning_rate': 0.008897222222222221, 'epoch': 5.49}\n",
      "{'loss': 0.1908, 'learning_rate': 0.008894444444444444, 'epoch': 5.51}\n",
      "{'loss': 0.203, 'learning_rate': 0.008891666666666668, 'epoch': 5.52}\n",
      "{'loss': 0.2035, 'learning_rate': 0.008888888888888889, 'epoch': 5.54}\n",
      "{'eval_loss': 0.19394302368164062, 'eval_roc_auc': 0.8398889636064073, 'eval_runtime': 55.3245, 'eval_samples_per_second': 30.366, 'eval_steps_per_second': 3.796, 'epoch': 5.54}\n",
      "{'loss': 0.1981, 'learning_rate': 0.008886111111111112, 'epoch': 5.55}\n",
      "{'loss': 0.1825, 'learning_rate': 0.008883333333333333, 'epoch': 5.56}\n",
      "{'loss': 0.1875, 'learning_rate': 0.008880555555555556, 'epoch': 5.58}\n",
      "{'loss': 0.1854, 'learning_rate': 0.008877777777777778, 'epoch': 5.59}\n",
      "{'loss': 0.1892, 'learning_rate': 0.008875, 'epoch': 5.61}\n",
      "{'loss': 0.1847, 'learning_rate': 0.008872222222222222, 'epoch': 5.62}\n",
      "{'loss': 0.1893, 'learning_rate': 0.008869444444444444, 'epoch': 5.63}\n",
      "{'loss': 0.1961, 'learning_rate': 0.008866666666666667, 'epoch': 5.65}\n",
      "{'loss': 0.2107, 'learning_rate': 0.00886388888888889, 'epoch': 5.66}\n",
      "{'loss': 0.1932, 'learning_rate': 0.008861111111111111, 'epoch': 5.67}\n",
      "{'loss': 0.211, 'learning_rate': 0.008858333333333334, 'epoch': 5.69}\n",
      "{'loss': 0.202, 'learning_rate': 0.008855555555555556, 'epoch': 5.7}\n",
      "{'loss': 0.1924, 'learning_rate': 0.008852777777777779, 'epoch': 5.72}\n",
      "{'loss': 0.212, 'learning_rate': 0.00885, 'epoch': 5.73}\n",
      "{'loss': 0.1854, 'learning_rate': 0.008847222222222222, 'epoch': 5.74}\n",
      "{'loss': 0.1846, 'learning_rate': 0.008844444444444445, 'epoch': 5.76}\n",
      "{'loss': 0.211, 'learning_rate': 0.008841666666666666, 'epoch': 5.77}\n",
      "{'loss': 0.2073, 'learning_rate': 0.00883888888888889, 'epoch': 5.79}\n",
      "{'loss': 0.2094, 'learning_rate': 0.008836111111111112, 'epoch': 5.8}\n",
      "{'loss': 0.1904, 'learning_rate': 0.008833333333333334, 'epoch': 5.81}\n",
      "{'loss': 0.199, 'learning_rate': 0.008830555555555557, 'epoch': 5.83}\n",
      "{'loss': 0.1953, 'learning_rate': 0.008827777777777778, 'epoch': 5.84}\n",
      "{'loss': 0.1836, 'learning_rate': 0.008825, 'epoch': 5.85}\n",
      "{'loss': 0.1903, 'learning_rate': 0.008822222222222223, 'epoch': 5.87}\n",
      "{'loss': 0.1953, 'learning_rate': 0.008819444444444444, 'epoch': 5.88}\n",
      "{'eval_loss': 0.191043421626091, 'eval_roc_auc': 0.8434742067528564, 'eval_runtime': 54.9677, 'eval_samples_per_second': 30.563, 'eval_steps_per_second': 3.82, 'epoch': 5.88}\n",
      "{'loss': 0.1863, 'learning_rate': 0.008816666666666667, 'epoch': 5.9}\n",
      "{'loss': 0.1912, 'learning_rate': 0.008813888888888888, 'epoch': 5.91}\n",
      "{'loss': 0.1968, 'learning_rate': 0.008811111111111112, 'epoch': 5.92}\n",
      "{'loss': 0.1945, 'learning_rate': 0.008808333333333333, 'epoch': 5.94}\n",
      "{'loss': 0.1964, 'learning_rate': 0.008805555555555556, 'epoch': 5.95}\n",
      "{'loss': 0.2021, 'learning_rate': 0.00880277777777778, 'epoch': 5.97}\n",
      "{'loss': 0.1841, 'learning_rate': 0.0088, 'epoch': 5.98}\n",
      "{'loss': 0.1952, 'learning_rate': 0.008797222222222222, 'epoch': 5.99}\n",
      "{'loss': 0.1966, 'learning_rate': 0.008794444444444445, 'epoch': 6.01}\n",
      "{'loss': 0.209, 'learning_rate': 0.008791666666666666, 'epoch': 6.02}\n",
      "{'loss': 0.1878, 'learning_rate': 0.00878888888888889, 'epoch': 6.03}\n",
      "{'loss': 0.1925, 'learning_rate': 0.00878611111111111, 'epoch': 6.05}\n",
      "{'loss': 0.1978, 'learning_rate': 0.008783333333333334, 'epoch': 6.06}\n",
      "{'loss': 0.2104, 'learning_rate': 0.008780555555555555, 'epoch': 6.08}\n",
      "{'loss': 0.2052, 'learning_rate': 0.008777777777777778, 'epoch': 6.09}\n",
      "{'loss': 0.1873, 'learning_rate': 0.008775, 'epoch': 6.1}\n",
      "{'loss': 0.2001, 'learning_rate': 0.008772222222222223, 'epoch': 6.12}\n",
      "{'loss': 0.2114, 'learning_rate': 0.008769444444444444, 'epoch': 6.13}\n",
      "{'loss': 0.1938, 'learning_rate': 0.008766666666666667, 'epoch': 6.15}\n",
      "{'loss': 0.1959, 'learning_rate': 0.008763888888888889, 'epoch': 6.16}\n",
      "{'loss': 0.1923, 'learning_rate': 0.00876111111111111, 'epoch': 6.17}\n",
      "{'loss': 0.1988, 'learning_rate': 0.008758333333333333, 'epoch': 6.19}\n",
      "{'loss': 0.1827, 'learning_rate': 0.008755555555555556, 'epoch': 6.2}\n",
      "{'loss': 0.1919, 'learning_rate': 0.008752777777777778, 'epoch': 6.21}\n",
      "{'loss': 0.1938, 'learning_rate': 0.00875, 'epoch': 6.23}\n",
      "{'eval_loss': 0.1882815808057785, 'eval_roc_auc': 0.8482889088738723, 'eval_runtime': 53.9375, 'eval_samples_per_second': 31.147, 'eval_steps_per_second': 3.893, 'epoch': 6.23}\n",
      "{'loss': 0.189, 'learning_rate': 0.008747222222222222, 'epoch': 6.24}\n",
      "{'loss': 0.1765, 'learning_rate': 0.008744444444444445, 'epoch': 6.26}\n",
      "{'loss': 0.1912, 'learning_rate': 0.008741666666666667, 'epoch': 6.27}\n",
      "{'loss': 0.1877, 'learning_rate': 0.00873888888888889, 'epoch': 6.28}\n",
      "{'loss': 0.1907, 'learning_rate': 0.008736111111111111, 'epoch': 6.3}\n",
      "{'loss': 0.1899, 'learning_rate': 0.008733333333333333, 'epoch': 6.31}\n",
      "{'loss': 0.1921, 'learning_rate': 0.008730555555555556, 'epoch': 6.33}\n",
      "{'loss': 0.2034, 'learning_rate': 0.008727777777777777, 'epoch': 6.34}\n",
      "{'loss': 0.1927, 'learning_rate': 0.008725, 'epoch': 6.35}\n",
      "{'loss': 0.1895, 'learning_rate': 0.008722222222222223, 'epoch': 6.37}\n",
      "{'loss': 0.2003, 'learning_rate': 0.008719444444444445, 'epoch': 6.38}\n",
      "{'loss': 0.1934, 'learning_rate': 0.008716666666666668, 'epoch': 6.39}\n",
      "{'loss': 0.1789, 'learning_rate': 0.008713888888888889, 'epoch': 6.41}\n",
      "{'loss': 0.1796, 'learning_rate': 0.00871111111111111, 'epoch': 6.42}\n",
      "{'loss': 0.1956, 'learning_rate': 0.008708333333333334, 'epoch': 6.44}\n",
      "{'loss': 0.195, 'learning_rate': 0.008705555555555555, 'epoch': 6.45}\n",
      "{'loss': 0.201, 'learning_rate': 0.008702777777777778, 'epoch': 6.46}\n",
      "{'loss': 0.1869, 'learning_rate': 0.0087, 'epoch': 6.48}\n",
      "{'loss': 0.1851, 'learning_rate': 0.008697222222222223, 'epoch': 6.49}\n",
      "{'loss': 0.2082, 'learning_rate': 0.008694444444444446, 'epoch': 6.51}\n",
      "{'loss': 0.1821, 'learning_rate': 0.008691666666666667, 'epoch': 6.52}\n",
      "{'loss': 0.1998, 'learning_rate': 0.00868888888888889, 'epoch': 6.53}\n",
      "{'loss': 0.1958, 'learning_rate': 0.008686111111111111, 'epoch': 6.55}\n",
      "{'loss': 0.19, 'learning_rate': 0.008683333333333333, 'epoch': 6.56}\n",
      "{'loss': 0.1896, 'learning_rate': 0.008680555555555556, 'epoch': 6.57}\n",
      "{'eval_loss': 0.18581855297088623, 'eval_roc_auc': 0.8537271901924216, 'eval_runtime': 54.4039, 'eval_samples_per_second': 30.88, 'eval_steps_per_second': 3.86, 'epoch': 6.57}\n",
      "{'loss': 0.1831, 'learning_rate': 0.008677777777777777, 'epoch': 6.59}\n",
      "{'loss': 0.1927, 'learning_rate': 0.008675, 'epoch': 6.6}\n",
      "{'loss': 0.199, 'learning_rate': 0.008672222222222222, 'epoch': 6.62}\n",
      "{'loss': 0.1781, 'learning_rate': 0.008669444444444445, 'epoch': 6.63}\n",
      "{'loss': 0.1871, 'learning_rate': 0.008666666666666668, 'epoch': 6.64}\n",
      "{'loss': 0.1925, 'learning_rate': 0.00866388888888889, 'epoch': 6.66}\n",
      "{'loss': 0.1948, 'learning_rate': 0.008661111111111112, 'epoch': 6.67}\n",
      "{'loss': 0.1797, 'learning_rate': 0.008658333333333334, 'epoch': 6.69}\n",
      "{'loss': 0.1968, 'learning_rate': 0.008655555555555555, 'epoch': 6.7}\n",
      "{'loss': 0.1986, 'learning_rate': 0.008652777777777778, 'epoch': 6.71}\n",
      "{'loss': 0.1808, 'learning_rate': 0.00865, 'epoch': 6.73}\n",
      "{'loss': 0.183, 'learning_rate': 0.008647222222222221, 'epoch': 6.74}\n",
      "{'loss': 0.1952, 'learning_rate': 0.008644444444444444, 'epoch': 6.75}\n",
      "{'loss': 0.1802, 'learning_rate': 0.008641666666666667, 'epoch': 6.77}\n",
      "{'loss': 0.1989, 'learning_rate': 0.008638888888888889, 'epoch': 6.78}\n",
      "{'loss': 0.1852, 'learning_rate': 0.008636111111111112, 'epoch': 6.8}\n",
      "{'loss': 0.1953, 'learning_rate': 0.008633333333333333, 'epoch': 6.81}\n",
      "{'loss': 0.1749, 'learning_rate': 0.008630555555555556, 'epoch': 6.82}\n",
      "{'loss': 0.1862, 'learning_rate': 0.008627777777777778, 'epoch': 6.84}\n",
      "{'loss': 0.1911, 'learning_rate': 0.008625, 'epoch': 6.85}\n",
      "{'loss': 0.2064, 'learning_rate': 0.008622222222222222, 'epoch': 6.87}\n",
      "{'loss': 0.199, 'learning_rate': 0.008619444444444443, 'epoch': 6.88}\n",
      "{'loss': 0.1977, 'learning_rate': 0.008616666666666667, 'epoch': 6.89}\n",
      "{'loss': 0.2093, 'learning_rate': 0.00861388888888889, 'epoch': 6.91}\n",
      "{'loss': 0.1979, 'learning_rate': 0.008611111111111111, 'epoch': 6.92}\n",
      "{'eval_loss': 0.18581710755825043, 'eval_roc_auc': 0.8540777002163671, 'eval_runtime': 54.3796, 'eval_samples_per_second': 30.894, 'eval_steps_per_second': 3.862, 'epoch': 6.92}\n",
      "{'loss': 0.1872, 'learning_rate': 0.008608333333333334, 'epoch': 6.93}\n",
      "{'loss': 0.1807, 'learning_rate': 0.008605555555555556, 'epoch': 6.95}\n",
      "{'loss': 0.1736, 'learning_rate': 0.008602777777777779, 'epoch': 6.96}\n",
      "{'loss': 0.195, 'learning_rate': 0.0086, 'epoch': 6.98}\n",
      "{'loss': 0.1903, 'learning_rate': 0.008597222222222223, 'epoch': 6.99}\n",
      "{'loss': 0.1783, 'learning_rate': 0.008594444444444444, 'epoch': 7.0}\n",
      "{'loss': 0.1842, 'learning_rate': 0.008591666666666666, 'epoch': 7.02}\n",
      "{'loss': 0.1935, 'learning_rate': 0.008588888888888889, 'epoch': 7.03}\n",
      "{'loss': 0.1946, 'learning_rate': 0.008586111111111112, 'epoch': 7.04}\n",
      "{'loss': 0.1745, 'learning_rate': 0.008583333333333333, 'epoch': 7.06}\n",
      "{'loss': 0.1826, 'learning_rate': 0.008580555555555557, 'epoch': 7.07}\n",
      "{'loss': 0.1751, 'learning_rate': 0.008577777777777778, 'epoch': 7.09}\n",
      "{'loss': 0.1922, 'learning_rate': 0.008575000000000001, 'epoch': 7.1}\n",
      "{'loss': 0.194, 'learning_rate': 0.008572222222222222, 'epoch': 7.11}\n",
      "{'loss': 0.1943, 'learning_rate': 0.008569444444444444, 'epoch': 7.13}\n",
      "{'loss': 0.1877, 'learning_rate': 0.008566666666666667, 'epoch': 7.14}\n",
      "{'loss': 0.1821, 'learning_rate': 0.008563888888888888, 'epoch': 7.16}\n",
      "{'loss': 0.1964, 'learning_rate': 0.008561111111111111, 'epoch': 7.17}\n",
      "{'loss': 0.2024, 'learning_rate': 0.008558333333333333, 'epoch': 7.18}\n",
      "{'loss': 0.1911, 'learning_rate': 0.008555555555555556, 'epoch': 7.2}\n",
      "{'loss': 0.1846, 'learning_rate': 0.008552777777777779, 'epoch': 7.21}\n",
      "{'loss': 0.1934, 'learning_rate': 0.00855, 'epoch': 7.22}\n",
      "{'loss': 0.2049, 'learning_rate': 0.008547222222222223, 'epoch': 7.24}\n",
      "{'loss': 0.1779, 'learning_rate': 0.008544444444444445, 'epoch': 7.25}\n",
      "{'loss': 0.1901, 'learning_rate': 0.008541666666666666, 'epoch': 7.27}\n",
      "{'eval_loss': 0.18524445593357086, 'eval_roc_auc': 0.8542119641409425, 'eval_runtime': 53.0076, 'eval_samples_per_second': 31.694, 'eval_steps_per_second': 3.962, 'epoch': 7.27}\n",
      "{'loss': 0.1855, 'learning_rate': 0.00853888888888889, 'epoch': 7.28}\n",
      "{'loss': 0.1836, 'learning_rate': 0.00853611111111111, 'epoch': 7.29}\n",
      "{'loss': 0.192, 'learning_rate': 0.008533333333333334, 'epoch': 7.31}\n",
      "{'loss': 0.1994, 'learning_rate': 0.008530555555555555, 'epoch': 7.32}\n",
      "{'loss': 0.1869, 'learning_rate': 0.008527777777777778, 'epoch': 7.34}\n",
      "{'loss': 0.1798, 'learning_rate': 0.008525000000000001, 'epoch': 7.35}\n",
      "{'loss': 0.1866, 'learning_rate': 0.008522222222222223, 'epoch': 7.36}\n",
      "{'loss': 0.1953, 'learning_rate': 0.008519444444444444, 'epoch': 7.38}\n",
      "{'loss': 0.1911, 'learning_rate': 0.008516666666666667, 'epoch': 7.39}\n",
      "{'loss': 0.1871, 'learning_rate': 0.008513888888888889, 'epoch': 7.4}\n",
      "{'loss': 0.1989, 'learning_rate': 0.008511111111111112, 'epoch': 7.42}\n",
      "{'loss': 0.1776, 'learning_rate': 0.008508333333333333, 'epoch': 7.43}\n",
      "{'loss': 0.1886, 'learning_rate': 0.008505555555555556, 'epoch': 7.45}\n",
      "{'loss': 0.1688, 'learning_rate': 0.008502777777777778, 'epoch': 7.46}\n",
      "{'loss': 0.1967, 'learning_rate': 0.0085, 'epoch': 7.47}\n",
      "{'loss': 0.1857, 'learning_rate': 0.008497222222222224, 'epoch': 7.49}\n",
      "{'loss': 0.1737, 'learning_rate': 0.008494444444444445, 'epoch': 7.5}\n",
      "{'loss': 0.1837, 'learning_rate': 0.008491666666666666, 'epoch': 7.52}\n",
      "{'loss': 0.1837, 'learning_rate': 0.00848888888888889, 'epoch': 7.53}\n",
      "{'loss': 0.1872, 'learning_rate': 0.008486111111111111, 'epoch': 7.54}\n",
      "{'loss': 0.1832, 'learning_rate': 0.008483333333333334, 'epoch': 7.56}\n",
      "{'loss': 0.204, 'learning_rate': 0.008480555555555555, 'epoch': 7.57}\n",
      "{'loss': 0.1845, 'learning_rate': 0.008477777777777777, 'epoch': 7.58}\n",
      "{'loss': 0.1928, 'learning_rate': 0.008475, 'epoch': 7.6}\n",
      "{'loss': 0.1831, 'learning_rate': 0.008472222222222223, 'epoch': 7.61}\n",
      "{'eval_loss': 0.1824818253517151, 'eval_roc_auc': 0.8589080790650996, 'eval_runtime': 53.4191, 'eval_samples_per_second': 31.449, 'eval_steps_per_second': 3.931, 'epoch': 7.61}\n",
      "{'loss': 0.1798, 'learning_rate': 0.008469444444444444, 'epoch': 7.63}\n",
      "{'loss': 0.1954, 'learning_rate': 0.008466666666666667, 'epoch': 7.64}\n",
      "{'loss': 0.1893, 'learning_rate': 0.008463888888888889, 'epoch': 7.65}\n",
      "{'loss': 0.1889, 'learning_rate': 0.008461111111111112, 'epoch': 7.67}\n",
      "{'loss': 0.1889, 'learning_rate': 0.008458333333333333, 'epoch': 7.68}\n",
      "{'loss': 0.184, 'learning_rate': 0.008455555555555555, 'epoch': 7.7}\n",
      "{'loss': 0.1872, 'learning_rate': 0.008452777777777778, 'epoch': 7.71}\n",
      "{'loss': 0.1778, 'learning_rate': 0.00845, 'epoch': 7.72}\n",
      "{'loss': 0.1815, 'learning_rate': 0.008447222222222222, 'epoch': 7.74}\n",
      "{'loss': 0.1836, 'learning_rate': 0.008444444444444445, 'epoch': 7.75}\n",
      "{'loss': 0.1784, 'learning_rate': 0.008441666666666667, 'epoch': 7.76}\n",
      "{'loss': 0.1903, 'learning_rate': 0.00843888888888889, 'epoch': 7.78}\n",
      "{'loss': 0.1753, 'learning_rate': 0.008436111111111111, 'epoch': 7.79}\n",
      "{'loss': 0.1966, 'learning_rate': 0.008433333333333334, 'epoch': 7.81}\n",
      "{'loss': 0.1861, 'learning_rate': 0.008430555555555556, 'epoch': 7.82}\n",
      "{'loss': 0.1996, 'learning_rate': 0.008427777777777777, 'epoch': 7.83}\n",
      "{'loss': 0.1944, 'learning_rate': 0.008425, 'epoch': 7.85}\n",
      "{'loss': 0.183, 'learning_rate': 0.008422222222222222, 'epoch': 7.86}\n",
      "{'loss': 0.1855, 'learning_rate': 0.008419444444444445, 'epoch': 7.88}\n",
      "{'loss': 0.1711, 'learning_rate': 0.008416666666666668, 'epoch': 7.89}\n",
      "{'loss': 0.1884, 'learning_rate': 0.00841388888888889, 'epoch': 7.9}\n",
      "{'loss': 0.1917, 'learning_rate': 0.008411111111111112, 'epoch': 7.92}\n",
      "{'loss': 0.186, 'learning_rate': 0.008408333333333334, 'epoch': 7.93}\n",
      "{'loss': 0.1847, 'learning_rate': 0.008405555555555555, 'epoch': 7.94}\n",
      "{'loss': 0.1927, 'learning_rate': 0.008402777777777778, 'epoch': 7.96}\n",
      "{'eval_loss': 0.18097436428070068, 'eval_roc_auc': 0.8610703785823193, 'eval_runtime': 53.9506, 'eval_samples_per_second': 31.14, 'eval_steps_per_second': 3.892, 'epoch': 7.96}\n",
      "{'loss': 0.1873, 'learning_rate': 0.0084, 'epoch': 7.97}\n",
      "{'loss': 0.1685, 'learning_rate': 0.008397222222222223, 'epoch': 7.99}\n",
      "{'loss': 0.1787, 'learning_rate': 0.008394444444444444, 'epoch': 8.0}\n",
      "{'loss': 0.1943, 'learning_rate': 0.008391666666666667, 'epoch': 8.01}\n",
      "{'loss': 0.181, 'learning_rate': 0.008388888888888888, 'epoch': 8.03}\n",
      "{'loss': 0.1794, 'learning_rate': 0.008386111111111112, 'epoch': 8.04}\n",
      "{'loss': 0.1812, 'learning_rate': 0.008383333333333335, 'epoch': 8.06}\n",
      "{'loss': 0.1818, 'learning_rate': 0.008380555555555556, 'epoch': 8.07}\n",
      "{'loss': 0.1535, 'learning_rate': 0.008377777777777777, 'epoch': 8.08}\n",
      "{'loss': 0.1867, 'learning_rate': 0.008375, 'epoch': 8.1}\n",
      "{'loss': 0.1847, 'learning_rate': 0.008372222222222222, 'epoch': 8.11}\n",
      "{'loss': 0.1752, 'learning_rate': 0.008369444444444445, 'epoch': 8.12}\n",
      "{'loss': 0.1981, 'learning_rate': 0.008366666666666666, 'epoch': 8.14}\n",
      "{'loss': 0.1917, 'learning_rate': 0.00836388888888889, 'epoch': 8.15}\n",
      "{'loss': 0.1883, 'learning_rate': 0.00836111111111111, 'epoch': 8.17}\n",
      "{'loss': 0.1897, 'learning_rate': 0.008358333333333334, 'epoch': 8.18}\n",
      "{'loss': 0.1845, 'learning_rate': 0.008355555555555557, 'epoch': 8.19}\n",
      "{'loss': 0.1846, 'learning_rate': 0.008352777777777778, 'epoch': 8.21}\n",
      "{'loss': 0.1746, 'learning_rate': 0.00835, 'epoch': 8.22}\n",
      "{'loss': 0.1861, 'learning_rate': 0.008347222222222223, 'epoch': 8.24}\n",
      "{'loss': 0.1878, 'learning_rate': 0.008344444444444444, 'epoch': 8.25}\n",
      "{'loss': 0.1758, 'learning_rate': 0.008341666666666666, 'epoch': 8.26}\n",
      "{'loss': 0.1991, 'learning_rate': 0.008338888888888889, 'epoch': 8.28}\n",
      "{'loss': 0.1874, 'learning_rate': 0.008336111111111112, 'epoch': 8.29}\n",
      "{'loss': 0.1876, 'learning_rate': 0.008333333333333333, 'epoch': 8.3}\n",
      "{'eval_loss': 0.1792573630809784, 'eval_roc_auc': 0.8633300503950311, 'eval_runtime': 55.6693, 'eval_samples_per_second': 30.178, 'eval_steps_per_second': 3.772, 'epoch': 8.3}\n",
      "{'loss': 0.1784, 'learning_rate': 0.008330555555555556, 'epoch': 8.32}\n",
      "{'loss': 0.1741, 'learning_rate': 0.008327777777777778, 'epoch': 8.33}\n",
      "{'loss': 0.1818, 'learning_rate': 0.008325, 'epoch': 8.35}\n",
      "{'loss': 0.1742, 'learning_rate': 0.008322222222222222, 'epoch': 8.36}\n",
      "{'loss': 0.1874, 'learning_rate': 0.008319444444444445, 'epoch': 8.37}\n",
      "{'loss': 0.1794, 'learning_rate': 0.008316666666666667, 'epoch': 8.39}\n",
      "{'loss': 0.1844, 'learning_rate': 0.008313888888888888, 'epoch': 8.4}\n",
      "{'loss': 0.1829, 'learning_rate': 0.008311111111111111, 'epoch': 8.42}\n",
      "{'loss': 0.1764, 'learning_rate': 0.008308333333333333, 'epoch': 8.43}\n",
      "{'loss': 0.1743, 'learning_rate': 0.008305555555555556, 'epoch': 8.44}\n",
      "{'loss': 0.1942, 'learning_rate': 0.008302777777777779, 'epoch': 8.46}\n",
      "{'loss': 0.1878, 'learning_rate': 0.0083, 'epoch': 8.47}\n",
      "{'loss': 0.186, 'learning_rate': 0.008297222222222223, 'epoch': 8.48}\n",
      "{'loss': 0.1871, 'learning_rate': 0.008294444444444445, 'epoch': 8.5}\n",
      "{'loss': 0.1848, 'learning_rate': 0.008291666666666668, 'epoch': 8.51}\n",
      "{'loss': 0.1981, 'learning_rate': 0.008288888888888889, 'epoch': 8.53}\n",
      "{'loss': 0.1763, 'learning_rate': 0.00828611111111111, 'epoch': 8.54}\n",
      "{'loss': 0.182, 'learning_rate': 0.008283333333333334, 'epoch': 8.55}\n",
      "{'loss': 0.1898, 'learning_rate': 0.008280555555555555, 'epoch': 8.57}\n",
      "{'loss': 0.1855, 'learning_rate': 0.008277777777777778, 'epoch': 8.58}\n",
      "{'loss': 0.1826, 'learning_rate': 0.008275000000000001, 'epoch': 8.6}\n",
      "{'loss': 0.1902, 'learning_rate': 0.008272222222222222, 'epoch': 8.61}\n",
      "{'loss': 0.1835, 'learning_rate': 0.008269444444444446, 'epoch': 8.62}\n",
      "{'loss': 0.1909, 'learning_rate': 0.008266666666666667, 'epoch': 8.64}\n",
      "{'loss': 0.1843, 'learning_rate': 0.008263888888888888, 'epoch': 8.65}\n",
      "{'eval_loss': 0.1774255484342575, 'eval_roc_auc': 0.8656641309331448, 'eval_runtime': 56.4049, 'eval_samples_per_second': 29.785, 'eval_steps_per_second': 3.723, 'epoch': 8.65}\n",
      "{'loss': 0.1837, 'learning_rate': 0.008261111111111111, 'epoch': 8.66}\n",
      "{'loss': 0.1927, 'learning_rate': 0.008258333333333333, 'epoch': 8.68}\n",
      "{'loss': 0.1737, 'learning_rate': 0.008255555555555556, 'epoch': 8.69}\n",
      "{'loss': 0.183, 'learning_rate': 0.008252777777777777, 'epoch': 8.71}\n",
      "{'loss': 0.1876, 'learning_rate': 0.00825, 'epoch': 8.72}\n",
      "{'loss': 0.1755, 'learning_rate': 0.008247222222222222, 'epoch': 8.73}\n",
      "{'loss': 0.1691, 'learning_rate': 0.008244444444444445, 'epoch': 8.75}\n",
      "{'loss': 0.1933, 'learning_rate': 0.008241666666666668, 'epoch': 8.76}\n",
      "{'loss': 0.1849, 'learning_rate': 0.00823888888888889, 'epoch': 8.78}\n",
      "{'loss': 0.1845, 'learning_rate': 0.00823611111111111, 'epoch': 8.79}\n",
      "{'loss': 0.1963, 'learning_rate': 0.008233333333333334, 'epoch': 8.8}\n",
      "{'loss': 0.1882, 'learning_rate': 0.008230555555555555, 'epoch': 8.82}\n",
      "{'loss': 0.1811, 'learning_rate': 0.008227777777777778, 'epoch': 8.83}\n",
      "{'loss': 0.178, 'learning_rate': 0.008225, 'epoch': 8.84}\n",
      "{'loss': 0.1838, 'learning_rate': 0.008222222222222223, 'epoch': 8.86}\n",
      "{'loss': 0.186, 'learning_rate': 0.008219444444444444, 'epoch': 8.87}\n",
      "{'loss': 0.1564, 'learning_rate': 0.008216666666666667, 'epoch': 8.89}\n",
      "{'loss': 0.1851, 'learning_rate': 0.008213888888888889, 'epoch': 8.9}\n",
      "{'loss': 0.1847, 'learning_rate': 0.008211111111111112, 'epoch': 8.91}\n",
      "{'loss': 0.1753, 'learning_rate': 0.008208333333333333, 'epoch': 8.93}\n",
      "{'loss': 0.1803, 'learning_rate': 0.008205555555555556, 'epoch': 8.94}\n",
      "{'loss': 0.1836, 'learning_rate': 0.008202777777777778, 'epoch': 8.96}\n",
      "{'loss': 0.1838, 'learning_rate': 0.008199999999999999, 'epoch': 8.97}\n",
      "{'loss': 0.1774, 'learning_rate': 0.008197222222222222, 'epoch': 8.98}\n",
      "{'loss': 0.1692, 'learning_rate': 0.008194444444444445, 'epoch': 9.0}\n",
      "{'eval_loss': 0.177669495344162, 'eval_roc_auc': 0.8677027279740492, 'eval_runtime': 55.377, 'eval_samples_per_second': 30.338, 'eval_steps_per_second': 3.792, 'epoch': 9.0}\n",
      "{'loss': 0.1884, 'learning_rate': 0.008191666666666667, 'epoch': 9.01}\n",
      "{'loss': 0.1546, 'learning_rate': 0.00818888888888889, 'epoch': 9.02}\n",
      "{'loss': 0.1728, 'learning_rate': 0.008186111111111111, 'epoch': 9.04}\n",
      "{'loss': 0.1759, 'learning_rate': 0.008183333333333334, 'epoch': 9.05}\n",
      "{'loss': 0.1777, 'learning_rate': 0.008180555555555555, 'epoch': 9.07}\n",
      "{'loss': 0.1773, 'learning_rate': 0.008177777777777779, 'epoch': 9.08}\n",
      "{'loss': 0.1721, 'learning_rate': 0.008175, 'epoch': 9.09}\n",
      "{'loss': 0.1732, 'learning_rate': 0.008172222222222221, 'epoch': 9.11}\n",
      "{'loss': 0.1728, 'learning_rate': 0.008169444444444444, 'epoch': 9.12}\n",
      "{'loss': 0.1852, 'learning_rate': 0.008166666666666666, 'epoch': 9.13}\n",
      "{'loss': 0.1968, 'learning_rate': 0.008163888888888889, 'epoch': 9.15}\n",
      "{'loss': 0.1644, 'learning_rate': 0.008161111111111112, 'epoch': 9.16}\n",
      "{'loss': 0.1739, 'learning_rate': 0.008158333333333333, 'epoch': 9.18}\n",
      "{'loss': 0.1795, 'learning_rate': 0.008155555555555557, 'epoch': 9.19}\n",
      "{'loss': 0.1674, 'learning_rate': 0.008152777777777778, 'epoch': 9.2}\n",
      "{'loss': 0.1779, 'learning_rate': 0.00815, 'epoch': 9.22}\n",
      "{'loss': 0.171, 'learning_rate': 0.008147222222222222, 'epoch': 9.23}\n",
      "{'loss': 0.1801, 'learning_rate': 0.008144444444444444, 'epoch': 9.25}\n",
      "{'loss': 0.1918, 'learning_rate': 0.008141666666666667, 'epoch': 9.26}\n",
      "{'loss': 0.1803, 'learning_rate': 0.008138888888888888, 'epoch': 9.27}\n",
      "{'loss': 0.182, 'learning_rate': 0.008136111111111111, 'epoch': 9.29}\n",
      "{'loss': 0.1722, 'learning_rate': 0.008133333333333334, 'epoch': 9.3}\n",
      "{'loss': 0.1866, 'learning_rate': 0.008130555555555556, 'epoch': 9.31}\n",
      "{'loss': 0.1808, 'learning_rate': 0.008127777777777779, 'epoch': 9.33}\n",
      "{'loss': 0.1769, 'learning_rate': 0.008125, 'epoch': 9.34}\n",
      "{'eval_loss': 0.17407135665416718, 'eval_roc_auc': 0.8702781184086869, 'eval_runtime': 54.5813, 'eval_samples_per_second': 30.78, 'eval_steps_per_second': 3.847, 'epoch': 9.34}\n",
      "{'loss': 0.1679, 'learning_rate': 0.008122222222222222, 'epoch': 9.36}\n",
      "{'loss': 0.1634, 'learning_rate': 0.008119444444444445, 'epoch': 9.37}\n",
      "{'loss': 0.175, 'learning_rate': 0.008116666666666666, 'epoch': 9.38}\n",
      "{'loss': 0.1835, 'learning_rate': 0.00811388888888889, 'epoch': 9.4}\n",
      "{'loss': 0.1967, 'learning_rate': 0.00811111111111111, 'epoch': 9.41}\n",
      "{'loss': 0.1806, 'learning_rate': 0.008108333333333334, 'epoch': 9.43}\n",
      "{'loss': 0.1911, 'learning_rate': 0.008105555555555557, 'epoch': 9.44}\n",
      "{'loss': 0.1889, 'learning_rate': 0.008102777777777778, 'epoch': 9.45}\n",
      "{'loss': 0.1766, 'learning_rate': 0.008100000000000001, 'epoch': 9.47}\n",
      "{'loss': 0.1819, 'learning_rate': 0.008097222222222223, 'epoch': 9.48}\n",
      "{'loss': 0.1802, 'learning_rate': 0.008094444444444444, 'epoch': 9.49}\n",
      "{'loss': 0.193, 'learning_rate': 0.008091666666666667, 'epoch': 9.51}\n",
      "{'loss': 0.186, 'learning_rate': 0.008088888888888889, 'epoch': 9.52}\n",
      "{'loss': 0.195, 'learning_rate': 0.00808611111111111, 'epoch': 9.54}\n",
      "{'loss': 0.1802, 'learning_rate': 0.008083333333333333, 'epoch': 9.55}\n",
      "{'loss': 0.1769, 'learning_rate': 0.008080555555555556, 'epoch': 9.56}\n",
      "{'loss': 0.1701, 'learning_rate': 0.008077777777777777, 'epoch': 9.58}\n",
      "{'loss': 0.1838, 'learning_rate': 0.008075, 'epoch': 9.59}\n",
      "{'loss': 0.184, 'learning_rate': 0.008072222222222222, 'epoch': 9.61}\n",
      "{'loss': 0.1769, 'learning_rate': 0.008069444444444445, 'epoch': 9.62}\n",
      "{'loss': 0.1817, 'learning_rate': 0.008066666666666666, 'epoch': 9.63}\n",
      "{'loss': 0.1735, 'learning_rate': 0.00806388888888889, 'epoch': 9.65}\n",
      "{'loss': 0.1865, 'learning_rate': 0.008061111111111111, 'epoch': 9.66}\n",
      "{'loss': 0.1807, 'learning_rate': 0.008058333333333332, 'epoch': 9.67}\n",
      "{'loss': 0.1754, 'learning_rate': 0.008055555555555555, 'epoch': 9.69}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jgauthier/u/projects/ideal-word-representations/20231114 word rnn.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bspirit/home/jgauthier/u/projects/ideal-word-representations/20231114%20word%20rnn.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1556\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1557\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1558\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1559\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1560\u001b[0m     )\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/trainer.py:1929\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1926\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mepoch \u001b[39m=\u001b[39m epoch \u001b[39m+\u001b[39m (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m steps_skipped) \u001b[39m/\u001b[39m steps_in_epoch\n\u001b[1;32m   1927\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m-> 1929\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[1;32m   1930\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_substep_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/trainer.py:2256\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2254\u001b[0m         metrics\u001b[39m.\u001b[39mupdate(dataset_metrics)\n\u001b[1;32m   2255\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2256\u001b[0m     metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(ignore_keys\u001b[39m=\u001b[39;49mignore_keys_for_eval)\n\u001b[1;32m   2257\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report_to_hp_search(trial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2259\u001b[0m \u001b[39m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/trainer.py:2972\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2969\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   2971\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 2972\u001b[0m output \u001b[39m=\u001b[39m eval_loop(\n\u001b[1;32m   2973\u001b[0m     eval_dataloader,\n\u001b[1;32m   2974\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEvaluation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   2975\u001b[0m     \u001b[39m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   2976\u001b[0m     \u001b[39m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   2977\u001b[0m     prediction_loss_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2978\u001b[0m     ignore_keys\u001b[39m=\u001b[39;49mignore_keys,\n\u001b[1;32m   2979\u001b[0m     metric_key_prefix\u001b[39m=\u001b[39;49mmetric_key_prefix,\n\u001b[1;32m   2980\u001b[0m )\n\u001b[1;32m   2982\u001b[0m total_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mworld_size\n\u001b[1;32m   2983\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmetric_key_prefix\u001b[39m}\u001b[39;00m\u001b[39m_jit_compilation_time\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m output\u001b[39m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/trainer.py:3161\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3158\u001b[0m         batch_size \u001b[39m=\u001b[39m observed_batch_size\n\u001b[1;32m   3160\u001b[0m \u001b[39m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 3161\u001b[0m loss, logits, labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprediction_step(model, inputs, prediction_loss_only, ignore_keys\u001b[39m=\u001b[39;49mignore_keys)\n\u001b[1;32m   3162\u001b[0m main_input_name \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39m\"\u001b[39m\u001b[39mmain_input_name\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   3163\u001b[0m inputs_decode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39minclude_inputs_for_metrics \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/trainer.py:3376\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   3374\u001b[0m \u001b[39mif\u001b[39;00m has_labels \u001b[39mor\u001b[39;00m loss_without_labels:\n\u001b[1;32m   3375\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3376\u001b[0m         loss, outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs, return_outputs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   3377\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m   3379\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mdict\u001b[39m):\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/trainer.py:2707\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2705\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2706\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2707\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2708\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2709\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2710\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/userdata/jgauthier/projects/ideal-word-representations/models/frame_level.py:65\u001b[0m, in \u001b[0;36mFrameLevelRNNClassifier.forward\u001b[0;34m(self, input_values, attention_mask, label_mask, output_attentions, output_hidden_states, return_dict, labels)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m     55\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m     56\u001b[0m         input_values,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m         labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     63\u001b[0m ):\n\u001b[1;32m     64\u001b[0m     return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m---> 65\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwav2vec2(\n\u001b[1;32m     66\u001b[0m         input_values,\n\u001b[1;32m     67\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m     68\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m     69\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m     70\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m     71\u001b[0m     )\n\u001b[1;32m     73\u001b[0m     hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m     74\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1579\u001b[0m, in \u001b[0;36mWav2Vec2Model.forward\u001b[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1574\u001b[0m hidden_states, extract_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_projection(extract_features)\n\u001b[1;32m   1575\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mask_hidden_states(\n\u001b[1;32m   1576\u001b[0m     hidden_states, mask_time_indices\u001b[39m=\u001b[39mmask_time_indices, attention_mask\u001b[39m=\u001b[39mattention_mask\n\u001b[1;32m   1577\u001b[0m )\n\u001b[0;32m-> 1579\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1580\u001b[0m     hidden_states,\n\u001b[1;32m   1581\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1582\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1583\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1584\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1585\u001b[0m )\n\u001b[1;32m   1587\u001b[0m hidden_states \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1589\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madapter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:819\u001b[0m, in \u001b[0;36mWav2Vec2Encoder.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    813\u001b[0m         layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    814\u001b[0m             create_custom_forward(layer),\n\u001b[1;32m    815\u001b[0m             hidden_states,\n\u001b[1;32m    816\u001b[0m             attention_mask,\n\u001b[1;32m    817\u001b[0m         )\n\u001b[1;32m    818\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 819\u001b[0m         layer_outputs \u001b[39m=\u001b[39m layer(\n\u001b[1;32m    820\u001b[0m             hidden_states, attention_mask\u001b[39m=\u001b[39;49mattention_mask, output_attentions\u001b[39m=\u001b[39;49moutput_attentions\n\u001b[1;32m    821\u001b[0m         )\n\u001b[1;32m    822\u001b[0m     hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    824\u001b[0m \u001b[39mif\u001b[39;00m skip_the_layer:\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:692\u001b[0m, in \u001b[0;36mWav2Vec2EncoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states, attention_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    691\u001b[0m     attn_residual \u001b[39m=\u001b[39m hidden_states\n\u001b[0;32m--> 692\u001b[0m     hidden_states, attn_weights, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    693\u001b[0m         hidden_states, attention_mask\u001b[39m=\u001b[39;49mattention_mask, output_attentions\u001b[39m=\u001b[39;49moutput_attentions\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    696\u001b[0m     hidden_states \u001b[39m=\u001b[39m attn_residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/userdata/jgauthier/transformers/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:588\u001b[0m, in \u001b[0;36mWav2Vec2Attention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    585\u001b[0m     past_key_value \u001b[39m=\u001b[39m (key_states, value_states)\n\u001b[1;32m    587\u001b[0m proj_shape \u001b[39m=\u001b[39m (bsz \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim)\n\u001b[0;32m--> 588\u001b[0m query_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shape(query_states, tgt_len, bsz)\u001b[39m.\u001b[39;49mview(\u001b[39m*\u001b[39;49mproj_shape)\n\u001b[1;32m    589\u001b[0m key_states \u001b[39m=\u001b[39m key_states\u001b[39m.\u001b[39mreshape(\u001b[39m*\u001b[39mproj_shape)\n\u001b[1;32m    590\u001b[0m value_states \u001b[39m=\u001b[39m value_states\u001b[39m.\u001b[39mreshape(\u001b[39m*\u001b[39mproj_shape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
